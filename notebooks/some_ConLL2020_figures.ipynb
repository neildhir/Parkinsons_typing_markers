{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from src.preprocess import preprocessMRC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nd/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/MRC/MRCData-processed-interpolated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentences = df.sentence_content.unique()[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Books include Penguin Island, a satire on the Dreyfus affair'],\n",
       "       ['However, religions other than Islam, use a different pronunciation for Allah, although the spelling is the same'],\n",
       "       ['The Franks alliance was important exactly because of their renown hostility towards the Byzantine'],\n",
       "       ['He is buried in Egypt, Aswan at the Mausoleum of Aga Khan'],\n",
       "       ['The w-shaped glyph above the second consonant that it geminates, is in fact the beginning of a small letter'],\n",
       "       ['The novel explores the relationship between Patroclus and Achilles from boyhood to the fateful events of the Iliad'],\n",
       "       ['Generally considered a part of Central Asia, it is sometimes ascribed to a regional bloc in either the Middle East or South Asia'],\n",
       "       ['Although early behavioural or cognitive intervention can help children gain self-care, social, and communication skills, their is no known cure'],\n",
       "       [\"Lincoln's coffin would be encased in concrete several feet thick, and surrounded by a cage, and buried beneath a rock slab\"],\n",
       "       ['As of 2004, nearly 50% of Americans who were enrolled in employer health insurance plans were covered for acupuncture treatments'],\n",
       "       ['However, there is no evidence that those tattoos were used as acupuncture points or if they were just decorative in nature'],\n",
       "       ['They fought a thirty years war on the side of the Lamtuna Arabized Berbers who claimed Himyarite ancestry from the early Islamic invasions '],\n",
       "       ['Over three million cattle are residents of the province at one time or another, and Alberta beef has a healthy worldwide market'],\n",
       "       ['The Korean men have not fared so well in Olympic competition but still produce good results'],\n",
       "       ['Split-finger aiming requires the archer to place the index finger above the nocked arrow, while the middle and ring fingers are both placed below']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_char_pairs = [(1,13),(2,8),(3,10),(4,12),(5,12),(6,9),(7,10),(8,9),(9,10),(10,12),(11,9),(12,12),(13,11),(14,11),(15,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMedical Research Council funded PD copy-typing data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nd/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (433672, 12)\n",
      "Size of dataframe after row pruning: (433411, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (433411, 12)\n",
      "Size of dataframe after row pruning: (414321, 12)\n",
      "Using mode: MRC_MODE\n",
      "\n",
      "Total number of study subjects: 229\n",
      "Number of sentences typed by PD patients: 1415\n",
      "Number of sentences typed by controls: 1862\n",
      "Average sentence length: 120.30\n",
      "Minimum sentence length: 51\n",
      "Maximum sentence length: 241\n"
     ]
    }
   ],
   "source": [
    "proc = preprocessMRC()\n",
    "out = proc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Preprocessed_typed_sentence</th>\n",
       "      <th>locations</th>\n",
       "      <th>IKI_timings</th>\n",
       "      <th>PPTS_list</th>\n",
       "      <th>hold_time</th>\n",
       "      <th>pause_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>boosωkss includde penguiin islaand, a satiree ...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[288.70000000001164, 149.6999999999971, 355.59...</td>\n",
       "      <td>[b, o, o, s, ω, k, s, s,  , i, n, c, l, u, d, ...</td>\n",
       "      <td>[103.70000000001164, 61.19999999999709, 126.39...</td>\n",
       "      <td>[185.0, 88.5, 229.1999999999971, 385.699999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>however, religioosωns otheertω than islam, use...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[692.1000000000022, 150.5, 269.7000000000007, ...</td>\n",
       "      <td>[h, o, w, e, v, e, r, ,,  , r, e, l, i, g, i, ...</td>\n",
       "      <td>[31.600000000002183, 76.79999999999927, 124.09...</td>\n",
       "      <td>[660.5, 73.70000000000073, 145.60000000000218,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the franks alliancee was  importantt eaωxactly...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[252.60000000000582, 112.39999999999418, 174.3...</td>\n",
       "      <td>[t, h, e,  , f, r, a, n, k, s,  , a, l, l, i, ...</td>\n",
       "      <td>[114.30000000001746, 97.20000000001164, 104.20...</td>\n",
       "      <td>[138.29999999998836, 15.199999999982538, 70.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>hsωe is burieed  in eωegypt, aswamωn at thee m...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[433.79999999999563, 601.5999999999985, 290.5,...</td>\n",
       "      <td>[h, s, ω, e,  , i, s,  , b, u, r, i, e, e, d, ...</td>\n",
       "      <td>[140.29999999999563, 65.0, 126.5, 102.10000000...</td>\n",
       "      <td>[293.5, 536.5999999999985, 164.0, 158.29999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>the w-shaped glpyh above thee seecondd connsnω...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[285.1000000000058, 145.1999999999971, 214.599...</td>\n",
       "      <td>[t, h, e,  , w, -, s, h, a, p, e, d,  , g, l, ...</td>\n",
       "      <td>[145.60000000000582, 126.69999999999709, 85.09...</td>\n",
       "      <td>[139.5, 18.5, 129.5, 37.29999999998836, 139.39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID  Diagnosis Sentence_ID  \\\n",
       "0              11          1           1   \n",
       "1              11          1           2   \n",
       "2              11          1           3   \n",
       "3              11          1           4   \n",
       "4              11          1           5   \n",
       "\n",
       "                         Preprocessed_typed_sentence  \\\n",
       "0  boosωkss includde penguiin islaand, a satiree ...   \n",
       "1  however, religioosωns otheertω than islam, use...   \n",
       "2  the franks alliancee was  importantt eaωxactly...   \n",
       "3  hsωe is burieed  in eωegypt, aswamωn at thee m...   \n",
       "4  the w-shaped glpyh above thee seecondd connsnω...   \n",
       "\n",
       "                                           locations  \\\n",
       "0  0000000000000000000000000000000000000000000000...   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2  0000000000000000000000000000000000000000000000...   \n",
       "3  0000000000000000000000000000000000000000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                         IKI_timings  \\\n",
       "0  [288.70000000001164, 149.6999999999971, 355.59...   \n",
       "1  [692.1000000000022, 150.5, 269.7000000000007, ...   \n",
       "2  [252.60000000000582, 112.39999999999418, 174.3...   \n",
       "3  [433.79999999999563, 601.5999999999985, 290.5,...   \n",
       "4  [285.1000000000058, 145.1999999999971, 214.599...   \n",
       "\n",
       "                                           PPTS_list  \\\n",
       "0  [b, o, o, s, ω, k, s, s,  , i, n, c, l, u, d, ...   \n",
       "1  [h, o, w, e, v, e, r, ,,  , r, e, l, i, g, i, ...   \n",
       "2  [t, h, e,  , f, r, a, n, k, s,  , a, l, l, i, ...   \n",
       "3  [h, s, ω, e,  , i, s,  , b, u, r, i, e, e, d, ...   \n",
       "4  [t, h, e,  , w, -, s, h, a, p, e, d,  , g, l, ...   \n",
       "\n",
       "                                           hold_time  \\\n",
       "0  [103.70000000001164, 61.19999999999709, 126.39...   \n",
       "1  [31.600000000002183, 76.79999999999927, 124.09...   \n",
       "2  [114.30000000001746, 97.20000000001164, 104.20...   \n",
       "3  [140.29999999999563, 65.0, 126.5, 102.10000000...   \n",
       "4  [145.60000000000582, 126.69999999999709, 85.09...   \n",
       "\n",
       "                                          pause_time  \n",
       "0  [185.0, 88.5, 229.1999999999971, 385.699999999...  \n",
       "1  [660.5, 73.70000000000073, 145.60000000000218,...  \n",
       "2  [138.29999999998836, 15.199999999982538, 70.19...  \n",
       "3  [293.5, 536.5999999999985, 164.0, 158.29999999...  \n",
       "4  [139.5, 18.5, 129.5, 37.29999999998836, 139.39...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loc[(out.Participant_ID == 11) & (out.Sentence_ID == str(1)), \"Preprocessed_typed_sentence\"].tolist()[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word): \n",
    "    return [char.lower() for char in word]  \n",
    "\n",
    "def get_sentence_stats(df, target_sentences, sentence_id, diagnosis = 0,chars_to_consider=10):\n",
    "    \n",
    "    # load target sentences first\n",
    "    # assert sentence_id in range(0,target_sentences.shape[0])\n",
    "    ref_sent = split(list(target_sentences[sentence_id-1,:])[0]) # Note that the reference sentences are zero-indexed\n",
    "    print(\"This is the target sentence: {}\".format(target_sentences[sentence_id-1,:]))\n",
    "    print(\"Chars to consider: {}\".format(ref_sent[:chars_to_consider]))\n",
    "    ref_chars = ref_sent[:chars_to_consider]\n",
    "    n=len(ref_chars)\n",
    "    idxs = range(n)\n",
    "    \n",
    "    iki_stats = {k:[] for k in idxs}\n",
    "    hold_time_stats = {k:[] for k in idxs}\n",
    "    pause_time_stats = {k:[] for k in idxs}\n",
    "    \n",
    "    # Get the unique number of subjects\n",
    "    subjects = sorted(set(df.Participant_ID))  # NOTE: set() is weakly rando\n",
    "    # Loop over subjects\n",
    "    for subject in subjects:\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        if str(sentence_id) in df.loc[(df.Participant_ID == subject) & (df.Diagnosis == diagnosis)].Sentence_ID.unique():\n",
    "            # Sentence has been typed so we collect the stats\n",
    "            \n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.Participant_ID == subject) & (df.Sentence_ID == str(sentence_id))\n",
    "            \n",
    "            # To make more sense of the statistics we only collect it _if_ the subject has typed same character\n",
    "            # the reference sentence.\n",
    "            typed_sent = df.loc[coordinates, \"Preprocessed_typed_sentence\"].tolist()[0]\n",
    "            iki = df.loc[coordinates, \"IKI_timings\"].tolist()[0]\n",
    "            hold_time = df.loc[coordinates, \"hold_time\"].tolist()[0]\n",
    "            pause_time = df.loc[coordinates, \"pause_time\"].tolist()[0]\n",
    "            \n",
    "            # Find char stats\n",
    "            for i in idxs:\n",
    "                # print(subject,sentence_id,typed_sent[c],ref_sent[c])\n",
    "                if typed_sent[i] == ref_chars[i]:\n",
    "                    iki_stats[i].append(iki[i])\n",
    "                    hold_time_stats[i].append(hold_time[i])\n",
    "                    pause_time_stats[i].append(pause_time[i])\n",
    "\n",
    "    return iki_stats, hold_time_stats, pause_time_stats, ref_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_for_plotting(dict_times, ref_chars, assigned_diagnosis):\n",
    "    times = []\n",
    "    chars = []\n",
    "    diagnosis = []\n",
    "    idxs = range(len(ref_chars))\n",
    "    for i,c in enumerate(idxs):\n",
    "        n=len(dict_times[i])\n",
    "        chars.extend(n*[c])\n",
    "        times.extend(dict_times[i])\n",
    "        diagnosis.extend(n*[assigned_diagnosis])\n",
    "        \n",
    "    return pd.DataFrame(data=list(zip(chars,times,diagnosis)),columns=['key','time','Class'])\n",
    "\n",
    "def create_binary_dataframe(control_times, pd_times, ref_chars):\n",
    "    A = create_dataframe_for_plotting(control_times,ref_chars,assigned_diagnosis='Controls')\n",
    "    B = create_dataframe_for_plotting(pd_times,ref_chars,assigned_diagnosis=\"PwPD\")\n",
    "    return A.append(B)\n",
    "\n",
    "def get_plotting_data(df,target_sentences,sent_ID,char_count):\n",
    "    \n",
    "    iki_0,hold_time_0,pause_time_0, ref_chars = get_sentence_stats(df,target_sentences=target_sentences,sentence_id=sent_ID,diagnosis=0,chars_to_consider=char_count)\n",
    "    iki_1,hold_time_1,pause_time_1, ref_chars = get_sentence_stats(df,target_sentences=target_sentences,sentence_id=sent_ID,diagnosis=1,chars_to_consider=char_count)\n",
    "\n",
    "    # Make dataframe\n",
    "    A = create_binary_dataframe(hold_time_0,hold_time_1,ref_chars)\n",
    "    B = create_binary_dataframe(iki_0,iki_1,ref_chars)\n",
    "    C = create_binary_dataframe(pause_time_0,pause_time_1,ref_chars)\n",
    "    A['type'] = 'Hold-down'\n",
    "    B['type'] = 'Inter-key interval'\n",
    "    C['type'] = 'Pause'\n",
    "    tmp = A.append(B) # Replace with concat\n",
    "    D = tmp.append(C)\n",
    "    \n",
    "    return D, ref_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_plot(df,ref_chars,sent_ID,y_min,y_max,save_me=False):\n",
    "    sns.set_context(\"notebook\", font_scale=1.5)\n",
    "    sns.set_style(\"ticks\")\n",
    "    g = sns.catplot(x=\"key\", \n",
    "                    y=\"time\", \n",
    "                    hue=\"Class\", \n",
    "                    data=df, \n",
    "                    col=\"type\", \n",
    "                    capsize=.33, \n",
    "                    palette=\"colorblind\", \n",
    "                    scale=0.9,\n",
    "                    height=5, \n",
    "                    legend_out=False,\n",
    "                    aspect=0.9, \n",
    "                    kind=\"point\",\n",
    "                    lw=6,\n",
    "                    errwidth=2.,\n",
    "                    ci='sd')\n",
    "\n",
    "    g.map(plt.axhline, y=0, lw=1.5, ls=\"--\", c=\"0.75\",zorder=0)\n",
    "    g.set(ylim=(y_min,y_max))\n",
    "    g.fig.get_axes()[0].legend(loc='upper center',handletextpad=0.2,ncol=1)\n",
    "    g.set(xticklabels=ref_chars)\n",
    "    g.set_titles('{col_name}')\n",
    "    g.set_xlabels(\"\")\n",
    "    g.set_ylabels(\"Duration $[10^{-2} \\ s]$\")\n",
    "    \n",
    "    if save_me:\n",
    "        save_to = \"../figures/time_plots/time_plot_sentence_ID_\" + str(sent_ID) + '.pdf'\n",
    "        plt.savefig(save_to, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 1\n",
      "\n",
      "This is the target sentence: ['Books include Penguin Island, a satire on the Dreyfus affair']\n",
      "Chars to consider: ['b', 'o', 'o', 'k', 's', ' ', 'i', 'n', 'c', 'l', 'u', 'd', 'e']\n",
      "This is the target sentence: ['Books include Penguin Island, a satire on the Dreyfus affair']\n",
      "Chars to consider: ['b', 'o', 'o', 'k', 's', ' ', 'i', 'n', 'c', 'l', 'u', 'd', 'e']\n",
      "Sentence: 2\n",
      "\n",
      "This is the target sentence: ['However, religions other than Islam, use a different pronunciation for Allah, although the spelling is the same']\n",
      "Chars to consider: ['h', 'o', 'w', 'e', 'v', 'e', 'r', ',']\n",
      "This is the target sentence: ['However, religions other than Islam, use a different pronunciation for Allah, although the spelling is the same']\n",
      "Chars to consider: ['h', 'o', 'w', 'e', 'v', 'e', 'r', ',']\n",
      "Sentence: 3\n",
      "\n",
      "This is the target sentence: ['The Franks alliance was important exactly because of their renown hostility towards the Byzantine']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'f', 'r', 'a', 'n', 'k', 's']\n",
      "This is the target sentence: ['The Franks alliance was important exactly because of their renown hostility towards the Byzantine']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'f', 'r', 'a', 'n', 'k', 's']\n",
      "Sentence: 4\n",
      "\n",
      "This is the target sentence: ['He is buried in Egypt, Aswan at the Mausoleum of Aga Khan']\n",
      "Chars to consider: ['h', 'e', ' ', 'i', 's', ' ', 'b', 'u', 'r', 'i', 'e', 'd']\n",
      "This is the target sentence: ['He is buried in Egypt, Aswan at the Mausoleum of Aga Khan']\n",
      "Chars to consider: ['h', 'e', ' ', 'i', 's', ' ', 'b', 'u', 'r', 'i', 'e', 'd']\n",
      "Sentence: 5\n",
      "\n",
      "This is the target sentence: ['The w-shaped glyph above the second consonant that it geminates, is in fact the beginning of a small letter']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'w', '-', 's', 'h', 'a', 'p', 'e', 'd']\n",
      "This is the target sentence: ['The w-shaped glyph above the second consonant that it geminates, is in fact the beginning of a small letter']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'w', '-', 's', 'h', 'a', 'p', 'e', 'd']\n",
      "Sentence: 6\n",
      "\n",
      "This is the target sentence: ['The novel explores the relationship between Patroclus and Achilles from boyhood to the fateful events of the Iliad']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'n', 'o', 'v', 'e', 'l']\n",
      "This is the target sentence: ['The novel explores the relationship between Patroclus and Achilles from boyhood to the fateful events of the Iliad']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'n', 'o', 'v', 'e', 'l']\n",
      "Sentence: 7\n",
      "\n",
      "This is the target sentence: ['Generally considered a part of Central Asia, it is sometimes ascribed to a regional bloc in either the Middle East or South Asia']\n",
      "Chars to consider: ['g', 'e', 'n', 'e', 'r', 'a', 'l', 'l', 'y', ' ']\n",
      "This is the target sentence: ['Generally considered a part of Central Asia, it is sometimes ascribed to a regional bloc in either the Middle East or South Asia']\n",
      "Chars to consider: ['g', 'e', 'n', 'e', 'r', 'a', 'l', 'l', 'y', ' ']\n",
      "Sentence: 8\n",
      "\n",
      "This is the target sentence: ['Although early behavioural or cognitive intervention can help children gain self-care, social, and communication skills, their is no known cure']\n",
      "Chars to consider: ['a', 'l', 't', 'h', 'o', 'u', 'g', 'h', ' ']\n",
      "This is the target sentence: ['Although early behavioural or cognitive intervention can help children gain self-care, social, and communication skills, their is no known cure']\n",
      "Chars to consider: ['a', 'l', 't', 'h', 'o', 'u', 'g', 'h', ' ']\n",
      "Sentence: 9\n",
      "\n",
      "This is the target sentence: [\"Lincoln's coffin would be encased in concrete several feet thick, and surrounded by a cage, and buried beneath a rock slab\"]\n",
      "Chars to consider: ['l', 'i', 'n', 'c', 'o', 'l', 'n', \"'\", 's', ' ']\n",
      "This is the target sentence: [\"Lincoln's coffin would be encased in concrete several feet thick, and surrounded by a cage, and buried beneath a rock slab\"]\n",
      "Chars to consider: ['l', 'i', 'n', 'c', 'o', 'l', 'n', \"'\", 's', ' ']\n",
      "Sentence: 10\n",
      "\n",
      "This is the target sentence: ['As of 2004, nearly 50% of Americans who were enrolled in employer health insurance plans were covered for acupuncture treatments']\n",
      "Chars to consider: ['a', 's', ' ', 'o', 'f', ' ', '2', '0', '0', '4', ',', ' ']\n",
      "This is the target sentence: ['As of 2004, nearly 50% of Americans who were enrolled in employer health insurance plans were covered for acupuncture treatments']\n",
      "Chars to consider: ['a', 's', ' ', 'o', 'f', ' ', '2', '0', '0', '4', ',', ' ']\n",
      "Sentence: 11\n",
      "\n",
      "This is the target sentence: ['However, there is no evidence that those tattoos were used as acupuncture points or if they were just decorative in nature']\n",
      "Chars to consider: ['h', 'o', 'w', 'e', 'v', 'e', 'r', ',', ' ']\n",
      "This is the target sentence: ['However, there is no evidence that those tattoos were used as acupuncture points or if they were just decorative in nature']\n",
      "Chars to consider: ['h', 'o', 'w', 'e', 'v', 'e', 'r', ',', ' ']\n",
      "Sentence: 12\n",
      "\n",
      "This is the target sentence: ['They fought a thirty years war on the side of the Lamtuna Arabized Berbers who claimed Himyarite ancestry from the early Islamic invasions ']\n",
      "Chars to consider: ['t', 'h', 'e', 'y', ' ', 'f', 'o', 'u', 'g', 'h', 't', ' ']\n",
      "This is the target sentence: ['They fought a thirty years war on the side of the Lamtuna Arabized Berbers who claimed Himyarite ancestry from the early Islamic invasions ']\n",
      "Chars to consider: ['t', 'h', 'e', 'y', ' ', 'f', 'o', 'u', 'g', 'h', 't', ' ']\n",
      "Sentence: 13\n",
      "\n",
      "This is the target sentence: ['Over three million cattle are residents of the province at one time or another, and Alberta beef has a healthy worldwide market']\n",
      "Chars to consider: ['o', 'v', 'e', 'r', ' ', 't', 'h', 'r', 'e', 'e', ' ']\n",
      "This is the target sentence: ['Over three million cattle are residents of the province at one time or another, and Alberta beef has a healthy worldwide market']\n",
      "Chars to consider: ['o', 'v', 'e', 'r', ' ', 't', 'h', 'r', 'e', 'e', ' ']\n",
      "Sentence: 14\n",
      "\n",
      "This is the target sentence: ['The Korean men have not fared so well in Olympic competition but still produce good results']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'k', 'o', 'r', 'e', 'a', 'n', ' ']\n",
      "This is the target sentence: ['The Korean men have not fared so well in Olympic competition but still produce good results']\n",
      "Chars to consider: ['t', 'h', 'e', ' ', 'k', 'o', 'r', 'e', 'a', 'n', ' ']\n",
      "Sentence: 15\n",
      "\n",
      "This is the target sentence: ['Split-finger aiming requires the archer to place the index finger above the nocked arrow, while the middle and ring fingers are both placed below']\n",
      "Chars to consider: ['s', 'p', 'l', 'i', 't', '-', 'f', 'i', 'n', 'g', 'e', 'r', ' ']\n",
      "This is the target sentence: ['Split-finger aiming requires the archer to place the index finger above the nocked arrow, while the middle and ring fingers are both placed below']\n",
      "Chars to consider: ['s', 'p', 'l', 'i', 't', '-', 'f', 'i', 'n', 'g', 'e', 'r', ' ']\n"
     ]
    }
   ],
   "source": [
    "# Dict contains sentence ID on key, the first item in list is the char-count per sentence to display, the other two numbers are the min and max of the vertical axis\n",
    "sentence_stats = {1:[13,-200, 800],\n",
    "                  2:[8,-200, 1200],\n",
    "                  3:[10,-200, 1000],\n",
    "                  4:[12,-200, 800],\n",
    "                  5:[12,-200, 1200],\n",
    "                  6:[9,-200, 800],\n",
    "                  7:[10,-300, 800],\n",
    "                  8:[9,-200, 800],\n",
    "                  9:[10,-200, 1200],\n",
    "                  10:[12,-200, 1200],\n",
    "                  11:[9,-200, 800],\n",
    "                  12:[12,-200, 800],\n",
    "                  13:[11,-200, 800],\n",
    "                  14:[11,-200, 1000],\n",
    "                  15:[13,-200, 1200]}\n",
    "\n",
    "def plot_times(df,target_sentences,sentence_stats):\n",
    "    if isinstance(sentence_stats,dict):\n",
    "        for sent_ID in sentence_stats.keys():\n",
    "            print(\"Sentence: {}\\n\".format(sent_ID))\n",
    "            n_chars,y_min,y_max = sentence_stats[sent_ID]\n",
    "            df_plot, ref_chars = get_plotting_data(df,target_sentences,sent_ID,n_chars)\n",
    "            time_plot(df_plot,ref_chars,sent_ID,y_min,y_max,save_me=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "plot_times(out,target_sentences,sentence_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
