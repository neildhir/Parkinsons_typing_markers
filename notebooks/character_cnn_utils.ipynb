{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "# This blokc is important if we want the memory to grow on the GPU, and not block allocate the whole thing\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from datetime import datetime\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "from sklearn.utils import class_weight \n",
    "from numpy import vstack, asarray\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import pandas as pd\n",
    "\n",
    "# Hyperparam opt\n",
    "import talos as ta\n",
    "import numpy as np\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "# Global params live here\n",
    "import haberrspd.charCNN.globals\n",
    "from haberrspd.charCNN.models_tf import char_cnn_model_talos\n",
    "from haberrspd.charCNN.data_utilities import create_training_data_keras\n",
    "from haberrspd.postprocess_cnn_results import PostprocessTalos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PostprocessTalos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/neil/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/neil/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "test.load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters used in all typed sentences: 45\n"
     ]
    }
   ],
   "source": [
    "X_tests, targets = test.create_crossvalidated_test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(X_tests),len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "10 == len(X_tests) == len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters used in all typed sentences: 45\n"
     ]
    }
   ],
   "source": [
    "out = test.load_corresponding_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.361111\n",
       "1      0.638889\n",
       "2      0.361111\n",
       "3      0.638889\n",
       "4      0.361111\n",
       "         ...   \n",
       "295    0.638889\n",
       "296    0.638889\n",
       "297    0.638889\n",
       "298    0.361111\n",
       "299    0.638889\n",
       "Name: val_acc, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.results['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n",
      "(144, 200, 45) (144, 1)\n"
     ]
    }
   ],
   "source": [
    "assert len(X_tests) == len(targets)\n",
    "rocs = []  # Store all ROC 'curves' here\n",
    "for X_test, y_test in zip(X_tests, targets):\n",
    "    print(X_test.shape,y_test.shape)\n",
    "    labels_and_label_probs = np.zeros((len(X_test), 2))\n",
    "    for i, (y, x) in enumerate(zip(y_test, X_test)):\n",
    "        labels_and_label_probs[i, :] = [y, float(test.model.predict(x[np.newaxis, :, :]))]\n",
    "    rocs.append(labels_and_label_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894729],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894723],\n",
       "       [1.        , 0.49894741],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894741],\n",
       "       [1.        , 0.49894747],\n",
       "       [0.        , 0.49894729],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894741],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894729],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [1.        , 0.49894729],\n",
       "       [1.        , 0.49894729],\n",
       "       [1.        , 0.49894723],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894729],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894729],\n",
       "       [1.        , 0.49894723],\n",
       "       [1.        , 0.49894747],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894747],\n",
       "       [1.        , 0.49894723],\n",
       "       [0.        , 0.49894729],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.4989475 ],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894747],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894747],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894735],\n",
       "       [1.        , 0.49894723],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894729],\n",
       "       [1.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [0.        , 0.49894729],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894747],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894741],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894735],\n",
       "       [0.        , 0.49894741]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>alphabet_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>control_class_weight</th>\n",
       "      <th>conv_activation</th>\n",
       "      <th>conv_bias_initializer</th>\n",
       "      <th>...</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>lr</th>\n",
       "      <th>max_sentence_length</th>\n",
       "      <th>number_of_large_filters</th>\n",
       "      <th>number_of_small_filters</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>pd_class_weight</th>\n",
       "      <th>pool_length</th>\n",
       "      <th>small_filter_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119980</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2.08</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119402</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>8.02</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>6</td>\n",
       "      <td>0.689973</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.693631</td>\n",
       "      <td>0.565116</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>4.06</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119804</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120172</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2.08</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120113</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120270</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>6.04</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7</td>\n",
       "      <td>0.120265</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.120144</td>\n",
       "      <td>0.362791</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>6.04</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120684</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.120193</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>8.02</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.120318</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>8.02</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120266</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.120202</td>\n",
       "      <td>0.469767</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>8.02</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120720</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>0.362791</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>6.04</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss   val_acc      loss       acc  alphabet_size  \\\n",
       "299             6  0.119980  0.638889  0.120237  0.523256             45   \n",
       "125             6  0.119402  0.638889  0.120415  0.616279             45   \n",
       "250             6  0.689973  0.638889  0.693631  0.565116             45   \n",
       "116             6  0.119804  0.638889  0.120172  0.637209             45   \n",
       "118             6  0.120113  0.638889  0.120270  0.465116             45   \n",
       "..            ...       ...       ...       ...       ...            ...   \n",
       "152             7  0.120265  0.361111  0.120144  0.362791             45   \n",
       "154             6  0.120684  0.361111  0.120193  0.444186             45   \n",
       "155             7  0.120333  0.361111  0.120318  0.453488             45   \n",
       "158             6  0.120266  0.361111  0.120202  0.469767             45   \n",
       "150             6  0.120720  0.361111  0.120159  0.362791             45   \n",
       "\n",
       "     batch_size  control_class_weight conv_activation conv_bias_initializer  \\\n",
       "299          32              0.784672            relu               uniform   \n",
       "125          16              0.784672            relu               uniform   \n",
       "250          32              0.784672            relu               uniform   \n",
       "116          16              0.784672            relu               uniform   \n",
       "118          16              0.784672            relu               uniform   \n",
       "..          ...                   ...             ...                   ...   \n",
       "152          16              0.784672            relu               uniform   \n",
       "154          32              0.784672            relu               uniform   \n",
       "155          16              0.784672            relu               uniform   \n",
       "158          16              0.784672            relu               uniform   \n",
       "150          16              0.784672            relu               uniform   \n",
       "\n",
       "     ... last_activation               loss.1    lr max_sentence_length  \\\n",
       "299  ...         sigmoid              logcosh  2.08                 200   \n",
       "125  ...         sigmoid              logcosh  8.02                 200   \n",
       "250  ...         sigmoid  binary_crossentropy  4.06                 200   \n",
       "116  ...         sigmoid              logcosh  2.08                 200   \n",
       "118  ...         sigmoid              logcosh  6.04                 200   \n",
       "..   ...             ...                  ...   ...                 ...   \n",
       "152  ...         sigmoid              logcosh  6.04                 200   \n",
       "154  ...         sigmoid              logcosh  8.02                 200   \n",
       "155  ...         sigmoid              logcosh  8.02                 200   \n",
       "158  ...         sigmoid              logcosh  8.02                 200   \n",
       "150  ...         sigmoid              logcosh  6.04                 200   \n",
       "\n",
       "    number_of_large_filters number_of_small_filters  \\\n",
       "299                       1                       2   \n",
       "125                       2                       4   \n",
       "250                       4                       4   \n",
       "116                       4                       4   \n",
       "118                       1                       2   \n",
       "..                      ...                     ...   \n",
       "152                       4                       2   \n",
       "154                       1                       4   \n",
       "155                       2                       4   \n",
       "158                       2                       2   \n",
       "150                       2                       1   \n",
       "\n",
       "                            optimizer  pd_class_weight  pool_length  \\\n",
       "299  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "125  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "250  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "116  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "118  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "..                                ...              ...          ...   \n",
       "152   <class 'keras.optimizers.Adam'>         1.378205            2   \n",
       "154  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "155  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "158  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "150   <class 'keras.optimizers.Adam'>         1.378205            4   \n",
       "\n",
       "     small_filter_length  \n",
       "299                    8  \n",
       "125                    8  \n",
       "250                    2  \n",
       "116                    2  \n",
       "118                    4  \n",
       "..                   ...  \n",
       "152                    4  \n",
       "154                    4  \n",
       "155                    2  \n",
       "158                    4  \n",
       "150                    2  \n",
       "\n",
       "[300 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by validation accuracy\n",
    "test.results.sort_values(by=['val_acc'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = 'squared_hinge'\n",
    "\n",
    "if loss_func == 'hinge' or loss_func == 'squared_hinge':\n",
    "    y_train = [-1 if x==0 else x for x in y_train]\n",
    "    y_test = [-1 if x==0 else x for x in y_test]\n",
    "    \n",
    "if loss_func == 'binary_crossentropy':\n",
    "    # Check if label-space is correct\n",
    "    if (-1 in y_train) or (-1 in y_test):\n",
    "        y_train = [0 if x==-1 else x for x in y_train]\n",
    "        y_test = [0 if x==-1 else x for x in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model.compile(loss=loss_func,  # TODO: change to cosine loss, cosine_proximity, binary_crossentropy\n",
    "              optimizer='adam',            # TODO: check which is most appropriate\n",
    "              metrics=['accuracy'])        # Probs other options here which are more useful\n",
    "\n",
    "# Check if checkpoints dir exists, if not make it\n",
    "if not os.path.exists('../../keras_checkpoints'):\n",
    "    os.makedirs('../../keras_checkpoints')\n",
    "\n",
    "# Callbacks\n",
    "file_name = \"char-CNN\"\n",
    "check_cb = ModelCheckpoint(file_name + '.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                           monitor='val_loss',\n",
    "                           verbose=0,\n",
    "                           save_best_only=True,\n",
    "                           mode='min')\n",
    "\n",
    "earlystop_cb = EarlyStopping(monitor='val_loss',\n",
    "                             patience=7,\n",
    "                             verbose=0,\n",
    "                             mode='auto')\n",
    "\n",
    "# history = LossHistory()\n",
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "-Add class-weight option to take into account class-imbalance on patients and controls\n",
    "\"\"\"\n",
    "fit_hist = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     validation_data=(X_test, y_test),\n",
    "                     verbose=0, # Set to zero if using live plotting of losses\n",
    "                     class_weight = class_weights,\n",
    "                     batch_size=128,\n",
    "                     epochs=40,\n",
    "                     #shuffle=True, # Our data is already shuffled during data loading\n",
    "                     callbacks=[\n",
    "                                #check_cb,\n",
    "                                #tensorboard_callback,\n",
    "                                PlotLossesCallback(),\n",
    "                                #earlystop_cb\n",
    "                               ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TALOS: hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utilities import (create_training_data_keras,\n",
    "                                              create_data_objects,\n",
    "                                              english_language_qwerty_keyboard,\n",
    "                                              us_keyboard_keys_to_2d_coordinates_mrc,\n",
    "                                             )\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 100.0)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters used in all typed sentences: 54\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(\n",
    "    DATA_ROOT, \"char_time_space\", \"SpanishData-preprocessed.csv\")\n",
    "\n",
    "# Class weights are dynamic as the data-loader is stochastic and changes with each run.\n",
    "class_weights = dict(zip([0, 1], class_weight.compute_class_weight(\"balanced\", list(set(y_train)), y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 11100, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4199"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params = {\n",
    "    \"lr\": (0.1, 10, 5),  # This is a range not a tuple\n",
    "    \"conv_output_space\": [8, 16, 32],  # ,8],\n",
    "    \"number_of_large_filters\": [1, 2, 4],\n",
    "    \"number_of_small_filters\": [1, 2, 4],\n",
    "    \"large_filter_length\": [8, 16, 32],  # When time is included [20,40,80,160], when not: [10,20,40,80]\n",
    "    \"small_filter_length\": [2, 4, 8],  # [5, 10, 20],\n",
    "    \"pool_length\": [2, 4],\n",
    "    \"dense_units_layer_3\": [32, 64],\n",
    "    \"dense_units_layer_2\": [16, 32],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100, 200],\n",
    "    \"dropout\": (0, 0.5, 5),\n",
    "    \"conv_padding\": [\"same\"],\n",
    "    \"conv_kernel_initializer\": [\"uniform\"],\n",
    "    \"conv_bias_initializer\": [\"uniform\"],\n",
    "    \"dense_kernel_initializer\": [\"uniform\"],\n",
    "    \"dense_bias_initializer\": [\"uniform\"],\n",
    "    \"optimizer\": [Adam, Nadam],  # If used this way, these have to explicitly imported\n",
    "    \"loss\": [\"logcosh\", \"binary_crossentropy\"],  # Loss functions\n",
    "    \"conv_activation\": [\"relu\"],\n",
    "    \"dense_activation\": [\"relu\"],\n",
    "    \"last_activation\": [\"sigmoid\"],\n",
    "    # Stationary parameters, i.e. do not get optimised\n",
    "    \"max_sentence_length\": [max_sentence_length],\n",
    "    \"alphabet_size\": [alphabet_size],\n",
    "    \"control_class_weight\": [class_weights[0]],\n",
    "    \"pd_class_weight\": [class_weights[1]],\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "'sgd': SGD,\n",
    "'rmsprop': RMSprop,\n",
    "'adagrad': Adagrad,\n",
    "'adadelta': Adadelta,\n",
    "'adam': Adam,\n",
    "'adamax': Adamax,\n",
    "'nadam': Nadam\n",
    "\"\"\"\n",
    "\n",
    "def size_of_optimisation_space(params):\n",
    "    space = 1\n",
    "    for attribute in params.keys():\n",
    "        if type(attribute) == tuple:\n",
    "            space*=params[attribute][-1]\n",
    "        else:\n",
    "            space*=len(params[attribute])\n",
    "        \n",
    "    return space\n",
    "\n",
    "int(size_of_optimisation_space(opt_params) * 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6892 - val_acc: 0.6389\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6894 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6905 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6904 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6933 - acc: 0.6372 - val_loss: 0.6911 - val_acc: 0.6389\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6907 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|█         | 1/10 [00:02<00:19,  2.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6946 - acc: 0.3628 - val_loss: 0.6950 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3628 - val_loss: 0.6942 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6933 - acc: 0.3837 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.4465 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6936 - acc: 0.3512 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3628 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3581 - val_loss: 0.6934 - val_acc: 0.3611\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6933 - acc: 0.5186 - val_loss: 0.6937 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 2/10 [00:05<00:20,  2.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6949 - acc: 0.6372 - val_loss: 0.6896 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6938 - acc: 0.5767 - val_loss: 0.6928 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6937 - acc: 0.6047 - val_loss: 0.6937 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6940 - acc: 0.4419 - val_loss: 0.6933 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6939 - acc: 0.3721 - val_loss: 0.6927 - val_acc: 0.6389\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6941 - acc: 0.6000 - val_loss: 0.6924 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|███       | 3/10 [00:08<00:18,  2.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.1203 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1212 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1209 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1205 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1205 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:10<00:14,  2.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6962 - val_acc: 0.3611\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6957 - val_acc: 0.3611\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6932 - acc: 0.3884 - val_loss: 0.6935 - val_acc: 0.3611\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6939 - acc: 0.4419 - val_loss: 0.6937 - val_acc: 0.3611\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6933 - acc: 0.3977 - val_loss: 0.6944 - val_acc: 0.3611\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6929 - acc: 0.4186 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6930 - acc: 0.4256 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6932 - acc: 0.4070 - val_loss: 0.6938 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 5/10 [00:12<00:11,  2.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6937 - acc: 0.4326 - val_loss: 0.6925 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6933 - acc: 0.6395 - val_loss: 0.6926 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6932 - acc: 0.4605 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6916 - val_acc: 0.6389\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6933 - acc: 0.5558 - val_loss: 0.6930 - val_acc: 0.6389\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5884 - val_loss: 0.6910 - val_acc: 0.6389\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6932 - acc: 0.5605 - val_loss: 0.6931 - val_acc: 0.6389\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5953 - val_loss: 0.6916 - val_acc: 0.6389\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6932 - acc: 0.5512 - val_loss: 0.6924 - val_acc: 0.6389\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5279 - val_loss: 0.6921 - val_acc: 0.6389\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6942 - acc: 0.3698 - val_loss: 0.6964 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|██████    | 6/10 [00:14<00:08,  2.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1209 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1207 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1206 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.1201 - acc: 0.4512 - val_loss: 0.1204 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.1195 - acc: 0.4837 - val_loss: 0.1257 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|███████   | 7/10 [00:15<00:06,  2.01s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6935 - acc: 0.6372 - val_loss: 0.6892 - val_acc: 0.6389\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6900 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6913 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6918 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6936 - acc: 0.5116 - val_loss: 0.6925 - val_acc: 0.6389\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6279 - val_loss: 0.6920 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|████████  | 8/10 [00:19<00:05,  2.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1202 - acc: 0.4791 - val_loss: 0.1202 - val_acc: 0.3611\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1202 - acc: 0.5581 - val_loss: 0.1197 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1201 - acc: 0.6372 - val_loss: 0.1199 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1201 - acc: 0.6372 - val_loss: 0.1200 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1201 - acc: 0.4558 - val_loss: 0.1202 - val_acc: 0.3611\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1201 - acc: 0.3814 - val_loss: 0.1201 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|█████████ | 9/10 [00:21<00:02,  2.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6935 - acc: 0.5349 - val_loss: 0.6922 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5860 - val_loss: 0.6923 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6924 - val_acc: 0.6389\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.4465 - val_loss: 0.6935 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6935 - acc: 0.3860 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6935 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 10/10 [00:24<00:00,  2.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 s, sys: 896 ms, total: 28.9 s\n",
      "Wall time: 24.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = ta.Scan(x=X_train,\n",
    "            y=asarray(y_train).reshape(-1, 1),\n",
    "            x_val=X_test, \n",
    "            y_val=asarray(y_test).reshape(-1, 1),\n",
    "            experiment_name='../results/test',\n",
    "            model=char_cnn_model_talos,\n",
    "            round_limit=10,\n",
    "#             fraction_limit=0.005,\n",
    "            disable_progress_bar=False,\n",
    "            params=opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights passed to activation function\n",
    "from talos import Deploy, Predict, Restore\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test:  144\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 "
     ]
    }
   ],
   "source": [
    "results = np.zeros((len(X_test),2))\n",
    "print(\"Size of test: \", len(X_test))\n",
    "for i,(y,x) in enumerate(zip(y_test, X_test)):\n",
    "    print(i, end=\" \")\n",
    "    results[i,:] = [y, float(p.predict(x[np.newaxis,:,:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"foo-\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + \".csv\", \n",
    "           results,fmt='%.15f', \n",
    "           delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package test_deploy_MJFF_char_attempt_1 have been saved.\n",
      "data is not 2d, dummy data written instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x7f6c04e35b38>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deploy(scan_object=t, model_name='test_deploy_MJFF_char_attempt_1',metric='val_acc',asc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talos.utils.load_model import load_model\n",
    "\n",
    "tada = load_model(\"test_deploy/test_deploy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49789613]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tada.predict(x[np.newaxis,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
