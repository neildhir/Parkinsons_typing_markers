{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "# This blokc is important if we want the memory to grow on the GPU, and not block allocate the whole thing\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from datetime import datetime\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "from sklearn.utils import class_weight \n",
    "from numpy import vstack, asarray\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparam opt\n",
    "import talos as ta\n",
    "import numpy as np\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "# Global params live here\n",
    "import haberrspd.charCNN.globals\n",
    "from haberrspd.charCNN.models_tf import char_cnn_model_talos\n",
    "from haberrspd.charCNN.data_utilities import create_training_data_keras\n",
    "from haberrspd.postprocess_cnn_results import PostprocessTalos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from: ../results/MRC/char_time_space/english_mrc_attempt_1_talos_best_model_2019-12-06_02-13-28.zip\n",
      "Load test data from: mrc/char_time_space/EnglishData-preprocessed_attempt_1.csv\n"
     ]
    }
   ],
   "source": [
    "test = PostprocessTalos(dataset='mrc',which_information=\"char_time_space\", attempt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters used in all typed sentences: 60\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d0ae953c4bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mean_and_variance_of_ROC_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/postprocess_cnn_results.py\u001b[0m in \u001b[0;36mcalculate_mean_and_variance_of_ROC_curves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Get all samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_all_ROC_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/postprocess_cnn_results.py\u001b[0m in \u001b[0;36mcalculate_all_ROC_curves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_all_ROC_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mX_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_crossvalidated_test_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mrocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Store all ROC 'curves' here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/postprocess_cnn_results.py\u001b[0m in \u001b[0;36mcreate_crossvalidated_test_datasets\u001b[0;34m(self, splits)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_crossvalidated_test_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Note that these are received as proper arrays i.e. y is not a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_corresponding_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# SSS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/postprocess_cnn_results.py\u001b[0m in \u001b[0;36mload_corresponding_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Get processed data, ready to insert into the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         return create_training_data_keras(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_information\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_plotting_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/charCNN/data_utilities.py\u001b[0m in \u001b[0;36mcreate_training_data_keras\u001b[0;34m(DATA_ROOT, which_information, csv_file, feat_type, indicator_character, mrc_unk_symbol, for_plotting_results)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mspace_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Append coordinates to one-hot encoded sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ijk->kij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# Get labels (diagnoses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \"\"\"\n\u001b[1;32m    698\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = test.calculate_mean_and_variance_of_ROC_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out[0],out[1])\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>alphabet_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>control_class_weight</th>\n",
       "      <th>conv_activation</th>\n",
       "      <th>conv_bias_initializer</th>\n",
       "      <th>...</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>lr</th>\n",
       "      <th>max_sentence_length</th>\n",
       "      <th>number_of_large_filters</th>\n",
       "      <th>number_of_small_filters</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>pd_class_weight</th>\n",
       "      <th>pool_length</th>\n",
       "      <th>small_filter_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119980</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2.08</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119402</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>8.02</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>6</td>\n",
       "      <td>0.689973</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.693631</td>\n",
       "      <td>0.565116</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>4.06</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6</td>\n",
       "      <td>0.119804</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120172</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>2.08</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120113</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.120270</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784672</td>\n",
       "      <td>relu</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>6.04</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
       "      <td>1.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss   val_acc      loss       acc  alphabet_size  \\\n",
       "299             6  0.119980  0.638889  0.120237  0.523256             45   \n",
       "125             6  0.119402  0.638889  0.120415  0.616279             45   \n",
       "250             6  0.689973  0.638889  0.693631  0.565116             45   \n",
       "116             6  0.119804  0.638889  0.120172  0.637209             45   \n",
       "118             6  0.120113  0.638889  0.120270  0.465116             45   \n",
       "\n",
       "     batch_size  control_class_weight conv_activation conv_bias_initializer  \\\n",
       "299          32              0.784672            relu               uniform   \n",
       "125          16              0.784672            relu               uniform   \n",
       "250          32              0.784672            relu               uniform   \n",
       "116          16              0.784672            relu               uniform   \n",
       "118          16              0.784672            relu               uniform   \n",
       "\n",
       "     ... last_activation               loss.1    lr max_sentence_length  \\\n",
       "299  ...         sigmoid              logcosh  2.08                 200   \n",
       "125  ...         sigmoid              logcosh  8.02                 200   \n",
       "250  ...         sigmoid  binary_crossentropy  4.06                 200   \n",
       "116  ...         sigmoid              logcosh  2.08                 200   \n",
       "118  ...         sigmoid              logcosh  6.04                 200   \n",
       "\n",
       "    number_of_large_filters number_of_small_filters  \\\n",
       "299                       1                       2   \n",
       "125                       2                       4   \n",
       "250                       4                       4   \n",
       "116                       4                       4   \n",
       "118                       1                       2   \n",
       "\n",
       "                            optimizer  pd_class_weight  pool_length  \\\n",
       "299  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "125  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "250  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "116  <class 'keras.optimizers.Nadam'>         1.378205            2   \n",
       "118  <class 'keras.optimizers.Nadam'>         1.378205            4   \n",
       "\n",
       "     small_filter_length  \n",
       "299                    8  \n",
       "125                    8  \n",
       "250                    2  \n",
       "116                    2  \n",
       "118                    4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by validation accuracy\n",
    "test.results.sort_values(by=['val_acc'],ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = 'squared_hinge'\n",
    "\n",
    "if loss_func == 'hinge' or loss_func == 'squared_hinge':\n",
    "    y_train = [-1 if x==0 else x for x in y_train]\n",
    "    y_test = [-1 if x==0 else x for x in y_test]\n",
    "    \n",
    "if loss_func == 'binary_crossentropy':\n",
    "    # Check if label-space is correct\n",
    "    if (-1 in y_train) or (-1 in y_test):\n",
    "        y_train = [0 if x==-1 else x for x in y_train]\n",
    "        y_test = [0 if x==-1 else x for x in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model.compile(loss=loss_func,  # TODO: change to cosine loss, cosine_proximity, binary_crossentropy\n",
    "              optimizer='adam',            # TODO: check which is most appropriate\n",
    "              metrics=['accuracy'])        # Probs other options here which are more useful\n",
    "\n",
    "# Check if checkpoints dir exists, if not make it\n",
    "if not os.path.exists('../../keras_checkpoints'):\n",
    "    os.makedirs('../../keras_checkpoints')\n",
    "\n",
    "# Callbacks\n",
    "file_name = \"char-CNN\"\n",
    "check_cb = ModelCheckpoint(file_name + '.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                           monitor='val_loss',\n",
    "                           verbose=0,\n",
    "                           save_best_only=True,\n",
    "                           mode='min')\n",
    "\n",
    "earlystop_cb = EarlyStopping(monitor='val_loss',\n",
    "                             patience=7,\n",
    "                             verbose=0,\n",
    "                             mode='auto')\n",
    "\n",
    "# history = LossHistory()\n",
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "-Add class-weight option to take into account class-imbalance on patients and controls\n",
    "\"\"\"\n",
    "fit_hist = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     validation_data=(X_test, y_test),\n",
    "                     verbose=0, # Set to zero if using live plotting of losses\n",
    "                     class_weight = class_weights,\n",
    "                     batch_size=128,\n",
    "                     epochs=40,\n",
    "                     #shuffle=True, # Our data is already shuffled during data loading\n",
    "                     callbacks=[\n",
    "                                #check_cb,\n",
    "                                #tensorboard_callback,\n",
    "                                PlotLossesCallback(),\n",
    "                                #earlystop_cb\n",
    "                               ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TALOS: hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utilities import (create_training_data_keras,\n",
    "                                              create_data_objects,\n",
    "                                              english_language_qwerty_keyboard,\n",
    "                                              us_keyboard_keys_to_2d_coordinates_mrc,\n",
    "                                             )\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 100.0)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters used in all typed sentences: 54\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(\n",
    "    DATA_ROOT, \"char_time_space\", \"SpanishData-preprocessed.csv\")\n",
    "\n",
    "# Class weights are dynamic as the data-loader is stochastic and changes with each run.\n",
    "class_weights = dict(zip([0, 1], class_weight.compute_class_weight(\"balanced\", list(set(y_train)), y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 11100, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4199"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params = {\n",
    "    \"lr\": (0.1, 10, 5),  # This is a range not a tuple\n",
    "    \"conv_output_space\": [8, 16, 32],  # ,8],\n",
    "    \"number_of_large_filters\": [1, 2, 4],\n",
    "    \"number_of_small_filters\": [1, 2, 4],\n",
    "    \"large_filter_length\": [8, 16, 32],  # When time is included [20,40,80,160], when not: [10,20,40,80]\n",
    "    \"small_filter_length\": [2, 4, 8],  # [5, 10, 20],\n",
    "    \"pool_length\": [2, 4],\n",
    "    \"dense_units_layer_3\": [32, 64],\n",
    "    \"dense_units_layer_2\": [16, 32],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100, 200],\n",
    "    \"dropout\": (0, 0.5, 5),\n",
    "    \"conv_padding\": [\"same\"],\n",
    "    \"conv_kernel_initializer\": [\"uniform\"],\n",
    "    \"conv_bias_initializer\": [\"uniform\"],\n",
    "    \"dense_kernel_initializer\": [\"uniform\"],\n",
    "    \"dense_bias_initializer\": [\"uniform\"],\n",
    "    \"optimizer\": [Adam, Nadam],  # If used this way, these have to explicitly imported\n",
    "    \"loss\": [\"logcosh\", \"binary_crossentropy\"],  # Loss functions\n",
    "    \"conv_activation\": [\"relu\"],\n",
    "    \"dense_activation\": [\"relu\"],\n",
    "    \"last_activation\": [\"sigmoid\"],\n",
    "    # Stationary parameters, i.e. do not get optimised\n",
    "    \"max_sentence_length\": [max_sentence_length],\n",
    "    \"alphabet_size\": [alphabet_size],\n",
    "    \"control_class_weight\": [class_weights[0]],\n",
    "    \"pd_class_weight\": [class_weights[1]],\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "'sgd': SGD,\n",
    "'rmsprop': RMSprop,\n",
    "'adagrad': Adagrad,\n",
    "'adadelta': Adadelta,\n",
    "'adam': Adam,\n",
    "'adamax': Adamax,\n",
    "'nadam': Nadam\n",
    "\"\"\"\n",
    "\n",
    "def size_of_optimisation_space(params):\n",
    "    space = 1\n",
    "    for attribute in params.keys():\n",
    "        if type(attribute) == tuple:\n",
    "            space*=params[attribute][-1]\n",
    "        else:\n",
    "            space*=len(params[attribute])\n",
    "        \n",
    "    return space\n",
    "\n",
    "int(size_of_optimisation_space(opt_params) * 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6892 - val_acc: 0.6389\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6894 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6905 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6904 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6933 - acc: 0.6372 - val_loss: 0.6911 - val_acc: 0.6389\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6932 - acc: 0.6372 - val_loss: 0.6907 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|█         | 1/10 [00:02<00:19,  2.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6946 - acc: 0.3628 - val_loss: 0.6950 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3628 - val_loss: 0.6942 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6933 - acc: 0.3837 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.4465 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6936 - acc: 0.3512 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3628 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6934 - acc: 0.3581 - val_loss: 0.6934 - val_acc: 0.3611\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6933 - acc: 0.5186 - val_loss: 0.6937 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 2/10 [00:05<00:20,  2.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6949 - acc: 0.6372 - val_loss: 0.6896 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6938 - acc: 0.5767 - val_loss: 0.6928 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6937 - acc: 0.6047 - val_loss: 0.6937 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6940 - acc: 0.4419 - val_loss: 0.6933 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6939 - acc: 0.3721 - val_loss: 0.6927 - val_acc: 0.6389\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6941 - acc: 0.6000 - val_loss: 0.6924 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|███       | 3/10 [00:08<00:18,  2.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.1203 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1212 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1209 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1205 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.1201 - acc: 0.3628 - val_loss: 0.1205 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:10<00:14,  2.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6962 - val_acc: 0.3611\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6957 - val_acc: 0.3611\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6932 - acc: 0.3884 - val_loss: 0.6935 - val_acc: 0.3611\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6939 - acc: 0.4419 - val_loss: 0.6937 - val_acc: 0.3611\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6933 - acc: 0.3977 - val_loss: 0.6944 - val_acc: 0.3611\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6929 - acc: 0.4186 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6930 - acc: 0.4256 - val_loss: 0.6936 - val_acc: 0.3611\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6932 - acc: 0.4070 - val_loss: 0.6938 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 5/10 [00:12<00:11,  2.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6937 - acc: 0.4326 - val_loss: 0.6925 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6933 - acc: 0.6395 - val_loss: 0.6926 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6932 - acc: 0.4605 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6916 - val_acc: 0.6389\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6933 - acc: 0.5558 - val_loss: 0.6930 - val_acc: 0.6389\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5884 - val_loss: 0.6910 - val_acc: 0.6389\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6932 - acc: 0.5605 - val_loss: 0.6931 - val_acc: 0.6389\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5953 - val_loss: 0.6916 - val_acc: 0.6389\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6932 - acc: 0.5512 - val_loss: 0.6924 - val_acc: 0.6389\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5279 - val_loss: 0.6921 - val_acc: 0.6389\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6942 - acc: 0.3698 - val_loss: 0.6964 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|██████    | 6/10 [00:14<00:08,  2.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1209 - val_acc: 0.3611\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1208 - val_acc: 0.3611\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1207 - val_acc: 0.3611\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.1202 - acc: 0.3628 - val_loss: 0.1206 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.1201 - acc: 0.4512 - val_loss: 0.1204 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.1195 - acc: 0.4837 - val_loss: 0.1257 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|███████   | 7/10 [00:15<00:06,  2.01s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6935 - acc: 0.6372 - val_loss: 0.6892 - val_acc: 0.6389\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6900 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6913 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6918 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6936 - acc: 0.5116 - val_loss: 0.6925 - val_acc: 0.6389\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6934 - acc: 0.6279 - val_loss: 0.6920 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|████████  | 8/10 [00:19<00:05,  2.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1202 - acc: 0.4791 - val_loss: 0.1202 - val_acc: 0.3611\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1202 - acc: 0.5581 - val_loss: 0.1197 - val_acc: 0.6389\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1201 - acc: 0.6372 - val_loss: 0.1199 - val_acc: 0.6389\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1201 - acc: 0.6372 - val_loss: 0.1200 - val_acc: 0.6389\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1201 - acc: 0.4558 - val_loss: 0.1202 - val_acc: 0.3611\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1201 - acc: 0.3814 - val_loss: 0.1201 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|█████████ | 9/10 [00:21<00:02,  2.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6935 - acc: 0.5349 - val_loss: 0.6922 - val_acc: 0.6389\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6934 - acc: 0.5860 - val_loss: 0.6923 - val_acc: 0.6389\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6934 - acc: 0.6372 - val_loss: 0.6924 - val_acc: 0.6389\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6934 - acc: 0.4465 - val_loss: 0.6935 - val_acc: 0.3611\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6935 - acc: 0.3860 - val_loss: 0.6940 - val_acc: 0.3611\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6933 - acc: 0.3628 - val_loss: 0.6935 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 10/10 [00:24<00:00,  2.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 s, sys: 896 ms, total: 28.9 s\n",
      "Wall time: 24.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = ta.Scan(x=X_train,\n",
    "            y=asarray(y_train).reshape(-1, 1),\n",
    "            x_val=X_test, \n",
    "            y_val=asarray(y_test).reshape(-1, 1),\n",
    "            experiment_name='../results/test',\n",
    "            model=char_cnn_model_talos,\n",
    "            round_limit=10,\n",
    "#             fraction_limit=0.005,\n",
    "            disable_progress_bar=False,\n",
    "            params=opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights passed to activation function\n",
    "from talos import Deploy, Predict, Restore\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test:  144\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 "
     ]
    }
   ],
   "source": [
    "results = np.zeros((len(X_test),2))\n",
    "print(\"Size of test: \", len(X_test))\n",
    "for i,(y,x) in enumerate(zip(y_test, X_test)):\n",
    "    print(i, end=\" \")\n",
    "    results[i,:] = [y, float(p.predict(x[np.newaxis,:,:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"foo-\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + \".csv\", \n",
    "           results,fmt='%.15f', \n",
    "           delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package test_deploy_MJFF_char_attempt_1 have been saved.\n",
      "data is not 2d, dummy data written instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x7f6c04e35b38>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deploy(scan_object=t, model_name='test_deploy_MJFF_char_attempt_1',metric='val_acc',asc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talos.utils.load_model import load_model\n",
    "\n",
    "tada = load_model(\"test_deploy/test_deploy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49789613]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tada.predict(x[np.newaxis,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
