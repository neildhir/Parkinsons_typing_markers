{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "\n",
    "from haberrspd.preprocess import preprocessMJFF\n",
    "                         \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from scipy.stats import (gamma, lognorm, gengamma)\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Plot stuff\n",
    "import seaborn as sns\n",
    "from scipy.constants import golden\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Depending on where I am, set the path\n",
    "import socket\n",
    "if socket.gethostname() == 'pax':\n",
    "    # Monster machine\n",
    "    data_root = '../data/MJFF/' # My local path\n",
    "    data_root = Path(data_root)\n",
    "else:\n",
    "    # Laptop\n",
    "    data_root = '/home/nd/data/liverpool/MJFF' # My local path\n",
    "    data_root = Path(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character + Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/SpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_root / 'SpanishData-duplicateeventsremoved.csv')\n",
    "df = pd.read_csv(data_root / 'SpanishData.csv')\n",
    "df_meta = pd.read_csv(data_root / \"SpanishParticipantKey.csv\",\n",
    "                      index_col=0,\n",
    "                      header=0,\n",
    "                      names=['participant_id', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character ONLY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english',include_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/char/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = set(df_meta.loc[df_meta.diagnosis == 0].participant_id)\n",
    "pd_subjects = set(df_meta.loc[df_meta.diagnosis == 1].participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in pd_subjects:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    pd_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)\n",
    "    \n",
    "control_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in controls:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    control_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs\n",
    "pd_cleaned_list = [x for x in pd_timestamp_diffs if str(x) != 'nan']\n",
    "control_cleaned_list = [x for x in control_timestamp_diffs if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(pd_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(control_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical turk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(data_root /'preprocessed_MechanicalTurkCombinedEnglishData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/MJFF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IKI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_mjff_iki_training_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_mjff_data_objects, us_standard_layout_keyboard, english_keys_to_2d_coordinates\n",
    "import keras.backend as K\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, int64, ones, hstack, pad, einsum, dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import cast, float32, one_hot\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time_space\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "if which_information == \"char_time_space\":\n",
    "    # Get relevant long-format data\n",
    "    which_information = \"char_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "\n",
    "# Store alphabet size\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "print('Total number of characters:', alphabet_size)\n",
    "alphabet_indices = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "if which_information == \"char_time\" or which_information == \"char_time_space\":\n",
    "    # Rounds (up) to nearest thousand\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -3)\n",
    "if which_information == \"char\":\n",
    "    # Rounds (up) to nearest hundred\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -2)\n",
    "\n",
    "# Make training data array\n",
    "all_sentences = [item for sublist in subject_documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer which maps characters to integers\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "\n",
    "# Fit to text: convert all chars to ints\n",
    "tk.fit_on_texts(all_sentences)\n",
    "\n",
    "# Update alphabet\n",
    "tk.word_index = alphabet_indices\n",
    "\n",
    "# Get integer sequences: converts sequences of chars to sequences of ints\n",
    "int_sequences = tk.texts_to_sequences(all_sentences)\n",
    "\n",
    "# Pad sequences so that they all have the same length and then one-hot encode\n",
    "X = to_categorical(pad_sequences(int_sequences, maxlen=max_sentence_length, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information  =  'char_time_space'\n",
    "if which_information == 'char_time_space':\n",
    "    # Load relevant keyboard\n",
    "    keyboard = us_standard_layout_keyboard()  # OBS: nested list\n",
    "    # Check that all chars are in fact in our \"keyboard\" -- if not, we cannot map a coordinate\n",
    "    assert alphabet.issubset(set(list(itertools.chain.from_iterable(keyboard))))\n",
    "    space = [english_keys_to_2d_coordinates(sentence, keyboard) for sentence in all_sentences]\n",
    "    space_padded = [pad(s, [(0, max_sentence_length - len(s)), (0, 0)], mode='constant') for s in space]\n",
    "    # Append coordinates to one-hot encoded sentences\n",
    "    X = einsum('ijk->kij', dstack([hstack((x, s)) for (x, s) in zip(X, space_padded)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document (participant) -level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three options (at time of writing):\n",
    "\n",
    "1. Submit each sentence to model and extract classification probability for each sentence, agglomorate at the end, and the conduct a classification on the vector of all 15 probabilities.\n",
    "2. Calculate the expected value of all encoded (15) sentences and then pass this to the model and take the classification.\n",
    "3. Vertically stack all embedded sentences, and let the convolution run over this (very long) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_training_data_keras, create_mjff_data_objects\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "# subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "# X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(DATA_ROOT, which_information, data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in subject_documents[:3]:\n",
    "    print(doc[:2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Homogenise so that Spacebar is a blank character\n",
    "0. Delete rubbish characters (i.e. remove the rows)\n",
    "2. What to do with stuff like Shift\n",
    "3. Figure out what to do when multiple characters are depressed simultaneously\n",
    "4. Make lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from haberrspd.preprocess import clean_MRC, backspace_corrector, make_character_compression_time_sentence, reorder_key_timestamp_columns_mrc, calculate_edit_distance_between_response_and_target_MRC\n",
    "from haberrspd.charCNN.data_utils_tf import us_english_keyboard_mrc\n",
    "from numpy import concatenate\n",
    "from typing import Tuple\n",
    "import random\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from itertools import compress, count, groupby\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "# Monster machine\n",
    "data_root = '../data/MRC/' # My local path\n",
    "data_root = Path(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv(data_root / \"CombinedTypingDataSept27.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (814388, 12)\n",
      "Size of dataframe after row pruning: (812330, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (812330, 12)\n",
      "Size of dataframe after row pruning: (780201, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "      <td>1</td>\n",
       "      <td>25885.055</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26086.840</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>shift</td>\n",
       "      <td>keyup</td>\n",
       "      <td>1</td>\n",
       "      <td>26181.975</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>keyup</td>\n",
       "      <td>0</td>\n",
       "      <td>26193.745</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>o</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26321.480</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key     type  location  timestamp  participant_id  sentence_id  diagnosis\n",
       "0  shift  keydown         1  25885.055            1010            1          0\n",
       "1      h  keydown         0  26086.840            1010            1          0\n",
       "2  shift    keyup         1  26181.975            1010            1          0\n",
       "3      h    keyup         0  26193.745            1010            1          0\n",
       "4      o  keydown         0  26321.480            1010            1          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clean_MRC(df)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.copy(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol to process the MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A form of `create_char_compression_time_mjff_data` [to get the temporal data] <-- this needs to be set so that we get a list of \n",
    "2. Second use `create_dataframe_from_processed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_compression_time_mrc_data(df: pd.DataFrame, \n",
    "                                          time_redux_fact=10) -> Tuple[dict, list]:\n",
    "\n",
    "    assert set([\"participant_id\", \"key\", \"timestamp\", \"sentence_id\"]).issubset(df.columns)\n",
    "\n",
    "    # All sentences will be stored here, indexed by their type\n",
    "    char_compression_sentences = defaultdict(dict)\n",
    "    \n",
    "    # Get the unique number of subjects\n",
    "    subjects = sorted(set(df.participant_id))\n",
    "\n",
    "    # Loop over subjects\n",
    "    for subj_idx in subjects:\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "            \n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "            \n",
    "            print(\"Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "            \n",
    "            # Get correctly ordered sentences and total compression times\n",
    "            df_tmp = reorder_key_timestamp_columns_mrc(df.loc[coordinates, ('key','timestamp')])\n",
    "            \n",
    "            # TODO: check to see if the key-compression column follows the correct order\n",
    "            \n",
    "            \n",
    "            # \"correct\" the sentence by operating on user backspaces \n",
    "            corrected_char_sentence, removed_chars_indx = backspace_corrector(df_tmp.key.tolist())\n",
    "            \n",
    "            compression_times = calculate_total_key_compression_time(df_tmp.drop(df_tmp.index[removed_chars_indx]))\n",
    "            \n",
    "            assert len(compression_times) == len(corrected_char_sentence[::2]), \"Error at ({},{}).\".format(subj_idx,sent_idx)\n",
    "            assert any(x < 0 for x in compression_times) is False, \"Error at ({},{}).\".format(subj_idx,sent_idx) # Check no negative timings\n",
    "\n",
    "            # Make long-format version of each typed, corrected, sentence\n",
    "            # Note that we remove the last character to make the calculation correct.\n",
    "            char_compression_sentences[subj_idx][sent_idx] = make_character_compression_time_sentence(compression_times,\n",
    "                                                                                                      corrected_char_sentence[::2], \n",
    "                                                                                                      time_redux_fact)\n",
    "    return char_compression_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(v, d={}, c=count()):\n",
    "    if v in d:\n",
    "        return d.pop(v)\n",
    "    else:\n",
    "        d[v] = next(c)\n",
    "        return d[v]\n",
    "\n",
    "def reorder_key_timestamp_columns_mrc(df: pd.DataFrame):\n",
    "\n",
    "    # Check that the column is of even length\n",
    "    assert len(df) % 2 == 0, \"The length is {}.\".format(len(df))\n",
    "\n",
    "    # Use lookup function to extract the next row-order\n",
    "    df[\"new_row_order\"] = df.key.map(lookup)\n",
    "    \n",
    "    # Don't return an object, just leave as is\n",
    "    return df.sort_values(by=\"new_row_order\", kind=\"mergesort\").drop(\"new_row_order\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "58\n",
      "\n",
      "2\n",
      "4\n",
      "[broken sentence] Participant: 58, Sentence: 4\n",
      "1\n",
      "5\n",
      "3\n",
      "10\n",
      "9\n",
      "7\n",
      "8\n",
      "14\n",
      "6\n",
      "15\n",
      "12\n",
      "11\n",
      "[broken sentence] Participant: 58, Sentence: 11\n",
      "13\n",
      "\n",
      "85\n",
      "\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "10\n",
      "9\n",
      "7\n",
      "8\n",
      "14\n",
      "6\n",
      "15\n",
      "12\n",
      "11\n",
      "13\n",
      "\n",
      "1048\n",
      "\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "[broken sentence] Participant: 1048, Sentence: 15\n",
      "\n",
      "32\n",
      "\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "10\n",
      "9\n",
      "7\n",
      "8\n",
      "14\n",
      "6\n",
      "15\n",
      "12\n",
      "11\n",
      "13\n",
      "\n",
      "40\n",
      "\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "10\n",
      "9\n",
      "[broken sentence] Participant: 40, Sentence: 9\n",
      "7\n",
      "[broken sentence] Participant: 40, Sentence: 7\n",
      "8\n",
      "14\n",
      "6\n",
      "15\n",
      "12\n",
      "11\n",
      "13\n",
      "Percentage failed: 6.666666666666667\n",
      "5 70\n"
     ]
    }
   ],
   "source": [
    "# TODO: backstop removal before any of this is run properly\n",
    "# Test just a single sentence here\n",
    "\n",
    "\n",
    "fail=0\n",
    "success=0\n",
    "corrected_sentences = defaultdict(dict)\n",
    "broken_sentences = defaultdict(dict)\n",
    "for subj_idx in [58,85,1048,32,40]:#np.random.choice(df.participant_id.unique(),size=5,replace=False):\n",
    "    # Not all subjects have typed all sentences hence we have to do it this way\n",
    "    print(\"\\n{}\\n\".format(subj_idx))\n",
    "    for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "        \n",
    "        print(sent_idx)\n",
    "        \n",
    "        # Locate df segment to extract\n",
    "        coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "        \n",
    "        # Store temporary dataframe because why not\n",
    "        tmp_df = df.loc[coordinates, ('key','timestamp','type')].reset_index(drop=True) # Reset index \n",
    "        \n",
    "        #print(sent_idx)\n",
    "        \n",
    "        # Get correctly ordered sentences and total compression times\n",
    "        tmp_df = new_sort(tmp_df)\n",
    "        # Implements backspace contiguous presses [TODO: where do we sort????]\n",
    "#         with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#             print(backspace_implementer_mrc(tmp_df))\n",
    "    \n",
    "        # Removes contiguous shift presses\n",
    "        combine_contiguous_shift_keydowns_without_matching_keyup(tmp_df)\n",
    "        \n",
    "        \n",
    "        backspace_implementer_mrc(tmp_df)\n",
    "    \n",
    "        # Remove solitary key-presses which do not have a matching keyup or keydown\n",
    "        remove_solitary_key_presses(tmp_df)\n",
    "        \n",
    "        # Check what we managed to achieve\n",
    "        if assess_repeating_key_compression_pattern(tmp_df.type.tolist()):\n",
    "            \n",
    "            \n",
    "            # TODO: add condition which asserts that time column is monotonically increasing\n",
    "            \n",
    "            \n",
    "            # Condition succeeds: data-collection is fixed    \n",
    "            corrected_sentences[subj_idx][sent_idx] = tmp_df\n",
    "            success+=1\n",
    "        else:\n",
    "            # Condition fails: data-collection is broken\n",
    "            broken_sentences[subj_idx][sent_idx] = tmp_df\n",
    "            fail+=1\n",
    "            print(\"[broken sentence] Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "\n",
    "\n",
    "print(\"Percentage failed: {}\".format(100* (fail / (success+fail))))\n",
    "print(fail,success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>shift</td>\n",
       "      <td>25219.0</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>shift</td>\n",
       "      <td>25594.0</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>25422.0</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>25594.0</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>o</td>\n",
       "      <td>25766.0</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key  timestamp     type\n",
       "0  shift    25219.0  keydown\n",
       "1  shift    25594.0    keyup\n",
       "2      h    25422.0  keydown\n",
       "3      h    25594.0    keyup\n",
       "4      o    25766.0  keydown"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key   timestamp     type\n",
      "0    shift  328692.115  keydown\n",
      "1    shift  329131.950    keyup\n",
      "2        g  328947.860  keydown\n",
      "3        g  329107.855    keyup\n",
      "4        e  329339.850  keydown\n",
      "5        e  329547.930    keyup\n",
      "6        n  329635.915  keydown\n",
      "7        n  329795.745    keyup\n",
      "8        e  329835.740  keydown\n",
      "9        e  330059.685    keyup\n",
      "10       r  330027.665  keydown\n",
      "11       r  330219.710    keyup\n",
      "12       a  330315.745  keydown\n",
      "13       a  330523.675    keyup\n",
      "14       l  330531.695  keydown\n",
      "15       l  330635.650    keyup\n",
      "16       l  330755.945  keydown\n",
      "17       l  330899.675    keyup\n",
      "18       y  331059.600  keydown\n",
      "19       y  331227.705    keyup\n",
      "20          331339.715  keydown\n",
      "21          331571.615    keyup\n",
      "22       c  331611.640  keydown\n",
      "23       c  331827.570    keyup\n",
      "24       o  331803.455  keydown\n",
      "25       o  331955.460    keyup\n",
      "26       n  332139.490  keydown\n",
      "27       n  332259.440    keyup\n",
      "28       s  332283.420  keydown\n",
      "29       s  332475.580    keyup\n",
      "30       i  332523.555  keydown\n",
      "31       i  332723.380    keyup\n",
      "32       d  332763.440  keydown\n",
      "33       d  332955.475    keyup\n",
      "34       e  333091.280  keydown\n",
      "35       e  333315.420    keyup\n",
      "36       r  333299.250  keydown\n",
      "37       r  333539.300    keyup\n",
      "38       e  333547.255  keydown\n",
      "39       e  333707.435    keyup\n",
      "40       d  333907.170  keydown\n",
      "41       d  334067.230    keyup\n",
      "42          334195.220  keydown\n",
      "43          334363.170    keyup\n",
      "44       a  334371.195  keydown\n",
      "45       a  334571.390    keyup\n",
      "46          334587.340  keydown\n",
      "47          334747.170    keyup\n",
      "48       p  334843.040  keydown\n",
      "49       p  335051.015    keyup\n",
      "50       a  334979.050  keydown\n",
      "51       a  335219.080    keyup\n",
      "52       r  335267.180  keydown\n",
      "53       r  335419.190    keyup\n",
      "54       t  335555.175  keydown\n",
      "55       t  335754.940    keyup\n",
      "56          335770.995  keydown\n",
      "57          335955.200    keyup\n",
      "58       o  335979.070  keydown\n",
      "59       o  336226.945    keyup\n",
      "60       f  336122.935  keydown\n",
      "61       f  336323.090    keyup\n",
      "62          336403.000  keydown\n",
      "63          336618.835    keyup\n",
      "64   shift  336610.820  keydown\n",
      "65   shift  336970.855    keyup\n",
      "66       c  336811.370  keydown\n",
      "67       c  336994.915    keyup\n",
      "68       e  337218.915  keydown\n",
      "69       e  337426.740    keyup\n",
      "70       n  337450.725  keydown\n",
      "71       n  337618.915    keyup\n",
      "72       t  337642.865  keydown\n",
      "73       t  337802.630    keyup\n",
      "74       r  338034.625  keydown\n",
      "75       r  338242.650    keyup\n",
      "76       a  338186.770  keydown\n",
      "77       a  338442.805    keyup\n",
      "78       l  338378.600  keydown\n",
      "79       l  338546.820    keyup\n",
      "80          338754.615  keydown\n",
      "81          338962.725    keyup\n",
      "82   shift  338906.695  keydown\n",
      "83   shift  339170.565    keyup\n",
      "84       a  339026.535  keydown\n",
      "85       a  339226.620    keyup\n",
      "86       s  339394.720  keydown\n",
      "87       s  339618.420    keyup\n",
      "88       i  339986.405  keydown\n",
      "89       i  340154.375    keyup\n",
      "90       a  340114.330  keydown\n",
      "91       a  340298.365    keyup\n",
      "92       ,  342274.140  keydown\n",
      "93       ,  342378.320    keyup\n",
      "94          342618.095  keydown\n",
      "95          342722.195    keyup\n",
      "96       i  343258.000  keydown\n",
      "97       i  343482.040    keyup\n",
      "98       t  343458.040  keydown\n",
      "99       t  343690.015    keyup\n",
      "100         343594.590  keydown\n",
      "101         343753.960    keyup\n",
      "102      i  343801.855  keydown\n",
      "103      i  344009.850    keyup\n",
      "104      s  343977.785  keydown\n",
      "105      s  344169.835    keyup\n",
      "106         344113.845  keydown\n",
      "107         344329.935    keyup\n",
      "108      s  344330.100  keydown\n",
      "109      s  344506.065    keyup\n",
      "110      o  344410.175  keydown\n",
      "111      o  344585.930    keyup\n",
      "112      m  344713.855  keydown\n",
      "113      m  344897.880    keyup\n",
      "114      e  344857.770  keydown\n",
      "115      e  345057.685    keyup\n",
      "116      t  345337.880  keydown\n",
      "117      t  345561.640    keyup\n",
      "118      i  345521.665  keydown\n",
      "119      i  345673.690    keyup\n",
      "120      m  345817.820  keydown\n",
      "121      m  346001.665    keyup\n",
      "122      e  345945.540  keydown\n",
      "123      e  346177.740    keyup\n",
      "124      s  346177.910  keydown\n",
      "125      s  346417.610    keyup\n",
      "126         346489.620  keydown\n",
      "127         346689.510    keyup\n",
      "128      a  346721.460  keydown\n",
      "129      a  346913.645    keyup\n",
      "130      s  347033.365  keydown\n",
      "131      s  347209.515    keyup\n",
      "132      c  347385.600  keydown\n",
      "133      c  347561.385    keyup\n",
      "134      r  347873.760  keydown\n",
      "135      r  348097.315    keyup\n",
      "136      i  348145.305  keydown\n",
      "137      i  348321.460    keyup\n",
      "138      b  348449.215  keydown\n",
      "139      b  348649.485    keyup\n",
      "140      e  348801.300  keydown\n",
      "141      e  348969.255    keyup\n",
      "142      d  349177.260  keydown\n",
      "143      d  349329.250    keyup\n",
      "144         349417.155  keydown\n",
      "145         349713.235    keyup\n",
      "146      t  349657.345  keydown\n",
      "147      t  349881.155    keyup\n",
      "148      o  349857.010  keydown\n",
      "149      o  350041.075    keyup\n",
      "150         350112.975  keydown\n",
      "151         350257.150    keyup\n",
      "152      a  350193.100  keydown\n",
      "153      a  350409.170    keyup\n",
      "154         350417.100  keydown\n",
      "155         350648.990    keyup\n",
      "156      r  350593.210  keydown\n",
      "157      r  350809.395    keyup\n",
      "158      e  350809.650  keydown\n",
      "159      e  350945.200    keyup\n",
      "160      g  351096.855  keydown\n",
      "161      g  351273.075    keyup\n",
      "162      i  351321.010  keydown\n",
      "163      i  351552.900    keyup\n",
      "164      o  351512.860  keydown\n",
      "165      o  351689.010    keyup\n",
      "166      n  351904.805  keydown\n",
      "167      n  352032.825    keyup\n",
      "168      a  352024.750  keydown\n",
      "169      a  352224.960    keyup\n",
      "170      l  352328.695  keydown\n",
      "171      l  352496.720    keyup\n",
      "172         352640.845  keydown\n",
      "173         352832.715    keyup\n",
      "174      b  352928.695  keydown\n",
      "175      b  353088.610    keyup\n",
      "176      l  353512.745  keydown\n",
      "177      l  353640.590    keyup\n",
      "178      o  354128.510  keydown\n",
      "179      o  354336.685    keyup\n",
      "180      c  354376.585  keydown\n",
      "181      c  354560.635    keyup\n",
      "182         355008.355  keydown\n",
      "183         355176.410    keyup\n",
      "184      i  355264.485  keydown\n",
      "185      i  355424.365    keyup\n",
      "186      n  355608.405  keydown\n",
      "187      n  355784.315    keyup\n",
      "188         355824.240  keydown\n",
      "189         356032.275    keyup\n",
      "190      e  356336.265  keydown\n",
      "191      e  356512.345    keyup\n",
      "192      i  356536.215  keydown\n",
      "193      i  356728.210    keyup\n",
      "194      t  356784.230  keydown\n",
      "195      t  356992.105    keyup\n",
      "196      h  356984.195  keydown\n",
      "197      h  357112.090    keyup\n",
      "198      e  357096.285  keydown\n",
      "199      e  357336.130    keyup\n",
      "200      r  357304.210  keydown\n",
      "201      r  357496.155    keyup\n",
      "202         357568.120  keydown\n",
      "203         357736.210    keyup\n",
      "204      t  357927.920  keydown\n",
      "205      t  358248.425    keyup\n",
      "206      h  358056.030  keydown\n",
      "207      h  358311.920    keyup\n",
      "208      e  358216.180  keydown\n",
      "209      e  358439.870    keyup\n",
      "210         358544.065  keydown\n",
      "211         358743.880    keyup\n",
      "212  shift  358704.105  keydown\n",
      "213  shift  358999.795    keyup\n",
      "214      m  358871.925  keydown\n",
      "215      m  359007.845    keyup\n",
      "216      i  359175.775  keydown\n",
      "217      i  359303.930    keyup\n",
      "218      d  359631.795  keydown\n",
      "219      d  359703.735    keyup\n",
      "220      d  359783.940  keydown\n",
      "221      d  359911.925    keyup\n",
      "222      l  360087.760  keydown\n",
      "223      l  360215.835    keyup\n",
      "224      e  360191.785  keydown\n",
      "225      e  360359.830    keyup\n",
      "226         361351.515  keydown\n",
      "227         361527.645    keyup\n",
      "228  shift  361591.685  keydown\n",
      "229  shift  362103.395    keyup\n",
      "230      w  361887.420  keydown\n",
      "231      w  362063.370    keyup\n",
      "232      a  362375.575  keydown\n",
      "233      a  362607.610    keyup\n",
      "234      s  362927.515  keydown\n",
      "235      s  363087.275    keyup\n",
      "236      t  363279.425  keydown\n",
      "237      t  363471.315    keyup\n",
      "238         363567.190  keydown\n",
      "239         363751.500    keyup\n",
      "240      o  363783.400  keydown\n",
      "241      o  364031.220    keyup\n",
      "242      r  363983.115  keydown\n",
      "243      r  364247.330    keyup\n",
      "244         364231.285  keydown\n",
      "245         364463.110    keyup\n",
      "246  shift  364471.185  keydown\n",
      "247  shift  364959.055    keyup\n",
      "248      s  364759.300  keydown\n",
      "249      s  365014.995    keyup\n",
      "250      o  365086.935  keydown\n",
      "251      o  365311.050    keyup\n",
      "252      u  365374.965  keydown\n",
      "253      u  365583.060    keyup\n",
      "254      t  365991.005  keydown\n",
      "255      t  366214.850    keyup\n",
      "256      h  366094.880  keydown\n",
      "257      h  366262.935    keyup\n",
      "258         366335.050  keydown\n",
      "259         366526.840    keyup\n",
      "260  shift  366582.780  keydown\n",
      "261  shift  367082.575  keydown\n",
      "262  shift  367115.530  keydown\n",
      "263  shift  367148.585  keydown\n",
      "264      a  367158.850  keydown\n",
      "265      a  367366.715    keyup\n",
      "266  shift  367374.720    keyup\n",
      "267      s  367830.640  keydown\n",
      "268      s  368022.650    keyup\n",
      "269      i  368942.720  keydown\n",
      "270      i  369030.500    keyup\n",
      "271      a  369006.475  keydown\n",
      "272      a  369182.495    keyup\n",
      "273      £  370446.290  keydown\n",
      "274      £  370550.920    keyup\n"
     ]
    }
   ],
   "source": [
    "test_df = copy.copy(df.loc[(df.participant_id == 40) & \n",
    "                           (df.sentence_id == 7), \n",
    "                           (\"key\", \"timestamp\",\"type\")].reset_index(drop=True))\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(new_sort(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1       203.0\n",
       "2       172.0\n",
       "3         0.0\n",
       "4       172.0\n",
       "        ...  \n",
       "257     125.0\n",
       "258      94.0\n",
       "259      94.0\n",
       "260    4030.0\n",
       "261      94.0\n",
       "Name: timestamp, Length: 262, dtype: float64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.timestamp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key  timestamp     type\n",
      "0        €   293309.0  keydown\n",
      "1        €   297278.0    keyup\n",
      "2    shift   297684.0  keydown\n",
      "3        l   297872.0  keydown\n",
      "4        l   297997.0    keyup\n",
      "5    shift   298043.0    keyup\n",
      "6        i   298246.0  keydown\n",
      "7        i   298371.0    keyup\n",
      "8        n   298591.0  keydown\n",
      "9        n   298699.0    keyup\n",
      "10       c   298857.0  keydown\n",
      "11       c   299044.0    keyup\n",
      "12       o   299075.0  keydown\n",
      "13       o   299199.0    keyup\n",
      "14       l   300403.0  keydown\n",
      "15       l   300591.0    keyup\n",
      "16       n   300778.0  keydown\n",
      "17       n   300872.0    keyup\n",
      "18       '   301419.0  keydown\n",
      "19       s   301575.0  keydown\n",
      "20       '   301575.0    keyup\n",
      "21       s   301669.0    keyup\n",
      "22           302402.0  keydown\n",
      "23           302528.0    keyup\n",
      "24       c   303388.0  keydown\n",
      "25       c   303497.0    keyup\n",
      "26       o   303794.0  keydown\n",
      "27       o   303935.0    keyup\n",
      "28       f   304107.0  keydown\n",
      "29       f   304184.0    keyup\n",
      "30       f   304278.0  keydown\n",
      "31       i   304340.0  keydown\n",
      "32       f   304388.0    keyup\n",
      "33       i   304513.0    keyup\n",
      "34       n   304700.0  keydown\n",
      "35       n   304841.0    keyup\n",
      "36           305278.0  keydown\n",
      "37           305341.0    keyup\n",
      "38       w   305700.0  keydown\n",
      "39       w   305809.0    keyup\n",
      "40       o   306903.0  keydown\n",
      "41       u   307107.0  keydown\n",
      "42       o   307185.0    keyup\n",
      "43       u   307216.0    keyup\n",
      "44       l   307388.0  keydown\n",
      "45       d   307559.0  keydown\n",
      "46       l   307574.0    keyup\n",
      "47       d   307669.0    keyup\n",
      "48           307763.0  keydown\n",
      "49           307888.0    keyup\n",
      "50       b   308497.0  keydown\n",
      "51       b   308653.0    keyup\n",
      "52       e   308810.0  keydown\n",
      "53       e   308904.0    keyup\n",
      "54           309012.0  keydown\n",
      "55           309107.0    keyup\n",
      "56       e   309418.0  keydown\n",
      "57       e   309543.0    keyup\n",
      "58       n   309606.0  keydown\n",
      "59       n   309685.0    keyup\n",
      "60       c   309871.0  keydown\n",
      "61       a   309997.0  keydown\n",
      "62       c   310028.0    keyup\n",
      "63       s   310122.0  keydown\n",
      "64       a   310233.0    keyup\n",
      "65       s   310262.0    keyup\n",
      "66       e   310513.0  keydown\n",
      "67       e   310622.0    keyup\n",
      "68           310700.0  keydown\n",
      "69           310778.0    keyup\n",
      "70       i   311044.0  keydown\n",
      "71       i   311216.0    keyup\n",
      "72       n   311310.0  keydown\n",
      "73       n   311528.0    keyup\n",
      "74           311574.0  keydown\n",
      "75           311653.0    keyup\n",
      "76       c   311793.0  keydown\n",
      "77       o   311904.0  keydown\n",
      "78       c   311919.0    keyup\n",
      "79       n   312091.0  keydown\n",
      "80       o   312216.0    keyup\n",
      "81       n   312248.0    keyup\n",
      "82       c   312340.0  keydown\n",
      "83       c   312419.0    keyup\n",
      "84       r   312591.0  keydown\n",
      "85       e   312686.0  keydown\n",
      "86       r   312748.0    keyup\n",
      "87       e   312872.0    keyup\n",
      "88       t   312966.0  keydown\n",
      "89       e   313121.0  keydown\n",
      "90       t   313231.0    keyup\n",
      "91       e   313277.0    keyup\n",
      "92           313575.0  keydown\n",
      "93           313622.0    keyup\n",
      "94       s   313857.0  keydown\n",
      "95       e   313982.0  keydown\n",
      "96       s   314027.0    keyup\n",
      "97       e   314106.0    keyup\n",
      "98       v   314294.0  keydown\n",
      "99       v   314403.0    keyup\n",
      "100      e   314527.0  keydown\n",
      "101      r   314638.0  keydown\n",
      "102      e   314685.0    keyup\n",
      "103      r   314794.0    keyup\n",
      "104      a   314825.0  keydown\n",
      "105      a   314982.0    keyup\n",
      "106      l   314996.0  keydown\n",
      "107      l   315153.0    keyup\n",
      "108          315497.0  keydown\n",
      "109          315591.0    keyup\n",
      "110      f   316372.0  keydown\n",
      "111      f   316450.0    keyup\n",
      "112      e   316622.0  keydown\n",
      "113      e   316700.0    keyup\n",
      "114      e   316809.0  keydown\n",
      "115      t   317013.0  keydown\n",
      "116      e   317060.0    keyup\n",
      "117      t   317121.0    keyup\n",
      "118          317247.0  keydown\n",
      "119          317325.0    keyup\n",
      "120      t   317513.0  keydown\n",
      "121      t   317621.0    keyup\n",
      "122      h   317732.0  keydown\n",
      "123      h   317888.0    keyup\n",
      "124      i   317935.0  keydown\n",
      "125      i   318060.0    keyup\n",
      "126      c   318310.0  keydown\n",
      "127      c   318449.0    keyup\n",
      "128      k   318810.0  keydown\n",
      "129      k   318902.0    keyup\n",
      "130      ,   319700.0  keydown\n",
      "131      ,   319825.0    keyup\n",
      "132          321840.0  keydown\n",
      "133          321965.0    keyup\n",
      "134      a   322247.0  keydown\n",
      "135      a   322403.0    keyup\n",
      "136      n   322669.0  keydown\n",
      "137      n   322811.0    keyup\n",
      "138      d   322857.0  keydown\n",
      "139      d   322966.0    keyup\n",
      "140      s   323543.0  keydown\n",
      "141      s   323715.0    keyup\n",
      "142      €   323763.0  keydown\n",
      "143      €   325699.0    keyup\n",
      "144          326232.0  keydown\n",
      "145          326356.0    keyup\n",
      "146      s   326965.0  keydown\n",
      "147      s   327091.0    keyup\n",
      "148      u   327872.0  keydown\n",
      "149      u   327997.0    keyup\n",
      "150      r   328092.0  keydown\n",
      "151      r   328169.0    keyup\n",
      "152      r   328247.0  keydown\n",
      "153      r   328372.0    keyup\n",
      "154      o   328435.0  keydown\n",
      "155      u   328559.0  keydown\n",
      "156      u   328653.0    keyup\n",
      "157      o   328700.0    keyup\n",
      "158      n   328841.0  keydown\n",
      "159      n   328997.0    keyup\n",
      "160      d   329012.0  keydown\n",
      "161      e   329045.0  keydown\n",
      "162      d   329091.0    keyup\n",
      "163      d   329263.0  keydown\n",
      "164      e   329324.0    keyup\n",
      "165      d   329418.0    keyup\n",
      "166          329732.0  keydown\n",
      "167          329841.0    keyup\n",
      "168      b   330638.0  keydown\n",
      "169      b   330857.0    keyup\n",
      "170      y   330966.0  keydown\n",
      "171      y   331122.0    keyup\n",
      "172          331310.0  keydown\n",
      "173          331450.0    keyup\n",
      "174      a   331668.0  keydown\n",
      "175      a   331732.0    keyup\n",
      "176          332091.0  keydown\n",
      "177          332168.0    keyup\n",
      "178      c   332685.0  keydown\n",
      "179      c   332825.0    keyup\n",
      "180      a   332919.0  keydown\n",
      "181      a   333169.0    keyup\n",
      "182      g   333184.0  keydown\n",
      "183      e   333309.0  keydown\n",
      "184      g   333403.0    keyup\n",
      "185      e   333450.0    keyup\n",
      "186      ,   333902.0  keydown\n",
      "187      ,   334074.0    keyup\n",
      "188          334450.0  keydown\n",
      "189          334560.0    keyup\n",
      "190      a   335200.0  keydown\n",
      "191      a   335341.0    keyup\n",
      "192      n   335997.0  keydown\n",
      "193      n   336185.0    keyup\n",
      "194      d   336199.0  keydown\n",
      "195      d   336309.0    keyup\n",
      "196          336606.0  keydown\n",
      "197          336731.0    keyup\n",
      "198      b   338919.0  keydown\n",
      "199      b   339027.0    keyup\n",
      "200      u   339199.0  keydown\n",
      "201      u   339278.0    keyup\n",
      "202      r   339294.0  keydown\n",
      "203      r   339357.0    keyup\n",
      "204      i   339513.0  keydown\n",
      "205      i   339654.0    keyup\n",
      "206      e   339778.0  keydown\n",
      "207      e   339903.0    keyup\n",
      "208      d   340325.0  keydown\n",
      "209      d   340449.0    keyup\n",
      "210          340527.0  keydown\n",
      "211          340669.0    keyup\n",
      "212      b   340857.0  keydown\n",
      "213      b   340982.0    keyup\n",
      "214      e   341027.0  keydown\n",
      "215      e   341138.0    keyup\n",
      "216      n   341184.0  keydown\n",
      "217      e   341310.0  keydown\n",
      "218      n   341325.0    keyup\n",
      "219      e   341435.0    keyup\n",
      "220      a   341544.0  keydown\n",
      "221      t   341810.0  keydown\n",
      "222      a   341857.0    keyup\n",
      "223      h   341950.0  keydown\n",
      "224      t   341965.0    keyup\n",
      "225      h   342168.0    keyup\n",
      "226          342340.0  keydown\n",
      "227          342418.0    keyup\n",
      "228      a   342810.0  keydown\n",
      "229      a   342935.0    keyup\n",
      "230          343215.0  keydown\n",
      "231          343278.0    keyup\n",
      "232      r   343981.0  keydown\n",
      "233      r   344091.0    keyup\n",
      "234      o   344153.0  keydown\n",
      "235      o   344278.0    keyup\n",
      "236      c   344402.0  keydown\n",
      "237      c   344528.0    keyup\n",
      "238      k   344747.0  keydown\n",
      "239      k   344997.0    keyup\n",
      "240          346075.0  keydown\n",
      "241          346153.0    keyup\n",
      "242      s   346496.0  keydown\n",
      "243      s   346607.0    keyup\n",
      "244      l   346825.0  keydown\n",
      "245      a   346966.0  keydown\n",
      "246      l   346982.0    keyup\n",
      "247      a   347106.0    keyup\n",
      "248      b   347247.0  keydown\n",
      "249      b   347388.0    keyup\n",
      "250      £   347778.0  keydown\n",
      "251      £   347873.0    keyup\n"
     ]
    }
   ],
   "source": [
    "backspace_implementer_mrc(test_df)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backspace_implementer_mrc(df: pd.DataFrame, char=\"backspace\", test=False):\n",
    "#     \"\"\"\n",
    "#     Logic:\n",
    "#     1. Drop (remove rows) all backspace+keyup \n",
    "#     2. For all the remaining backspaces, remove its index and the preceeding two indices.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 1) Delete all backspace+keyups to start with\n",
    "#     idxs_up = df.index[(df.key == char) & (df.type == \"keyup\")].tolist()\n",
    "#     # In-place droppping of these rows\n",
    "#     df.drop(df.index[idxs_up], inplace=True)\n",
    "#     # Reset index so that we can sort it properly in the next step\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     # 2) Find all remaining backspace+keydowns\n",
    "#     idxs = df.index[(df.key == char) & (df.type == \"keydown\")].tolist()\n",
    "#     contiguous_groups = []\n",
    "#     for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "#         contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "#     indices_to_remove = []\n",
    "#     if len(idxs) != 0:\n",
    "#         for g in contiguous_groups:\n",
    "            \n",
    "#             if len(g) == 1:\n",
    "#                 # We do it this way because: because we want to capture this error slips\n",
    "#                 # Replace backspace character with indicator character\n",
    "#                 df.loc[g[0],\"key\"] = '€'\n",
    "            \n",
    "#             else:\n",
    "#                 # We invoke all backspaces except the first one.\n",
    "#                 indices_to_remove.extend(range_extend_mrc(g)[2:-1])\n",
    "                \n",
    "#         if test is False:\n",
    "            \n",
    "#             # Filter out negative indices which are non-sensical for deletion \n",
    "#             # (arises when more backspaces than characters in beginning of sentence)\n",
    "#             indices_to_remove = list(filter(lambda x: x >= 0, indices_to_remove))\n",
    "            \n",
    "# #             print(idxs_up)\n",
    "# #             print(contiguous_groups)\n",
    "# #             print(indices_to_remove)\n",
    "            \n",
    "#             # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "#             df.drop(df.index[indices_to_remove], inplace=True)\n",
    "            \n",
    "#             # Reset index so that we can sort it properly in the next step\n",
    "#             df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "#             assert \"€\" not in df.key.tolist()\n",
    "            \n",
    "#             # Replace remaining backspace with indicator characters        \n",
    "#             if char in df.key.tolist():\n",
    "#                 df.loc[df.key == char, 'key'] = '€'\n",
    "            \n",
    "#         else:\n",
    "#             print(\"Indices to remove: {}\".format(indices_to_remove))\n",
    "            \n",
    "# def range_extend(x):\n",
    "#     # Need to assert that this is given a sequentially ordered array\n",
    "#     return list(np.array(x) - len(x)) + x\n",
    "\n",
    "# def range_extend_mrc(x):\n",
    "#     # Need to assert that this is given a sequentially ordered array\n",
    "#     out = list(range(x[0]-2*len(x),x[0]-len(x))) + list(range(x[0]-len(x),x[0])) + x\n",
    "#     assert np.diff(out).sum() == len(out) - 1\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_extend(x):\n",
    "    # Need to assert that this is given a sequentially ordered array\n",
    "    return list(np.array(x) - len(x)) + x\n",
    "\n",
    "def range_extend_mrc(x):\n",
    "    # Need to assert that this is given a sequentially ordered array\n",
    "    out = list(range(x[0]-2*len(x),x[0]-len(x))) + list(range(x[0]-len(x),x[0])) + x\n",
    "    assert np.diff(out).sum() == len(out) - 1\n",
    "    return out\n",
    "\n",
    "def non_increasing(L):\n",
    "    return all(x>=y for x, y in zip(L, L[1:]))\n",
    "\n",
    "def non_decreasing(L):\n",
    "    return all(x<=y for x, y in zip(L, L[1:]))\n",
    "\n",
    "def monotonic(L):\n",
    "    return non_increasing(L) or non_decreasing(L)\n",
    "\n",
    "def backspace_implementer_mrc(df: pd.DataFrame, \n",
    "                              char=\"backspace\"):\n",
    "    \"\"\"\n",
    "    Logic:\n",
    "    1. Drop (remove rows) all backspace+keyup \n",
    "    2. For all the remaining backspaces, remove its index and the preceeding two indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems\n",
    "    idxs = df.index[(df.key == 'backspace')].tolist()\n",
    "    groups = []\n",
    "    remove = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "    # Only remove ones which are actually only of list length 1\n",
    "    for g in groups:\n",
    "        # Data-reading error\n",
    "        if len(g) == 1:\n",
    "            remove.extend(g)\n",
    "        # We replace these inline so we don't have to do it later\n",
    "        elif len(g) == 2:\n",
    "            # Place indicators [keydown]\n",
    "            df.loc[g[0],\"key\"] = '€' \n",
    "            # Place indicators [keyup]\n",
    "            df.loc[g[1],\"key\"] = '€' \n",
    "            \n",
    "    if remove: \n",
    "        # In-place droppping of rows with only one backspace\n",
    "        df.drop(df.index[remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 1) Delete all backspace+keyups to start with\n",
    "    idxs_up = df.index[(df.key == char) & (df.type == \"keyup\")].tolist()\n",
    "    # Copy these rows for later use\n",
    "    df_keyup = copy.copy(df.iloc[idxs_up])\n",
    "    # In-place dropping of these rows\n",
    "    df.drop(df.index[idxs_up], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 2) Find all remaining backspace+keydowns\n",
    "    idxs = df.index[(df.key == char) & (df.type == \"keydown\")].tolist()\n",
    "    contiguous_groups = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    indices_to_remove = []\n",
    "    if idxs:\n",
    "        for g in contiguous_groups:\n",
    "                            \n",
    "            gg = range_extend_mrc(g)\n",
    "            # If any negative indices, correct and move indicator characters\n",
    "            if any(i < 0 for i in gg):\n",
    "                gg = list(filter(lambda x: x >= 0, gg))\n",
    "                indices_to_remove.extend(gg[1:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0],\"key\"] = '€'\n",
    "            else:\n",
    "                indices_to_remove.extend(gg[3:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[2],\"key\"] = '€'\n",
    "                                         \n",
    "            # Place indicators [keyup]\n",
    "            # Given a value of keydown timestamp (z), select a row in the keyup df \n",
    "            # where timestamp is closest to z.\n",
    "            keyup_timestamp = df_keyup.loc[(df_keyup['timestamp'] >= df.loc[gg[-1],'timestamp'])].timestamp.values[0]\n",
    "            df.loc[gg[-1],(\"key\",\"timestamp\",\"type\")] = ['€', keyup_timestamp,'keyup']\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "          \n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Check that the indicators appear in the right places\n",
    "        indicator_indices = df.index[(df.key == \"€\")].tolist()\n",
    "        for pair in list(zip(indicator_indices, indicator_indices[1:]))[::2]:\n",
    "            assert pair[1] - pair[0] == 1, indicator_indices\n",
    "        assert \"backspace\" not in df.key.tolist()           \n",
    "        \n",
    "        #  Need to think a bit about these conditions as we are just looking at the absolute difference\n",
    "#         assert monotonic(df.timestamp.tolist()), df[(df.key == '€')].timestamp.tolist()\n",
    "#         assert any(i > 0 for i in df.timestamp.diff())\n",
    "#         assert not any(t <= 0 for t in df.timestamp.diff()), print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backspace_implementer_mrc(df: pd.DataFrame, char=\"backspace\", test=False):\n",
    "#     \"\"\"\n",
    "#     Logic:\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Find all backspaces\n",
    "#     idxs = df.index[(df.key == char)].tolist()\n",
    "#     contiguous_groups = []\n",
    "#     for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "#         contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "#     indices_to_remove = []\n",
    "#     if len(idxs) != 0:\n",
    "#         for g in contiguous_groups:\n",
    "            \n",
    "#             if len(g) == 1:\n",
    "                \n",
    "#                 # If we find a group of length one, then we delete it\n",
    "#                 # because it means there is a data-reading error\n",
    "#                 indices_to_remove.extend(g)\n",
    "                \n",
    "#             else:\n",
    "            \n",
    "#                 # Extract only the backspace+keyup at this group \n",
    "#                 idxs_up = df.iloc[g,:].index[df.iloc[g,:].type == \"keyup\"].tolist()\n",
    "#                 # Drop all but the last keyup, as that will be used as an indicator\n",
    "#                 df.drop(df.index[idxs_up[:-1]], inplace=True)\n",
    "#                 # Replace with indicator key [UPPER BOUND]\n",
    "#                 df.iloc[idxs_up[-1],\"key\"] = '€'\n",
    "#                 # Reset index so that we can sort it properly in the next step\n",
    "#                 df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#                 if len(g) == 1:\n",
    "#                     # If we find a group of length one, then we delete it\n",
    "#                     indices_to_remove.extend(g)\n",
    "\n",
    "#                 if len(g) == 2:\n",
    "#                     # If we find a group of length one, then we delete it\n",
    "#                     raise ValueError\n",
    "\n",
    "#                 else:\n",
    "#                     # We invoke all backspaces except the first one and the last\n",
    "#                     gg = range_extend_mrc(g)\n",
    "#     #                 print(gg)\n",
    "#                     indices_to_remove.extend(gg[3:-1])\n",
    "#                     # Replace with indicator keys\n",
    "#     #                 df.iloc[gg[0],\"key\"] = '€'\n",
    "#     #                 df.iloc[gg[-1],\"key\"] = '€'\n",
    "                \n",
    "#         if test is False:\n",
    "            \n",
    "#             # Filter out negative indices which are non-sensical for deletion \n",
    "#             # (arises when more backspaces than characters in beginning of sentence)\n",
    "#             indices_to_remove = list(filter(lambda x: x >= 0, indices_to_remove))\n",
    "            \n",
    "#             print(contiguous_groups)\n",
    "#             print(indices_to_remove)\n",
    "            \n",
    "#             # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "#             df.drop(df.index[indices_to_remove], inplace=True)\n",
    "# #             print(df)\n",
    "#             # Reset index so that we can sort it properly in the next step\n",
    "#             df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "#             # Replace remaining backspace with indicator characters        \n",
    "# #             if char in df.key.tolist():\n",
    "# #                 df.loc[df.key == char, 'key'] = '€'\n",
    "                \n",
    "#             assert \"backspace\" not in df.key.tolist()\n",
    "            \n",
    "#         else:\n",
    "#             print(\"Indices to remove: {}\".format(indices_to_remove))\n",
    "            \n",
    "# def range_extend(x):\n",
    "#     # Need to assert that this is given a sequentially ordered array\n",
    "#     return list(np.array(x) - len(x)) + x\n",
    "\n",
    "# def range_extend_mrc(x):\n",
    "#     # Need to assert that this is given a sequentially ordered array\n",
    "#     out = list(range(x[0]-len(x),x[0])) + x\n",
    "#     assert np.diff(out).sum() == len(out) - 1\n",
    "#     return out\n",
    "\n",
    "# # def range_extend_mrc(x):\n",
    "# #     # Need to assert that this is given a sequentially ordered array\n",
    "# #     out = list(range(x[0]-2*len(x),x[0]-len(x))) + list(range(x[0]-len(x),x[0])) + x\n",
    "# #     assert np.diff(out).sum() == len(out) - 1\n",
    "# #     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_solitary_key_presses(df):\n",
    "    \"\"\"\n",
    "    Three requirements for this function:\n",
    "\n",
    "    1. It has to be run \"last\"\n",
    "    2. backspace removal has to happen beforehand\n",
    "    3. The dataframe has to have been sorted prior to running this function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : [type]\n",
    "        [description]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [type]\n",
    "        [description]\n",
    "    \"\"\"\n",
    "\n",
    "    suspect_keys = []\n",
    "    for key, value in Counter(df.key.tolist()).items():\n",
    "        if value % 2 != 0:\n",
    "            # Find all keys which appear an unequal number of times\n",
    "            suspect_keys.append(key)\n",
    "\n",
    "    # Do not remove \"correction identifier key\" i.e. €\n",
    "    suspect_keys = [key for key in suspect_keys if key not in {\"€\"}]\n",
    "\n",
    "    # Find all instances of suspect keys in df\n",
    "    if len(suspect_keys) != 0:\n",
    "        indices_to_keep = []\n",
    "        all_idxs = []\n",
    "        for key in suspect_keys:\n",
    "            idxs = df.loc[df.key == key].index\n",
    "            all_idxs.extend(idxs)\n",
    "            # If there is more than one such key\n",
    "            for pair in list(zip(idxs, idxs[1:]))[::2]:\n",
    "                if pair[1] - pair[0] == 1:\n",
    "                    indices_to_keep.extend(pair)\n",
    "\n",
    "        # Take set difference to find what's left\n",
    "        indices_to_remove = list(set(all_idxs) - set(indices_to_keep))\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def new_sort(df):\n",
    "        \n",
    "    df_2 = pd.DataFrame(columns=[\"key\", \"timestamp\", \"type\"])\n",
    "    indexes = []\n",
    "    for i in range(len(df)):\n",
    "        if i not in indexes:\n",
    "            df_2 = df_2.append(df.loc[i,:])\n",
    "            letter = df.loc[i,\"key\"]\n",
    "            indexes.append(i)\n",
    "\n",
    "            for j in range(i+1, len(df)):\n",
    "                if ((df.loc[j,\"key\"] == df.loc[i,\"key\"]) and (j not in indexes)):\n",
    "\n",
    "                    df_2 = df_2.append( df.loc[j,:])\n",
    "                    indexes.append(j)\n",
    "                    break;\n",
    "                    \n",
    "    return df_2.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "def test_repeating_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    pat_len = len(pattern)\n",
    "    assert \"keydown\" == lst[0], \"keydown does not start the list: {}\".format(lst[0])\n",
    "    assert len(lst) % pat_len == 0, \"mismatched length of list\"\n",
    "    assert list(pattern) * (len(lst) // pat_len) == lst, \"the list does not follow the correct pattern\"\n",
    "    \n",
    "def assess_repeating_key_compression_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    \n",
    "    assert set(pattern).issubset(set(lst))\n",
    "    pat_len = len(pattern)\n",
    "    if (\"keydown\" == lst[0]) and (len(lst) % pat_len == 0) and (list(pattern) * (len(lst) // pat_len) == lst):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def combine_contiguous_shift_keydowns_without_matching_keyup(df):\n",
    "    \"\"\"\n",
    "    Function assumes that df has been sorted before getting this far.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the index of all shift keydowns (these are the ones causing the registration problems)\n",
    "    idxs_down = df.index[(df[\"key\"] == \"shift\") & (df[\"type\"] == \"keydown\")].tolist()\n",
    "\n",
    "    # Locate all contiguous sub-sequences\n",
    "    keydown_groups = []\n",
    "    for k, g in groupby(enumerate(idxs_down), lambda ix: ix[0] - ix[1]):\n",
    "        keydown_groups.append(list(map(itemgetter(1), g)))\n",
    "\n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_keydown_coordinates = []\n",
    "    for g in keydown_groups:\n",
    "        # Contiguous groups of shifts\n",
    "        if len(g) > 1:\n",
    "            ii = None\n",
    "            for j in range(1, 6):\n",
    "                if (df.loc[g[-1] + j, \"type\"] == \"keyup\") and (df.loc[g[-1] + j, \"key\"] == \"shift\"):\n",
    "                    ii = j\n",
    "            if ii:\n",
    "                # Do this if the immediate key after each group is a \"keyup\"\n",
    "                removal_keydown_coordinates.extend(g[1:])\n",
    "            else:\n",
    "                # Do this if there is no immediately preceeding \"keyup\"\n",
    "                removal_keydown_coordinates.extend(g)\n",
    "\n",
    "    #     print(keydown_groups,\"\\n\")\n",
    "    #     print(removal_keydown_coordinates)\n",
    "\n",
    "    # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "    df.drop(df.index[removal_keydown_coordinates], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "def remove_superfluous_shifts(df):\n",
    "    \n",
    "    ### NOTE the backspace operator has to appear before this\n",
    "    \n",
    "    idxs = df.index[df['key'] == 'shift'].tolist()\n",
    "    \n",
    "    # Locate a contiguous sub-sequence at the start of the sentence\n",
    "    shift_groups = []\n",
    "    for k, g in groupby(enumerate(idxs), lambda ix: ix[0] - ix[1]):\n",
    "        shift_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_shift_coordinates = []\n",
    "    for g in shift_groups:\n",
    "        if set(g) == 'keydown' or set(g) == 'keydown':\n",
    "            removal_shift_coordinates.append(g[:-1])\n",
    "            \n",
    "    \n",
    "        \n",
    "    if len(shift_groups[0]) > 2 and df.type[shift_groups[0][-1]] == 'keyup' and df.type[shift_groups[0][-2]] == 'keydown':\n",
    "        # Coordinates to remove\n",
    "        df.drop(df.index[shift_groups[0][:-2]], inplace=True)\n",
    "        \n",
    "    # Shifts should only ever appear as contiguous pairs\n",
    "    if not all([len(x) == 2 for x in shift_groups[1:]]): \n",
    "        print(\"Other shift combinations are also longer than they should be.\\n\")\n",
    "        print(shift_groups)\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
