{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "\n",
    "from haberrspd.preprocess import preprocessMJFF\n",
    "                         \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from scipy.stats import (gamma, lognorm, gengamma)\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Plot stuff\n",
    "import seaborn as sns\n",
    "from scipy.constants import golden\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Depending on where I am, set the path\n",
    "import socket\n",
    "if socket.gethostname() == 'pax':\n",
    "    # Monster machine\n",
    "    data_root = '../data/MJFF/' # My local path\n",
    "    data_root = Path(data_root)\n",
    "else:\n",
    "    # Laptop\n",
    "    data_root = '/home/nd/data/liverpool/MJFF' # My local path\n",
    "    data_root = Path(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character + Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/SpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_root / 'SpanishData-duplicateeventsremoved.csv')\n",
    "df = pd.read_csv(data_root / 'SpanishData.csv')\n",
    "df_meta = pd.read_csv(data_root / \"SpanishParticipantKey.csv\",\n",
    "                      index_col=0,\n",
    "                      header=0,\n",
    "                      names=['participant_id', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character ONLY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english',include_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/char/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = set(df_meta.loc[df_meta.diagnosis == 0].participant_id)\n",
    "pd_subjects = set(df_meta.loc[df_meta.diagnosis == 1].participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in pd_subjects:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    pd_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)\n",
    "    \n",
    "control_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in controls:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    control_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs\n",
    "pd_cleaned_list = [x for x in pd_timestamp_diffs if str(x) != 'nan']\n",
    "control_cleaned_list = [x for x in control_timestamp_diffs if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(pd_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(control_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical turk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(data_root /'preprocessed_MechanicalTurkCombinedEnglishData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/MJFF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IKI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_mjff_iki_training_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_mjff_data_objects, us_standard_layout_keyboard, english_keys_to_2d_coordinates\n",
    "import keras.backend as K\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, int64, ones, hstack, pad, einsum, dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import cast, float32, one_hot\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time_space\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "if which_information == \"char_time_space\":\n",
    "    # Get relevant long-format data\n",
    "    which_information = \"char_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "\n",
    "# Store alphabet size\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "print('Total number of characters:', alphabet_size)\n",
    "alphabet_indices = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "if which_information == \"char_time\" or which_information == \"char_time_space\":\n",
    "    # Rounds (up) to nearest thousand\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -3)\n",
    "if which_information == \"char\":\n",
    "    # Rounds (up) to nearest hundred\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -2)\n",
    "\n",
    "# Make training data array\n",
    "all_sentences = [item for sublist in subject_documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer which maps characters to integers\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "\n",
    "# Fit to text: convert all chars to ints\n",
    "tk.fit_on_texts(all_sentences)\n",
    "\n",
    "# Update alphabet\n",
    "tk.word_index = alphabet_indices\n",
    "\n",
    "# Get integer sequences: converts sequences of chars to sequences of ints\n",
    "int_sequences = tk.texts_to_sequences(all_sentences)\n",
    "\n",
    "# Pad sequences so that they all have the same length and then one-hot encode\n",
    "X = to_categorical(pad_sequences(int_sequences, maxlen=max_sentence_length, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information  =  'char_time_space'\n",
    "if which_information == 'char_time_space':\n",
    "    # Load relevant keyboard\n",
    "    keyboard = us_standard_layout_keyboard()  # OBS: nested list\n",
    "    # Check that all chars are in fact in our \"keyboard\" -- if not, we cannot map a coordinate\n",
    "    assert alphabet.issubset(set(list(itertools.chain.from_iterable(keyboard))))\n",
    "    space = [english_keys_to_2d_coordinates(sentence, keyboard) for sentence in all_sentences]\n",
    "    space_padded = [pad(s, [(0, max_sentence_length - len(s)), (0, 0)], mode='constant') for s in space]\n",
    "    # Append coordinates to one-hot encoded sentences\n",
    "    X = einsum('ijk->kij', dstack([hstack((x, s)) for (x, s) in zip(X, space_padded)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document (participant) -level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three options (at time of writing):\n",
    "\n",
    "1. Submit each sentence to model and extract classification probability for each sentence, agglomorate at the end, and the conduct a classification on the vector of all 15 probabilities.\n",
    "2. Calculate the expected value of all encoded (15) sentences and then pass this to the model and take the classification.\n",
    "3. Vertically stack all embedded sentences, and let the convolution run over this (very long) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_training_data_keras, create_mjff_data_objects\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "# subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "# X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(DATA_ROOT, which_information, data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in subject_documents[:3]:\n",
    "    print(doc[:2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Homogenise so that Spacebar is a blank character\n",
    "0. Delete rubbish characters (i.e. remove the rows)\n",
    "2. What to do with stuff like Shift\n",
    "3. Figure out what to do when multiple characters are depressed simultaneously\n",
    "4. Make lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from haberrspd.preprocess import (clean_mrc,\n",
    "                                  create_sentences_from_raw_typing_mrc,\n",
    "                                  backspace_corrector, \n",
    "                                  flatten,\n",
    "                                  calculate_edit_distance_between_response_and_target_MRC)\n",
    "from haberrspd.charCNN.data_utils_tf import us_english_keyboard_mrc\n",
    "from numpy import concatenate\n",
    "from typing import Tuple\n",
    "import random\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from itertools import compress, count, groupby\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "# Monster machine\n",
    "data_root = '../data/MRC/' # My local path\n",
    "data_root = Path(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_root / \"CombinedTypingDataSept27.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (814388, 12)\n",
      "Size of dataframe after row pruning: (812330, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (812330, 12)\n",
      "Size of dataframe after row pruning: (780201, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>β</td>\n",
       "      <td>keydown</td>\n",
       "      <td>1</td>\n",
       "      <td>25885.055</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26086.840</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>β</td>\n",
       "      <td>keyup</td>\n",
       "      <td>1</td>\n",
       "      <td>26181.975</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>keyup</td>\n",
       "      <td>0</td>\n",
       "      <td>26193.745</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26321.480</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key     type  location  timestamp  participant_id  sentence_id  diagnosis\n",
       "0   β  keydown         1  25885.055            1010            1          0\n",
       "1   h  keydown         0  26086.840            1010            1          0\n",
       "2   β    keyup         1  26181.975            1010            1          0\n",
       "3   h    keyup         0  26193.745            1010            1          0\n",
       "4   o  keydown         0  26321.480            1010            1          0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clean_mrc(df)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.copy(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_pickle(data_root / 'processed_mcr.pkl')\n",
    "# df = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol to process the MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A form of `create_char_compression_time_mjff_data` [to get the temporal data] <-- this needs to be set so that we get a list of \n",
    "2. Second use `create_dataframe_from_processed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.preprocess import (combine_contiguous_shift_keydowns_without_matching_keyup, \n",
    "                                  assess_repeating_key_compression_pattern, \n",
    "                                  make_character_compression_time_sentence_mrc)\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_from_raw_typing_mrc(df: pd.DataFrame, \n",
    "                                          make_long_format=True,\n",
    "                                          time_redux_fact=10) -> Tuple[dict, list]:\n",
    "\n",
    "    fail = 0\n",
    "    success = 0\n",
    "    corrected_sentences = defaultdict(dict)\n",
    "    broken_sentences = defaultdict(dict)\n",
    "    char_compression_sentences = defaultdict(dict)\n",
    "    for subj_idx in df.participant_id.unique():\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        print(\"\\t>>>This is subject: %i.\" % subj_idx)\n",
    "        for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "            print(sent_idx, end=\" \")\n",
    "            \n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "\n",
    "            # Store temporary dataframe because why not\n",
    "            tmp_df = df.loc[coordinates, (\"key\", \"timestamp\", \"type\")].reset_index(drop=True).copy()  # Reset index\n",
    "\n",
    "            # Action order:\n",
    "            #     0. Sort dataset\n",
    "            #     1. Implement backspaces\n",
    "            #     2. Remove contiguous shifts\n",
    "            #     3. Remove solitary keys\n",
    "\n",
    "            # Get correctly ordered sentences and total compression times\n",
    "            tmp_df = move_keys_to_temporal_monotonically_increasing_order(tmp_df)\n",
    "\n",
    "            # Method to 'implement' the users' backspace actions\n",
    "            backspace_implementer_mrc(tmp_df)\n",
    "\n",
    "            # Removes contiguous shift presses\n",
    "            combine_contiguous_shift_keydowns_without_matching_keyup(tmp_df)\n",
    "\n",
    "            # Remove solitary key-presses which do not have a matching keyup or keydown\n",
    "            # TODO: not sure if we need this.\n",
    "            remove_solitary_key_presses(tmp_df)\n",
    "\n",
    "            # Check what we managed to achieve\n",
    "            if assess_repeating_key_compression_pattern(tmp_df.type.tolist()):\n",
    "\n",
    "                # Condition succeeds: data-collection is fixed\n",
    "                corrected_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                success += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Condition fails: data-collection is broken\n",
    "                broken_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                fail += 1\n",
    "                print(\"[broken sentence] Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "                \n",
    "        print()\n",
    "\n",
    "#     for subj_idx in corrected_sentences.keys():\n",
    "#         # Not all subjects have typed all sentences hence we have to do it this way\n",
    "#         for sent_idx in corrected_sentences[subj_idx].keys():\n",
    "#             if make_long_format:\n",
    "#                 # Final long-format sentences stored here\n",
    "#                 char_compression_sentences[subj_idx][sent_idx] = \"\".join(\n",
    "#                     make_character_compression_time_sentence_mrc(\n",
    "#                         corrected_sentences[subj_idx][sent_idx], time_redux_fact=time_redux_fact\n",
    "#                     )\n",
    "#                 )\n",
    "#             else:\n",
    "#                 # We do not use the time-dimension and look only at the spatial component\n",
    "#                 # Final long-format sentences stored here\n",
    "#                 char_compression_sentences[subj_idx][sent_idx] = \"\".join(\n",
    "#                     corrected_sentences[subj_idx][sent_idx].key[::2]\n",
    "#                 )  # [::2] takes into account that we only want one of the keydown-keyup pair.\n",
    "\n",
    "    print(\"Percentage failed: {}\".format(round(100 * (fail / (success + fail)), 2)))\n",
    "    print(fail, success)\n",
    "\n",
    "    return char_compression_sentences, broken_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>>>This is subject: 1010.\n",
      "1 2 5 [broken sentence] Participant: 1010, Sentence: 5\n",
      "3 4 6 [broken sentence] Participant: 1010, Sentence: 6\n",
      "7 8 9 [broken sentence] Participant: 1010, Sentence: 9\n",
      "10 11 [broken sentence] Participant: 1010, Sentence: 11\n",
      "12 [broken sentence] Participant: 1010, Sentence: 12\n",
      "13 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-336-d6275dec5d29>\", line 34, in backspace_implementer_mrc\n",
      "    keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[broken sentence] Participant: 1010, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1011.\n",
      "1 > <ipython-input-336-d6275dec5d29>(34)backspace_implementer_mrc()\n",
      "-> keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  gg[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup['timestamp']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    44551.58\n",
      "37    44916.99\n",
      "Name: timestamp, dtype: float64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  gg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 29, 30, 31, 32, 33, 34, 35, 36]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 35, 36]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key  timestamp   type\n",
      "35   α   44551.58  keyup\n",
      "37   α   44916.99  keyup\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  contiguous_groups\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34, 35, 36]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df.loc[gg[-1]].timestamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52545.5850000726\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52545.5850000726\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([], dtype=float64)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([], dtype=float64)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [key, timestamp, type]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.timestamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    44551.58\n",
      "37    44916.99\n",
      "Name: timestamp, dtype: float64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    44551.58\n",
      "37    44916.99\n",
      "Name: timestamp, dtype: float64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.timestamp[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyError: -1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyError: -1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  df_keyup.timestamp.values[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44916.9900000561\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit()\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'keyup_timestamp' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-60ce327acb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sentences_from_raw_typing_mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-337-cfa8d0566a8f>\u001b[0m in \u001b[0;36mcreate_sentences_from_raw_typing_mrc\u001b[0;34m(df, make_long_format, time_redux_fact)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Method to 'implement' the users' backspace actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mbackspace_implementer_mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Removes contiguous shift presses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-336-d6275dec5d29>\u001b[0m in \u001b[0;36mbackspace_implementer_mrc\u001b[0;34m(df, backspace_char)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Assign the keyup indicator with the correct timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"€\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyup_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keyup\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# In-place operation, no need to return anything. Cannot reset index at this point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'keyup_timestamp' referenced before assignment"
     ]
    }
   ],
   "source": [
    "new = create_sentences_from_raw_typing_mrc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the sorting mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.preprocess import remove_solitary_key_presses, range_extend_mrc\n",
    "from itertools import count \n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_solitary_key_presses(df, verbose=False):\n",
    "\n",
    "    suspect_keys = []\n",
    "    for key, value in Counter(df.key.tolist()).items():\n",
    "        if value % 2 != 0:\n",
    "            # Find all keys which appear an unequal number of times\n",
    "            suspect_keys.append(key)\n",
    "\n",
    "    # Do not remove \"correction identifier key\" i.e. €\n",
    "    suspect_keys = [key for key in suspect_keys if key not in {\"€\", \"α\"}]\n",
    "\n",
    "    if verbose:\n",
    "        print(suspect_keys)\n",
    "\n",
    "    # Find all instances of suspect keys in df\n",
    "    if len(suspect_keys) != 0:\n",
    "        indices_to_keep = []\n",
    "        all_idxs = []\n",
    "        for key in suspect_keys:\n",
    "            idxs = df.loc[df.key == key].index\n",
    "            all_idxs.extend(idxs)\n",
    "            # If there is more than one such key\n",
    "            for pair in list(zip(idxs, idxs[1:]))[::2]:\n",
    "                if pair[1] - pair[0] == 1:\n",
    "                    indices_to_keep.extend(pair)\n",
    "\n",
    "        # Take set difference to find what's left\n",
    "        indices_to_remove = list(set(all_idxs) - set(indices_to_keep))\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "def find_all_backspace_groups(df, backspace_char = \"α\"):\n",
    "    ids = df.index[(df.key == backspace_char)].tolist()\n",
    "    groups = []\n",
    "    for k, g in groupby(enumerate(sorted(ids)), lambda ix: ix[1] - ix[0]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def lookup(v, \n",
    "           d={}, \n",
    "           c=count()):\n",
    "    if v in d:\n",
    "        return d.pop(v)\n",
    "    else:\n",
    "        d[v] = next(c)\n",
    "    return d[v]\n",
    "\n",
    "\n",
    "def reorder_key_timestamp_columns_mrc(df: pd.DataFrame):\n",
    "    # Use lookup function to extract the next row-order\n",
    "    df[\"new_row_order\"] = df.key.map(lookup)\n",
    "    return df.sort_values(by=\"new_row_order\", kind=\"mergesort\").drop(\"new_row_order\", axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def move_keys_to_temporal_monotonically_increasing_order(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # 1. Remove singular characters [in-place operation]\n",
    "    remove_solitary_key_presses(df) # Does not operate on backspaces or indicators\n",
    "    \n",
    "    # 2. hide/mask blocks of backspaces and don't re-order these, and then insert them again after the re-order\n",
    "    blocks = [i for i in find_all_backspace_groups(df, \"α\") if len(i) > 2]\n",
    "    if len(blocks) != 0:\n",
    "        proper_sorted = []\n",
    "        if len(blocks) == 1:\n",
    "            proper_sorted.append(reorder_key_timestamp_columns_mrc(df.iloc[0:blocks[0][0]]))\n",
    "            proper_sorted.append(df.iloc[blocks[0]])\n",
    "            proper_sorted.append(reorder_key_timestamp_columns_mrc(df.iloc[blocks[0][-1]+1:]))\n",
    "        else:\n",
    "            i = 0\n",
    "            for block in blocks:\n",
    "                # Character blocks to be re-ordered\n",
    "                proper_sorted.append(reorder_key_timestamp_columns_mrc(df.iloc[i:block[0]]))\n",
    "                # Backspaces blocks to be left as is\n",
    "                proper_sorted.append(df.iloc[block])\n",
    "                # Store the coordinate of last index in the backspace block\n",
    "                i = block[-1]+1\n",
    "            # Append the text block\n",
    "            proper_sorted.append(reorder_key_timestamp_columns_mrc(df.iloc[i:]))\n",
    "            \n",
    "        # Recombine all blocks and return\n",
    "        return pd.concat(proper_sorted, ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        # No contiguous blocks, so sort as usual\n",
    "        return reorder_key_timestamp_columns_mrc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = move_to_strict_striped_type_order(tmp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(out)\n",
    "#     print(reorder_key_timestamp_columns_mrc_nb(tmp0.iloc[161:-2]))\n",
    "#     print(tmp0.iloc[160:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = df.loc[(df.participant_id == 1011) & (df.sentence_id == 1), (\"key\", \"timestamp\", \"type\")].reset_index(drop=True)  # Reset index\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(tmp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicate_single_and_double_backspaces(df):\n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems\n",
    "    remove = []\n",
    "    groups = find_all_backspace_groups(df)\n",
    "    \n",
    "    # Only remove ones which are actually only of list length 1\n",
    "    for g in groups:\n",
    "        # Data-reading error\n",
    "        if len(g) == 1:\n",
    "            remove.extend(g)\n",
    "        # We replace these inline so we don't have to do it later\n",
    "        elif len(g) == 2:\n",
    "            # Place indicators [keydown]\n",
    "            df.loc[g[0], \"key\"] = \"€\"\n",
    "            # Place indicators [keyup]\n",
    "            df.loc[g[1], \"key\"] = \"€\"\n",
    "            \n",
    "######### Neil [15/11/19] : we do not need this right now but will keep it anyway\n",
    "#         else:\n",
    "#             # This line checks if a backspace (keydown,keyup) is included in a contiguous sequence\n",
    "#             t = df.loc[g,'type'].tolist()\n",
    "#             for i, pair in enumerate(list(zip(t, t[1:]))):\n",
    "#                 if df.loc[g[i-1],'type'] != 'keydown':\n",
    "#                     if pair == ('keydown', 'keyup') or pair == ('keyup', 'keydown'):\n",
    "#                         # Place indicators [keydown]\n",
    "#                         df.loc[g[i], \"key\"] = \"€\"\n",
    "#                         # Place indicators [keyup]\n",
    "#                         df.loc[g[i+1], \"key\"] = \"€\"\n",
    "\n",
    "    if remove:\n",
    "        # In-place droppping of rows with only one backspace\n",
    "        df.drop(df.index[remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "def remove_backspace_keyup(df, backspace_char):\n",
    "    \n",
    "    idxs_up = df.index[(df.key == backspace_char) & (df.type == \"keyup\")].tolist()\n",
    "    # Copy these rows for later use\n",
    "    df_keyup = df.iloc[idxs_up].copy(deep=True)\n",
    "    # In-place dropping of these rows\n",
    "    df.drop(df.index[idxs_up], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_keyup\n",
    "\n",
    "def find_remaining_backspace_keydown(df, backspace_char):\n",
    "    \n",
    "    idxs = df.index[(df.key == backspace_char) & (df.type == \"keydown\")].tolist()\n",
    "    contiguous_groups = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    return contiguous_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backspace_implementer_mrc(df, backspace_char = \"α\"):\n",
    "    \n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems    \n",
    "    indicate_single_and_double_backspaces(df)\n",
    "        \n",
    "    # 1) Delete all backspace+keyups to start with    \n",
    "    df_keyup = remove_backspace_keyup(df, backspace_char)\n",
    "\n",
    "    # 2) Find all remaining backspace+keydowns\n",
    "    contiguous_groups = find_remaining_backspace_keydown(df, backspace_char)\n",
    "    indices_to_remove = []\n",
    "    if contiguous_groups:\n",
    "        for g in contiguous_groups:\n",
    "            \n",
    "            # Get indices to delete backwards\n",
    "            gg = range_extend_mrc(g)\n",
    "            \n",
    "            # If any negative indices, correct and move indicator characters\n",
    "            if any(i < 0 for i in gg):\n",
    "                gg = list(filter(lambda x: x >= 0, gg))\n",
    "                indices_to_remove.extend(gg[1:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0], [\"key\", \"type\"]] = [\"€\", \"keydown\"]\n",
    "            else:\n",
    "                indices_to_remove.extend(gg[1:-1]) # replaced [3:-1]\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0], [\"key\", \"type\"]] = [\"€\", \"keydown\"] # replaced gg[2] with gg[0]\n",
    "\n",
    "            # Place indicators [keyup]\n",
    "            # Assign the keyup indicator with the correct timestamp\n",
    "            df.loc[gg[-1], (\"key\", \"timestamp\", \"type\")] = [\"€\", \n",
    "                                                            \n",
    "                        #### THis is not correct as it includes _ALL_ backspace + keyups\n",
    "                            #### hence we're getting the max of the whole things, rather\n",
    "                        #### than specific max of backspace blocks\n",
    "                                                            \n",
    "                                                            df_keyup.timestamp.max(), \n",
    "                                                            \"keyup\"]\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Check that the indicators appear in the right places\n",
    "        indicator_indices = df.index[(df.key == \"€\")].tolist()\n",
    "        for pair in list(zip(indicator_indices, indicator_indices[1:]))[::2]:\n",
    "            assert pair[1] - pair[0] == 1, indicator_indices\n",
    "        assert backspace_char not in df.key.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[140, 141, 142, 143], [150, 151, 152]]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = tmp0.copy(deep=True)\n",
    "# te_df = move_keys_to_temporal_monotonically_increasing_order(test_df)\n",
    "# backspace_implementer_mrc(te_df)\n",
    "indicate_single_and_double_backspaces(test_df)\n",
    "df_keyup = remove_backspace_keyup(test_df, \"α\")\n",
    "find_remaining_backspace_keydown(test_df, \"α\")\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    key   timestamp     type\n",
      "0     β  162608.660  keydown\n",
      "1     g  162705.285  keydown\n",
      "2     g  162797.605    keyup\n",
      "3     β  162836.230    keyup\n",
      "4     e  162866.700  keydown\n",
      "5     n  162961.990  keydown\n",
      "6     e  162978.375    keyup\n",
      "7     e  163053.525  keydown\n",
      "8     n  163061.230    keyup\n",
      "9     r  163127.330  keydown\n",
      "10    e  163184.520    keyup\n",
      "11    a  163222.395  keydown\n",
      "12    r  163252.195    keyup\n",
      "13    l  163255.150  keydown\n",
      "14    a  163319.245    keyup\n",
      "15    l  163361.730    keyup\n",
      "16    l  163437.705  keydown\n",
      "17    l  163607.185    keyup\n",
      "18    y  163654.415  keydown\n",
      "19    y  163763.260    keyup\n",
      "20       163805.430  keydown\n",
      "21       163950.420    keyup\n",
      "22    c  163955.770  keydown\n",
      "23    o  164059.980  keydown\n",
      "24    c  164084.420    keyup\n",
      "25    n  164117.010  keydown\n",
      "26    o  164212.935    keyup\n",
      "27    s  164216.835  keydown\n",
      "28    n  164236.720    keyup\n",
      "29    s  164341.955    keyup\n",
      "30    i  164348.645  keydown\n",
      "31    d  164407.100  keydown\n",
      "32    i  164456.845    keyup\n",
      "33    d  164518.595    keyup\n",
      "34    e  164580.215  keydown\n",
      "35    r  164655.285  keydown\n",
      "36    e  164697.505    keyup\n",
      "37    e  164754.785  keydown\n",
      "38    r  164829.030    keyup\n",
      "39    e  164897.975    keyup\n",
      "40    d  164948.200  keydown\n",
      "41    d  165075.600    keyup\n",
      "42       165085.315  keydown\n",
      "43    a  165180.020  keydown\n",
      "44       165186.030    keyup\n",
      "45    a  165311.680    keyup\n",
      "46       165334.175  keydown\n",
      "47       165432.855    keyup\n",
      "48    p  165785.710  keydown\n",
      "49    a  165857.795  keydown\n",
      "50    p  165919.395    keyup\n",
      "51    r  165949.250  keydown\n",
      "52    a  166016.795    keyup\n",
      "53    r  166056.165    keyup\n",
      "54    t  166128.565  keydown\n",
      "55       166215.570  keydown\n",
      "56    t  166245.315    keyup\n",
      "57    o  166316.620  keydown\n",
      "58       166349.205    keyup\n",
      "59    f  166366.245  keydown\n",
      "60    o  166451.020    keyup\n",
      "61    f  166483.485    keyup\n",
      "62       166498.070  keydown\n",
      "63    β  166584.720  keydown\n",
      "64    c  166622.670  keydown\n",
      "65       166637.060    keyup\n",
      "66    c  166716.045    keyup\n",
      "67    e  166785.740  keydown\n",
      "68    β  166792.415    keyup\n",
      "69    n  166918.350  keydown\n",
      "70    e  166942.950    keyup\n",
      "71    t  167019.955  keydown\n",
      "72    n  167054.185    keyup\n",
      "73    t  167110.230    keyup\n",
      "74    r  167146.730  keydown\n",
      "75    r  167244.985    keyup\n",
      "76    a  167273.090  keydown\n",
      "77    l  167355.380  keydown\n",
      "78    l  167449.385    keyup\n",
      "79    a  167473.125    keyup\n",
      "80    γ  167744.450  keydown\n",
      "81    α  167808.595  keydown\n",
      "82    α  167933.550    keyup\n",
      "83    γ  168069.940    keyup\n",
      "84    β  168136.310  keydown\n",
      "85    c  168241.035  keydown\n",
      "86    β  168345.215    keyup\n",
      "87    c  168353.555    keyup\n",
      "88    e  168434.745  keydown\n",
      "89    n  168541.440  keydown\n",
      "90    e  168551.675    keyup\n",
      "91    n  168661.025    keyup\n",
      "92    t  168672.460  keydown\n",
      "93    t  168757.340    keyup\n",
      "94    r  168847.075  keydown\n",
      "95    a  168938.800  keydown\n",
      "96    r  168993.430    keyup\n",
      "97    l  169033.085  keydown\n",
      "98       169097.745  keydown\n",
      "99    a  169118.020    keyup\n",
      "100   l  169187.885    keyup\n",
      "101      169250.905    keyup\n",
      "102   a  169256.880  keydown\n",
      "103   a  169405.710    keyup\n",
      "104   α  169559.320  keydown\n",
      "105   α  169638.695    keyup\n",
      "106   β  169742.160  keydown\n",
      "107   a  169782.515  keydown\n",
      "108   a  169880.815    keyup\n",
      "109   β  169921.280    keyup\n",
      "110   s  169970.445  keydown\n",
      "111   i  170070.180  keydown\n",
      "112   s  170095.535    keyup\n",
      "113   i  170186.835    keyup\n",
      "114   a  170204.545  keydown\n",
      "115   ,  170387.860  keydown\n",
      "116   a  170392.135    keyup\n",
      "117      170509.585  keydown\n",
      "118   ,  170545.030    keyup\n",
      "119   i  170651.680  keydown\n",
      "120      170688.785    keyup\n",
      "121   t  170711.085  keydown\n",
      "122   i  170763.510    keyup\n",
      "123      170813.070  keydown\n",
      "124   t  170850.705    keyup\n",
      "125   i  170885.305  keydown\n",
      "126      170958.595    keyup\n",
      "127   s  170961.935  keydown\n",
      "128      171053.220  keydown\n",
      "129   s  171059.875    keyup\n",
      "130   i  171065.030    keyup\n",
      "131   c  171135.440  keydown\n",
      "132      171163.230    keyup\n",
      "133   o  171208.490  keydown\n",
      "134   c  171274.625    keyup\n",
      "135   m  171300.550  keydown\n",
      "136   o  171399.230    keyup\n",
      "137   e  171423.575  keydown\n",
      "138   m  171449.165    keyup\n",
      "139   e  171570.660    keyup\n",
      "140   α  171891.345  keydown\n",
      "141   α  171967.560    keyup\n",
      "142   α  172052.340  keydown\n",
      "143   α  172146.435    keyup\n",
      "144   α  172218.620  keydown\n",
      "145   α  172307.335    keyup\n",
      "146   α  172372.755  keydown\n",
      "147   α  172472.135    keyup\n",
      "148   c  172541.475  keydown\n",
      "149   c  172688.405    keyup\n",
      "150   o  172691.790  keydown\n",
      "151   m  172792.395  keydown\n",
      "152   o  172889.340    keyup\n",
      "153   m  172956.050    keyup\n",
      "154   α  173335.670  keydown\n",
      "155   α  173397.975    keyup\n",
      "156   α  173469.530  keydown\n",
      "157   α  173568.825    keyup\n",
      "158   α  173740.150  keydown\n",
      "159   α  173845.255    keyup\n",
      "160   s  173993.945  keydown\n",
      "161   s  174125.090    keyup\n",
      "162   o  174153.585  keydown\n",
      "163   m  174212.660  keydown\n",
      "164   o  174306.235    keyup\n",
      "165   m  174361.785    keyup\n",
      "166   e  174369.265  keydown\n",
      "167   e  174494.050    keyup\n",
      "168   t  174562.470  keydown\n",
      "169   t  174662.700    keyup\n",
      "170   i  174665.805  keydown\n",
      "171   m  174745.825  keydown\n",
      "172   e  174795.415  keydown\n",
      "173   i  174815.705    keyup\n",
      "174   m  174856.885    keyup\n",
      "175   e  174872.760    keyup\n",
      "176   s  174949.420  keydown\n",
      "177   s  175101.295    keyup\n",
      "178      175104.045  keydown\n",
      "179      175247.340    keyup\n",
      "180   a  175353.740  keydown\n",
      "181   a  175498.435    keyup\n",
      "182   s  175572.100  keydown\n",
      "183   s  175707.305    keyup\n",
      "184   c  175771.635  keydown\n",
      "185   c  175853.020    keyup\n",
      "186   r  175925.295  keydown\n",
      "187   r  176042.445    keyup\n",
      "188   i  176078.760  keydown\n",
      "189   b  176125.245  keydown\n",
      "190   i  176198.270    keyup\n",
      "191   b  176229.725    keyup\n",
      "192   d  176404.270  keydown\n",
      "193   d  176537.835    keyup\n",
      "194   α  176821.615  keydown\n",
      "195   e  176885.495  keydown\n",
      "196   α  176932.915    keyup\n",
      "197   e  176970.745    keyup\n",
      "198   d  177027.710  keydown\n",
      "199   d  177126.785    keyup\n",
      "200      177141.340  keydown\n",
      "201   t  177213.360  keydown\n",
      "202      177258.745    keyup\n",
      "203   o  177322.735  keydown\n",
      "204   t  177333.320    keyup\n",
      "205      177373.040  keydown\n",
      "206   a  177451.845  keydown\n",
      "207   o  177456.195    keyup\n",
      "208      177489.980    keyup\n",
      "209   a  177552.515    keyup\n",
      "210      177579.215  keydown\n",
      "211   r  177656.125  keydown\n",
      "212      177705.760    keyup\n",
      "213   e  177757.965  keydown\n",
      "214   r  177809.350    keyup\n",
      "215   e  177899.560    keyup\n",
      "216   g  178666.335  keydown\n",
      "217   g  178805.090    keyup\n",
      "218   i  178914.755  keydown\n",
      "219   o  179060.925  keydown\n",
      "220   n  179162.275  keydown\n",
      "221   i  179220.955    keyup\n",
      "222   o  179233.385    keyup\n",
      "223   a  179252.570  keydown\n",
      "224   n  179287.220    keyup\n",
      "225   l  179371.620  keydown\n",
      "226   a  179455.830    keyup\n",
      "227      179480.980  keydown\n",
      "228   l  179487.270    keyup\n",
      "229      179624.785    keyup\n",
      "230   b  180044.115  keydown\n",
      "231   b  180206.720    keyup\n",
      "232   l  180272.590  keydown\n",
      "233   l  180378.970    keyup\n",
      "234   o  180458.675  keydown\n",
      "235   o  180562.470    keyup\n",
      "236   c  180590.120  keydown\n",
      "237   c  180733.010    keyup\n",
      "238      180892.290  keydown\n",
      "239      181019.310    keyup\n",
      "240   i  181056.800  keydown\n",
      "241   n  181133.730  keydown\n",
      "242   i  181256.410    keyup\n",
      "243   n  181281.970    keyup\n",
      "244      181339.155  keydown\n",
      "245      181478.195    keyup\n",
      "246   e  181612.560  keydown\n",
      "247   e  181700.015    keyup\n",
      "248   i  181705.670  keydown\n",
      "249   t  181767.090  keydown\n",
      "250   i  181823.715    keyup\n",
      "251   t  181866.155    keyup\n",
      "252   h  181893.135  keydown\n",
      "253   e  181942.855  keydown\n",
      "254   r  182002.130  keydown\n",
      "255   h  182012.475    keyup\n",
      "256      182061.830  keydown\n",
      "257   e  182108.200    keyup\n",
      "258   r  182132.010    keyup\n",
      "259      182196.880    keyup\n",
      "260   t  182232.780  keydown\n",
      "261   h  182239.820  keydown\n",
      "262   t  182281.045    keyup\n",
      "263   h  182352.295    keyup\n",
      "264   e  182417.430  keydown\n",
      "265   e  182573.140    keyup\n",
      "266      183086.675  keydown\n",
      "267   β  183152.460  keydown\n",
      "268      183214.070    keyup\n",
      "269   m  183277.915  keydown\n",
      "270   β  183384.910    keyup\n",
      "271   i  183402.980  keydown\n",
      "272   m  183442.115    keyup\n",
      "273   d  183512.235  keydown\n",
      "274   i  183522.770    keyup\n",
      "275   d  183585.650    keyup\n",
      "276   d  183645.680  keydown\n",
      "277   l  183751.920  keydown\n",
      "278   d  183766.905    keyup\n",
      "279   e  183879.195  keydown\n",
      "280   l  183891.230    keyup\n",
      "281      183928.820  keydown\n",
      "282   e  183958.505    keyup\n",
      "283   β  184015.435  keydown\n",
      "284   e  184095.070  keydown\n",
      "285      184101.770    keyup\n",
      "286   e  184206.470    keyup\n",
      "287   β  184214.490    keyup\n",
      "288   a  184310.315  keydown\n",
      "289   s  184345.975  keydown\n",
      "290   a  184420.200    keyup\n",
      "291   t  184489.085  keydown\n",
      "292   s  184536.525    keyup\n",
      "293   t  184595.895    keyup\n",
      "294      185293.465  keydown\n",
      "295      185437.775    keyup\n",
      "296   o  185467.565  keydown\n",
      "297   r  185581.120  keydown\n",
      "298   o  185610.410    keyup\n",
      "299   r  185680.200    keyup\n",
      "300      185693.985  keydown\n",
      "301   β  185772.400  keydown\n",
      "302   s  185805.055  keydown\n",
      "303      185871.220    keyup\n",
      "304   β  185909.560    keyup\n",
      "305   o  185973.795  keydown\n",
      "306   s  185984.680    keyup\n",
      "307   u  186077.510  keydown\n",
      "308   o  186160.040    keyup\n",
      "309   u  186177.090    keyup\n",
      "310   t  186183.115  keydown\n",
      "311   h  186269.815  keydown\n",
      "312   t  186311.805    keyup\n",
      "313      186366.400  keydown\n",
      "314   h  186386.015    keyup\n",
      "315   β  186416.070  keydown\n",
      "316   a  186470.050  keydown\n",
      "317      186537.115    keyup\n",
      "318   a  186577.185    keyup\n",
      "319   β  186686.500    keyup\n",
      "320   a  186714.020  keydown\n",
      "321   a  186788.600    keyup\n",
      "322   α  187128.465  keydown\n",
      "323   α  187220.705    keyup\n",
      "324   s  187270.310  keydown\n",
      "325   s  187369.355    keyup\n",
      "326   i  187414.100  keydown\n",
      "327   i  187530.280    keyup\n",
      "328   a  187548.165  keydown\n",
      "329   a  187733.950    keyup\n",
      "330   £  187813.905  keydown\n",
      "331   £  187935.245    keyup\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    tmp0 = df.loc[(df.participant_id == 1072) & (df.sentence_id == 8), (\"key\", \"timestamp\", \"type\")].reset_index(drop=True)  # Reset index\n",
    "    print(tmp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "try:\n",
    "    annoying_fuck = backspace_implementer_mrc(test_df)\n",
    "except:\n",
    "    extype, value, tb = sys.exc_info()\n",
    "    traceback.print_exc()\n",
    "    pdb.post_mortem(tb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
