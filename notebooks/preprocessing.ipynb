{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "\n",
    "from haberrspd.preprocess import preprocessMJFF\n",
    "                         \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from scipy.stats import (gamma, lognorm, gengamma)\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Plot stuff\n",
    "import seaborn as sns\n",
    "from scipy.constants import golden\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Depending on where I am, set the path\n",
    "import socket\n",
    "if socket.gethostname() == 'pax':\n",
    "    # Monster machine\n",
    "    data_root = '../data/MJFF/' # My local path\n",
    "    data_root = Path(data_root)\n",
    "else:\n",
    "    # Laptop\n",
    "    data_root = '/home/nd/data/liverpool/MJFF' # My local path\n",
    "    data_root = Path(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character + Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/SpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_root / 'SpanishData-duplicateeventsremoved.csv')\n",
    "df = pd.read_csv(data_root / 'SpanishData.csv')\n",
    "df_meta = pd.read_csv(data_root / \"SpanishParticipantKey.csv\",\n",
    "                      index_col=0,\n",
    "                      header=0,\n",
    "                      names=['participant_id', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character ONLY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english',include_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/char/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = set(df_meta.loc[df_meta.diagnosis == 0].participant_id)\n",
    "pd_subjects = set(df_meta.loc[df_meta.diagnosis == 1].participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in pd_subjects:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    pd_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)\n",
    "    \n",
    "control_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in controls:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    control_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs\n",
    "pd_cleaned_list = [x for x in pd_timestamp_diffs if str(x) != 'nan']\n",
    "control_cleaned_list = [x for x in control_timestamp_diffs if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(pd_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(control_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical turk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(data_root /'preprocessed_MechanicalTurkCombinedEnglishData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/MJFF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IKI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_mjff_iki_training_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_mjff_data_objects, us_standard_layout_keyboard, english_keys_to_2d_coordinates\n",
    "import keras.backend as K\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, int64, ones, hstack, pad, einsum, dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import cast, float32, one_hot\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time_space\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "if which_information == \"char_time_space\":\n",
    "    # Get relevant long-format data\n",
    "    which_information = \"char_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "\n",
    "# Store alphabet size\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "print('Total number of characters:', alphabet_size)\n",
    "alphabet_indices = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "if which_information == \"char_time\" or which_information == \"char_time_space\":\n",
    "    # Rounds (up) to nearest thousand\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -3)\n",
    "if which_information == \"char\":\n",
    "    # Rounds (up) to nearest hundred\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -2)\n",
    "\n",
    "# Make training data array\n",
    "all_sentences = [item for sublist in subject_documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer which maps characters to integers\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "\n",
    "# Fit to text: convert all chars to ints\n",
    "tk.fit_on_texts(all_sentences)\n",
    "\n",
    "# Update alphabet\n",
    "tk.word_index = alphabet_indices\n",
    "\n",
    "# Get integer sequences: converts sequences of chars to sequences of ints\n",
    "int_sequences = tk.texts_to_sequences(all_sentences)\n",
    "\n",
    "# Pad sequences so that they all have the same length and then one-hot encode\n",
    "X = to_categorical(pad_sequences(int_sequences, maxlen=max_sentence_length, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information  =  'char_time_space'\n",
    "if which_information == 'char_time_space':\n",
    "    # Load relevant keyboard\n",
    "    keyboard = us_standard_layout_keyboard()  # OBS: nested list\n",
    "    # Check that all chars are in fact in our \"keyboard\" -- if not, we cannot map a coordinate\n",
    "    assert alphabet.issubset(set(list(itertools.chain.from_iterable(keyboard))))\n",
    "    space = [english_keys_to_2d_coordinates(sentence, keyboard) for sentence in all_sentences]\n",
    "    space_padded = [pad(s, [(0, max_sentence_length - len(s)), (0, 0)], mode='constant') for s in space]\n",
    "    # Append coordinates to one-hot encoded sentences\n",
    "    X = einsum('ijk->kij', dstack([hstack((x, s)) for (x, s) in zip(X, space_padded)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document (participant) -level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three options (at time of writing):\n",
    "\n",
    "1. Submit each sentence to model and extract classification probability for each sentence, agglomorate at the end, and the conduct a classification on the vector of all 15 probabilities.\n",
    "2. Calculate the expected value of all encoded (15) sentences and then pass this to the model and take the classification.\n",
    "3. Vertically stack all embedded sentences, and let the convolution run over this (very long) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_training_data_keras, create_mjff_data_objects\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "# subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "# X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(DATA_ROOT, which_information, data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in subject_documents[:3]:\n",
    "    print(doc[:2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Homogenise so that Spacebar is a blank character\n",
    "0. Delete rubbish characters (i.e. remove the rows)\n",
    "2. What to do with stuff like Shift\n",
    "3. Figure out what to do when multiple characters are depressed simultaneously\n",
    "4. Make lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from haberrspd.preprocess import (clean_MRC, backspace_corrector, flatten,\n",
    "                                    make_character_compression_time_sentence, \n",
    "                                  reorder_key_timestamp_columns_mrc, calculate_edit_distance_between_response_and_target_MRC)\n",
    "from haberrspd.charCNN.data_utils_tf import us_english_keyboard_mrc\n",
    "from numpy import concatenate\n",
    "from typing import Tuple\n",
    "import random\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from itertools import compress, count, groupby\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "# Monster machine\n",
    "data_root = '../data/MRC/' # My local path\n",
    "data_root = Path(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv(data_root / \"CombinedTypingDataSept27.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (814388, 12)\n",
      "Size of dataframe after row pruning: (812330, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (812330, 12)\n",
      "Size of dataframe after row pruning: (780201, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>β</td>\n",
       "      <td>keydown</td>\n",
       "      <td>1</td>\n",
       "      <td>25885.055</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26086.840</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>β</td>\n",
       "      <td>keyup</td>\n",
       "      <td>1</td>\n",
       "      <td>26181.975</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>keyup</td>\n",
       "      <td>0</td>\n",
       "      <td>26193.745</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>o</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26321.480</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key     type  location  timestamp  participant_id  sentence_id  diagnosis\n",
       "0   β  keydown         1  25885.055            1010            1          0\n",
       "1   h  keydown         0  26086.840            1010            1          0\n",
       "2   β    keyup         1  26181.975            1010            1          0\n",
       "3   h    keyup         0  26193.745            1010            1          0\n",
       "4   o  keydown         0  26321.480            1010            1          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clean_MRC(df)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['β', 'h', 'o', 'w', 'e', 'v', 'r', ',', 't', 'α', 'l', 'i', 'g',\n",
       "       'n', 's', ' ', 'a', 'm', 'u', 'd', 'f', 'p', 'c', '.', '£', 'b',\n",
       "       'y', 'k', '-', 'x', 'z', '2', '0', '4', '5', '%', \"'\", 'γ', 'q',\n",
       "       '\\\\', 'δ', 'j', 'ε', '3', ';', '[', '=', '_', '8', '6', '$', '{',\n",
       "       '!', '&', 'ζ', '^', '|', 'alt', '/', '9', '\"', ']', ':', ')'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.key.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.copy(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol to process the MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A form of `create_char_compression_time_mjff_data` [to get the temporal data] <-- this needs to be set so that we get a list of \n",
    "2. Second use `create_dataframe_from_processed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_compression_time_mrc_data(df: pd.DataFrame, time_redux_fact=10) -> Tuple[dict, list]:\n",
    "\n",
    "    fail = 0\n",
    "    success = 0\n",
    "    corrected_sentences = defaultdict(dict)\n",
    "    broken_sentences = defaultdict(dict)\n",
    "    char_compression_sentences = defaultdict(dict)\n",
    "    for subj_idx in df.participant_id.unique():\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "\n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "\n",
    "            # Store temporary dataframe because why not\n",
    "            tmp_df = df.loc[coordinates, (\"key\", \"timestamp\", \"type\")].reset_index(drop=True)  # Reset index\n",
    "\n",
    "            # Action order:\n",
    "            #     0. Sort dataset\n",
    "            #     1. Implement backspaces\n",
    "            #     2. Remove contiguous shifts\n",
    "            #     3. Remove solitary keys\n",
    "\n",
    "            # Get correctly ordered sentences and total compression times\n",
    "            tmp_df = move_to_strict_striped_type_order(tmp_df)\n",
    "\n",
    "            # Method to 'implement' the users' backspace actions\n",
    "            backspace_implementer_mrc(tmp_df)\n",
    "\n",
    "            # Removes contiguous shift presses\n",
    "            combine_contiguous_shift_keydowns_without_matching_keyup(tmp_df)\n",
    "\n",
    "            # Remove solitary key-presses which do not have a matching keyup or keydown\n",
    "            remove_solitary_key_presses(tmp_df)\n",
    "\n",
    "            # Check what we managed to achieve\n",
    "            if assess_repeating_key_compression_pattern(tmp_df.type.tolist()):\n",
    "\n",
    "                # Condition succeeds: data-collection is fixed\n",
    "                corrected_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                success += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Condition fails: data-collection is broken\n",
    "                broken_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                fail += 1\n",
    "                print(\"[broken sentence] Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "\n",
    "    for subj_idx in corrected_sentences.keys():\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        for sent_idx in corrected_sentences[subj_idx].keys():\n",
    "            # Final long-format sentences stored here\n",
    "            char_compression_sentences[subj_idx][sent_idx] = \"\".join(\n",
    "                make_character_compression_time_sentence_mrc(\n",
    "                    corrected_sentences[subj_idx][sent_idx], time_redux_fact=time_redux_fact\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"Percentage failed: {}\".format(round(100 * (fail / (success + fail)), 2)))\n",
    "    print(fail, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           key  timestamp     type\n",
      "0        shift    25219.0  keydown\n",
      "1            h    25422.0  keydown\n",
      "2            h    25594.0    keyup\n",
      "3        shift    25594.0    keyup\n",
      "4            o    25766.0  keydown\n",
      "5            o    25892.0    keyup\n",
      "6            v    26188.0  keydown\n",
      "7            v    26343.0    keyup\n",
      "8    backspace    28734.0  keydown\n",
      "9    backspace    28828.0    keyup\n",
      "10           w    28999.0  keydown\n",
      "11           w    29078.0    keyup\n",
      "12           e    29827.0  keydown\n",
      "13           e    29953.0    keyup\n",
      "14           v    29984.0  keydown\n",
      "15           v    30109.0    keyup\n",
      "16           e    30265.0  keydown\n",
      "17           e    30531.0    keyup\n",
      "18           r    30703.0  keydown\n",
      "19           r    30813.0    keyup\n",
      "20           ,    31234.0  keydown\n",
      "21                31453.0  keydown\n",
      "22           ,    31468.0    keyup\n",
      "23           r    31594.0  keydown\n",
      "24                31594.0    keyup\n",
      "25           e    31688.0  keydown\n",
      "26           r    31749.0    keyup\n",
      "27           l    31797.0  keydown\n",
      "28           e    31827.0    keyup\n",
      "29           i    31985.0  keydown\n",
      "30           l    32062.0    keyup\n",
      "31           i    32124.0    keyup\n",
      "32           g    32172.0  keydown\n",
      "33           i    32297.0  keydown\n",
      "34           g    32312.0    keyup\n",
      "35           o    32531.0  keydown\n",
      "36           i    32624.0    keyup\n",
      "37           o    32797.0    keyup\n",
      "38           n    32969.0  keydown\n",
      "39           n    33094.0    keyup\n",
      "40           s    33235.0  keydown\n",
      "41           s    33328.0    keyup\n",
      "42           o    33687.0  keydown\n",
      "43           t    33844.0  keydown\n",
      "44           h    33984.0  keydown\n",
      "45           t    33984.0    keyup\n",
      "46           o    34016.0    keyup\n",
      "47           e    34110.0  keydown\n",
      "48           h    34125.0    keyup\n",
      "49           r    34280.0  keydown\n",
      "50           e    34360.0    keyup\n",
      "51           r    34406.0    keyup\n",
      "52                34516.0  keydown\n",
      "53                34593.0    keyup\n",
      "54           t    34610.0  keydown\n",
      "55           h    34735.0  keydown\n",
      "56           t    34749.0    keyup\n",
      "57           h    34828.0    keyup\n",
      "58           a    34937.0  keydown\n",
      "59           a    35156.0    keyup\n",
      "60           n    35702.0  keydown\n",
      "61           n    35844.0    keyup\n",
      "62                36328.0  keydown\n",
      "63                36391.0    keyup\n",
      "64       shift    36671.0  keydown\n",
      "65           i    36750.0  keydown\n",
      "66           i    36859.0    keyup\n",
      "67       shift    37062.0    keyup\n",
      "68           s    37437.0  keydown\n",
      "69           s    37562.0    keyup\n",
      "70           l    37843.0  keydown\n",
      "71           l    37938.0    keyup\n",
      "72           a    38015.0  keydown\n",
      "73           a    38155.0    keyup\n",
      "74           m    38233.0  keydown\n",
      "75           m    38374.0    keyup\n",
      "76           ,    39499.0  keydown\n",
      "77           ,    39701.0    keyup\n",
      "78           u    40170.0  keydown\n",
      "79           u    40295.0    keyup\n",
      "80   backspace    41201.0  keydown\n",
      "81   backspace    41326.0    keyup\n",
      "82                41983.0  keydown\n",
      "83                42154.0    keyup\n",
      "84           u    43061.0  keydown\n",
      "85           u    43171.0    keyup\n",
      "86           s    43295.0  keydown\n",
      "87           s    43373.0    keyup\n",
      "88           e    43795.0  keydown\n",
      "89           e    43858.0    keyup\n",
      "90                43920.0  keydown\n",
      "91                44014.0    keyup\n",
      "92           a    44154.0  keydown\n",
      "93           a    44296.0    keyup\n",
      "94                44608.0  keydown\n",
      "95                44686.0    keyup\n",
      "96           d    45498.0  keydown\n",
      "97           d    45592.0    keyup\n",
      "98           i    45733.0  keydown\n",
      "99           i    45812.0    keyup\n",
      "100          f    45968.0  keydown\n",
      "101          f    46046.0    keyup\n",
      "102          f    46139.0  keydown\n",
      "103          f    46234.0    keyup\n",
      "104          e    46466.0  keydown\n",
      "105          e    46515.0    keyup\n",
      "106          e    46654.0  keydown\n",
      "107          e    46749.0    keyup\n",
      "108  backspace    47326.0  keydown\n",
      "109  backspace    47483.0    keyup\n",
      "110          r    47592.0  keydown\n",
      "111          r    47765.0    keyup\n",
      "112          e    48093.0  keydown\n",
      "113          e    48201.0    keyup\n",
      "114          n    48545.0  keydown\n",
      "115          n    48670.0    keyup\n",
      "116          t    49436.0  keydown\n",
      "117          t    49546.0    keyup\n",
      "118               49639.0  keydown\n",
      "119               49733.0    keyup\n",
      "120          p    49951.0  keydown\n",
      "121          p    50061.0    keyup\n",
      "122          r    50139.0  keydown\n",
      "123          r    50232.0    keyup\n",
      "124          o    50404.0  keydown\n",
      "125          o    50544.0    keyup\n",
      "126          n    51249.0  keydown\n",
      "127          n    51436.0    keyup\n",
      "128          o    51701.0  keydown\n",
      "129          o    52044.0    keyup\n",
      "130  backspace    53108.0  keydown\n",
      "131  backspace    53233.0    keyup\n",
      "132          u    53669.0  keydown\n",
      "133          u    53764.0    keyup\n",
      "134          n    54108.0  keydown\n",
      "135          n    54217.0    keyup\n",
      "136          c    54670.0  keydown\n",
      "137          c    54764.0    keyup\n",
      "138          i    55139.0  keydown\n",
      "139          i    55233.0    keyup\n",
      "140          a    55342.0  keydown\n",
      "141          a    55576.0    keyup\n",
      "142          t    55607.0  keydown\n",
      "143          i    55686.0  keydown\n",
      "144          t    55747.0    keyup\n",
      "145          o    56045.0  keydown\n",
      "146          i    56092.0    keyup\n",
      "147          o    56357.0    keyup\n",
      "148          n    56466.0  keydown\n",
      "149          n    56701.0    keyup\n",
      "150               57372.0  keydown\n",
      "151               57435.0    keyup\n",
      "152          f    57779.0  keydown\n",
      "153          f    57873.0    keyup\n",
      "154          o    57981.0  keydown\n",
      "155          o    58108.0    keyup\n",
      "156          r    58169.0  keydown\n",
      "157          r    58277.0    keyup\n",
      "158      shift    59247.0  keydown\n",
      "159      shift    59545.0    keyup\n",
      "160               59810.0  keydown\n",
      "161               59903.0    keyup\n",
      "162      shift    60154.0  keydown\n",
      "163          a    60450.0  keydown\n",
      "164          a    60544.0    keyup\n",
      "165      shift    60591.0    keyup\n",
      "166          l    60716.0  keydown\n",
      "167          l    60795.0    keyup\n",
      "168          l    60888.0  keydown\n",
      "169          l    60966.0    keyup\n",
      "170          a    61122.0  keydown\n",
      "171          a    61169.0    keyup\n",
      "172          h    61903.0  keydown\n",
      "173          h    61981.0    keyup\n",
      "174          ,    62467.0  keydown\n",
      "175          ,    62622.0    keyup\n",
      "176               62857.0  keydown\n",
      "177               62950.0    keyup\n",
      "178          a    63763.0  keydown\n",
      "179          a    63858.0    keyup\n",
      "180          l    64028.0  keydown\n",
      "181          l    64138.0    keyup\n",
      "182          t    64560.0  keydown\n",
      "183          t    64716.0    keyup\n",
      "184          h    64858.0  keydown\n",
      "185          h    64982.0    keyup\n",
      "186          o    65294.0  keydown\n",
      "187          g    65450.0  keydown\n",
      "188          u    65607.0  keydown\n",
      "189          g    65607.0    keyup\n",
      "190          o    65686.0    keyup\n",
      "191          u    65716.0    keyup\n",
      "192  backspace    67310.0  keydown\n",
      "193  backspace    67403.0    keyup\n",
      "194  backspace    68419.0  keydown\n",
      "195  backspace    68545.0    keyup\n",
      "196          u    69060.0  keydown\n",
      "197          u    69170.0    keyup\n",
      "198          g    69372.0  keydown\n",
      "199          g    69450.0    keyup\n",
      "200          h    69513.0  keydown\n",
      "201          h    69622.0    keyup\n",
      "202               69825.0  keydown\n",
      "203               69950.0    keyup\n",
      "204          t    70076.0  keydown\n",
      "205          h    70232.0  keydown\n",
      "206          t    70248.0    keyup\n",
      "207          h    70357.0    keyup\n",
      "208          e    70403.0  keydown\n",
      "209          e    70514.0    keyup\n",
      "210          s    71012.0  keydown\n",
      "211          p    71138.0  keydown\n",
      "212          s    71201.0    keyup\n",
      "213          p    71263.0    keyup\n",
      "214  backspace    72622.0  keydown\n",
      "215  backspace    72700.0    keyup\n",
      "216  backspace    72779.0  keydown\n",
      "217  backspace    72857.0    keyup\n",
      "218               73514.0  keydown\n",
      "219               73639.0    keyup\n",
      "220          s    74075.0  keydown\n",
      "221          s    74216.0    keyup\n",
      "222          p    75357.0  keydown\n",
      "223          p    75466.0    keyup\n",
      "224          e    75685.0  keydown\n",
      "225          e    75763.0    keyup\n",
      "226          l    75967.0  keydown\n",
      "227          l    76044.0    keyup\n",
      "228          l    76139.0  keydown\n",
      "229          l    76278.0    keyup\n",
      "230          i    76436.0  keydown\n",
      "231          i    76622.0    keyup\n",
      "232          n    77216.0  keydown\n",
      "233          n    77372.0    keyup\n",
      "234          g    77389.0  keydown\n",
      "235          g    77528.0    keyup\n",
      "236               78639.0  keydown\n",
      "237               78763.0    keyup\n",
      "238          i    79076.0  keydown\n",
      "239          i    79200.0    keyup\n",
      "240          s    79262.0  keydown\n",
      "241          s    79388.0    keyup\n",
      "242               79607.0  keydown\n",
      "243               79763.0    keyup\n",
      "244          t    80075.0  keydown\n",
      "245          h    80248.0  keydown\n",
      "246          t    80248.0    keyup\n",
      "247          h    80435.0    keyup\n",
      "248          e    80482.0  keydown\n",
      "249          e    80576.0    keyup\n",
      "250               80669.0  keydown\n",
      "251               80825.0    keyup\n",
      "252          s    81778.0  keydown\n",
      "253          s    81873.0    keyup\n",
      "254          a    82810.0  keydown\n",
      "255          a    82950.0    keyup\n",
      "256          m    83060.0  keydown\n",
      "257          m    83185.0    keyup\n",
      "258          e    83279.0  keydown\n",
      "259          e    83373.0    keyup\n",
      "260          £    87403.0  keydown\n",
      "261          £    87497.0    keyup\n"
     ]
    }
   ],
   "source": [
    "test_df = copy.copy(df.loc[(df.participant_id == 58) & \n",
    "                           (df.sentence_id == 2), \n",
    "                           (\"key\", \"timestamp\",\"type\")].reset_index(drop=True))\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key  timestamp     type\n",
      "0        €   293309.0  keydown\n",
      "1        €   297278.0    keyup\n",
      "2    shift   297684.0  keydown\n",
      "3        l   297872.0  keydown\n",
      "4        l   297997.0    keyup\n",
      "5    shift   298043.0    keyup\n",
      "6        i   298246.0  keydown\n",
      "7        i   298371.0    keyup\n",
      "8        n   298591.0  keydown\n",
      "9        n   298699.0    keyup\n",
      "10       c   298857.0  keydown\n",
      "11       c   299044.0    keyup\n",
      "12       o   299075.0  keydown\n",
      "13       o   299199.0    keyup\n",
      "14       l   300403.0  keydown\n",
      "15       l   300591.0    keyup\n",
      "16       n   300778.0  keydown\n",
      "17       n   300872.0    keyup\n",
      "18       '   301419.0  keydown\n",
      "19       s   301575.0  keydown\n",
      "20       '   301575.0    keyup\n",
      "21       s   301669.0    keyup\n",
      "22           302402.0  keydown\n",
      "23           302528.0    keyup\n",
      "24       c   303388.0  keydown\n",
      "25       c   303497.0    keyup\n",
      "26       o   303794.0  keydown\n",
      "27       o   303935.0    keyup\n",
      "28       f   304107.0  keydown\n",
      "29       f   304184.0    keyup\n",
      "30       f   304278.0  keydown\n",
      "31       i   304340.0  keydown\n",
      "32       f   304388.0    keyup\n",
      "33       i   304513.0    keyup\n",
      "34       n   304700.0  keydown\n",
      "35       n   304841.0    keyup\n",
      "36           305278.0  keydown\n",
      "37           305341.0    keyup\n",
      "38       w   305700.0  keydown\n",
      "39       w   305809.0    keyup\n",
      "40       o   306903.0  keydown\n",
      "41       u   307107.0  keydown\n",
      "42       o   307185.0    keyup\n",
      "43       u   307216.0    keyup\n",
      "44       l   307388.0  keydown\n",
      "45       d   307559.0  keydown\n",
      "46       l   307574.0    keyup\n",
      "47       d   307669.0    keyup\n",
      "48           307763.0  keydown\n",
      "49           307888.0    keyup\n",
      "50       b   308497.0  keydown\n",
      "51       b   308653.0    keyup\n",
      "52       e   308810.0  keydown\n",
      "53       e   308904.0    keyup\n",
      "54           309012.0  keydown\n",
      "55           309107.0    keyup\n",
      "56       e   309418.0  keydown\n",
      "57       e   309543.0    keyup\n",
      "58       n   309606.0  keydown\n",
      "59       n   309685.0    keyup\n",
      "60       c   309871.0  keydown\n",
      "61       a   309997.0  keydown\n",
      "62       c   310028.0    keyup\n",
      "63       s   310122.0  keydown\n",
      "64       a   310233.0    keyup\n",
      "65       s   310262.0    keyup\n",
      "66       e   310513.0  keydown\n",
      "67       e   310622.0    keyup\n",
      "68           310700.0  keydown\n",
      "69           310778.0    keyup\n",
      "70       i   311044.0  keydown\n",
      "71       i   311216.0    keyup\n",
      "72       n   311310.0  keydown\n",
      "73       n   311528.0    keyup\n",
      "74           311574.0  keydown\n",
      "75           311653.0    keyup\n",
      "76       c   311793.0  keydown\n",
      "77       o   311904.0  keydown\n",
      "78       c   311919.0    keyup\n",
      "79       n   312091.0  keydown\n",
      "80       o   312216.0    keyup\n",
      "81       n   312248.0    keyup\n",
      "82       c   312340.0  keydown\n",
      "83       c   312419.0    keyup\n",
      "84       r   312591.0  keydown\n",
      "85       e   312686.0  keydown\n",
      "86       r   312748.0    keyup\n",
      "87       e   312872.0    keyup\n",
      "88       t   312966.0  keydown\n",
      "89       e   313121.0  keydown\n",
      "90       t   313231.0    keyup\n",
      "91       e   313277.0    keyup\n",
      "92           313575.0  keydown\n",
      "93           313622.0    keyup\n",
      "94       s   313857.0  keydown\n",
      "95       e   313982.0  keydown\n",
      "96       s   314027.0    keyup\n",
      "97       e   314106.0    keyup\n",
      "98       v   314294.0  keydown\n",
      "99       v   314403.0    keyup\n",
      "100      e   314527.0  keydown\n",
      "101      r   314638.0  keydown\n",
      "102      e   314685.0    keyup\n",
      "103      r   314794.0    keyup\n",
      "104      a   314825.0  keydown\n",
      "105      a   314982.0    keyup\n",
      "106      l   314996.0  keydown\n",
      "107      l   315153.0    keyup\n",
      "108          315497.0  keydown\n",
      "109          315591.0    keyup\n",
      "110      f   316372.0  keydown\n",
      "111      f   316450.0    keyup\n",
      "112      e   316622.0  keydown\n",
      "113      e   316700.0    keyup\n",
      "114      e   316809.0  keydown\n",
      "115      t   317013.0  keydown\n",
      "116      e   317060.0    keyup\n",
      "117      t   317121.0    keyup\n",
      "118          317247.0  keydown\n",
      "119          317325.0    keyup\n",
      "120      t   317513.0  keydown\n",
      "121      t   317621.0    keyup\n",
      "122      h   317732.0  keydown\n",
      "123      h   317888.0    keyup\n",
      "124      i   317935.0  keydown\n",
      "125      i   318060.0    keyup\n",
      "126      c   318310.0  keydown\n",
      "127      c   318449.0    keyup\n",
      "128      k   318810.0  keydown\n",
      "129      k   318902.0    keyup\n",
      "130      ,   319700.0  keydown\n",
      "131      ,   319825.0    keyup\n",
      "132          321840.0  keydown\n",
      "133          321965.0    keyup\n",
      "134      a   322247.0  keydown\n",
      "135      a   322403.0    keyup\n",
      "136      n   322669.0  keydown\n",
      "137      n   322811.0    keyup\n",
      "138      d   322857.0  keydown\n",
      "139      d   322966.0    keyup\n",
      "140      s   323543.0  keydown\n",
      "141      s   323715.0    keyup\n",
      "142      €   323763.0  keydown\n",
      "143      €   325699.0    keyup\n",
      "144          326232.0  keydown\n",
      "145          326356.0    keyup\n",
      "146      s   326965.0  keydown\n",
      "147      s   327091.0    keyup\n",
      "148      u   327872.0  keydown\n",
      "149      u   327997.0    keyup\n",
      "150      r   328092.0  keydown\n",
      "151      r   328169.0    keyup\n",
      "152      r   328247.0  keydown\n",
      "153      r   328372.0    keyup\n",
      "154      o   328435.0  keydown\n",
      "155      u   328559.0  keydown\n",
      "156      u   328653.0    keyup\n",
      "157      o   328700.0    keyup\n",
      "158      n   328841.0  keydown\n",
      "159      n   328997.0    keyup\n",
      "160      d   329012.0  keydown\n",
      "161      e   329045.0  keydown\n",
      "162      d   329091.0    keyup\n",
      "163      d   329263.0  keydown\n",
      "164      e   329324.0    keyup\n",
      "165      d   329418.0    keyup\n",
      "166          329732.0  keydown\n",
      "167          329841.0    keyup\n",
      "168      b   330638.0  keydown\n",
      "169      b   330857.0    keyup\n",
      "170      y   330966.0  keydown\n",
      "171      y   331122.0    keyup\n",
      "172          331310.0  keydown\n",
      "173          331450.0    keyup\n",
      "174      a   331668.0  keydown\n",
      "175      a   331732.0    keyup\n",
      "176          332091.0  keydown\n",
      "177          332168.0    keyup\n",
      "178      c   332685.0  keydown\n",
      "179      c   332825.0    keyup\n",
      "180      a   332919.0  keydown\n",
      "181      a   333169.0    keyup\n",
      "182      g   333184.0  keydown\n",
      "183      e   333309.0  keydown\n",
      "184      g   333403.0    keyup\n",
      "185      e   333450.0    keyup\n",
      "186      ,   333902.0  keydown\n",
      "187      ,   334074.0    keyup\n",
      "188          334450.0  keydown\n",
      "189          334560.0    keyup\n",
      "190      a   335200.0  keydown\n",
      "191      a   335341.0    keyup\n",
      "192      n   335997.0  keydown\n",
      "193      n   336185.0    keyup\n",
      "194      d   336199.0  keydown\n",
      "195      d   336309.0    keyup\n",
      "196          336606.0  keydown\n",
      "197          336731.0    keyup\n",
      "198      b   338919.0  keydown\n",
      "199      b   339027.0    keyup\n",
      "200      u   339199.0  keydown\n",
      "201      u   339278.0    keyup\n",
      "202      r   339294.0  keydown\n",
      "203      r   339357.0    keyup\n",
      "204      i   339513.0  keydown\n",
      "205      i   339654.0    keyup\n",
      "206      e   339778.0  keydown\n",
      "207      e   339903.0    keyup\n",
      "208      d   340325.0  keydown\n",
      "209      d   340449.0    keyup\n",
      "210          340527.0  keydown\n",
      "211          340669.0    keyup\n",
      "212      b   340857.0  keydown\n",
      "213      b   340982.0    keyup\n",
      "214      e   341027.0  keydown\n",
      "215      e   341138.0    keyup\n",
      "216      n   341184.0  keydown\n",
      "217      e   341310.0  keydown\n",
      "218      n   341325.0    keyup\n",
      "219      e   341435.0    keyup\n",
      "220      a   341544.0  keydown\n",
      "221      t   341810.0  keydown\n",
      "222      a   341857.0    keyup\n",
      "223      h   341950.0  keydown\n",
      "224      t   341965.0    keyup\n",
      "225      h   342168.0    keyup\n",
      "226          342340.0  keydown\n",
      "227          342418.0    keyup\n",
      "228      a   342810.0  keydown\n",
      "229      a   342935.0    keyup\n",
      "230          343215.0  keydown\n",
      "231          343278.0    keyup\n",
      "232      r   343981.0  keydown\n",
      "233      r   344091.0    keyup\n",
      "234      o   344153.0  keydown\n",
      "235      o   344278.0    keyup\n",
      "236      c   344402.0  keydown\n",
      "237      c   344528.0    keyup\n",
      "238      k   344747.0  keydown\n",
      "239      k   344997.0    keyup\n",
      "240          346075.0  keydown\n",
      "241          346153.0    keyup\n",
      "242      s   346496.0  keydown\n",
      "243      s   346607.0    keyup\n",
      "244      l   346825.0  keydown\n",
      "245      a   346966.0  keydown\n",
      "246      l   346982.0    keyup\n",
      "247      a   347106.0    keyup\n",
      "248      b   347247.0  keydown\n",
      "249      b   347388.0    keyup\n",
      "250      £   347778.0  keydown\n",
      "251      £   347873.0    keyup\n"
     ]
    }
   ],
   "source": [
    "backspace_implementer_mrc(test_df)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_extend(x):\n",
    "    # Need to assert that this is given a sequentially ordered array\n",
    "    return list(np.array(x) - len(x)) + x\n",
    "\n",
    "def range_extend_mrc(x):\n",
    "    # Need to assert that this is given a sequentially ordered array\n",
    "    out = list(range(x[0]-2*len(x),x[0]-len(x))) + list(range(x[0]-len(x),x[0])) + x\n",
    "    assert np.diff(out).sum() == len(out) - 1\n",
    "    return out\n",
    "\n",
    "def make_character_compression_time_sentence_mrc(df: pd.DataFrame, time_redux_fact=10) -> str:\n",
    "    long_form_sentence = []\n",
    "    for i in list(df.index)[::2]:\n",
    "        # Total key compression time\n",
    "        comp_time = abs(df.timestamp[i+1] - df.timestamp[i])\n",
    "        # Character compressed\n",
    "        long_form_sentence.append([df.key[i]] * int(comp_time // time_redux_fact))\n",
    "\n",
    "    return flatten(long_form_sentence)\n",
    "\n",
    "def backspace_implementer_mrc(df: pd.DataFrame, \n",
    "                              backspace_char=\"α\"):\n",
    "    \n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems\n",
    "    idxs = df.index[(df.key == backspace_char)].tolist()\n",
    "    groups = []\n",
    "    remove = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "    # Only remove ones which are actually only of list length 1\n",
    "    for g in groups:\n",
    "        # Data-reading error\n",
    "        if len(g) == 1:\n",
    "            remove.extend(g)\n",
    "        # We replace these inline so we don't have to do it later\n",
    "        elif len(g) == 2:\n",
    "            # Place indicators [keydown]\n",
    "            df.loc[g[0],\"key\"] = '€' \n",
    "            # Place indicators [keyup]\n",
    "            df.loc[g[1],\"key\"] = '€' \n",
    "            \n",
    "    if remove: \n",
    "        # In-place droppping of rows with only one backspace\n",
    "        df.drop(df.index[remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 1) Delete all backspace+keyups to start with\n",
    "    idxs_up = df.index[(df.key == backspace_char) & (df.type == \"keyup\")].tolist()\n",
    "    # Copy these rows for later use\n",
    "    df_keyup = copy.copy(df.iloc[idxs_up])\n",
    "    # In-place dropping of these rows\n",
    "    df.drop(df.index[idxs_up], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 2) Find all remaining backspace+keydowns\n",
    "    idxs = df.index[(df.key == backspace_char) & (df.type == \"keydown\")].tolist()\n",
    "    contiguous_groups = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    indices_to_remove = []\n",
    "    if idxs:\n",
    "        for g in contiguous_groups:\n",
    "                            \n",
    "            gg = range_extend_mrc(g)\n",
    "            # If any negative indices, correct and move indicator characters\n",
    "            if any(i < 0 for i in gg):\n",
    "                gg = list(filter(lambda x: x >= 0, gg))\n",
    "                indices_to_remove.extend(gg[1:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0],\"key\"] = '€'\n",
    "            else:\n",
    "                indices_to_remove.extend(gg[3:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[2],\"key\"] = '€'\n",
    "                                         \n",
    "            # Place indicators [keyup]\n",
    "            # Given a value of keydown timestamp (z), select a row in the keyup df \n",
    "            # where timestamp is closest to z.\n",
    "            keyup_timestamp = df_keyup.loc[(df_keyup['timestamp'] >= df.loc[gg[-1],'timestamp'])].timestamp.values[0]\n",
    "            df.loc[gg[-1],(\"key\",\"timestamp\",\"type\")] = ['€', keyup_timestamp,'keyup']\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "          \n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Check that the indicators appear in the right places\n",
    "        indicator_indices = df.index[(df.key == \"€\")].tolist()\n",
    "        for pair in list(zip(indicator_indices, indicator_indices[1:]))[::2]:\n",
    "            assert pair[1] - pair[0] == 1, indicator_indices\n",
    "        assert backspace_char not in df.key.tolist()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_solitary_key_presses(df):\n",
    "\n",
    "    suspect_keys = []\n",
    "    for key, value in Counter(df.key.tolist()).items():\n",
    "        if value % 2 != 0:\n",
    "            # Find all keys which appear an unequal number of times\n",
    "            suspect_keys.append(key)\n",
    "\n",
    "    # Do not remove \"correction identifier key\" i.e. €\n",
    "    suspect_keys = [key for key in suspect_keys if key not in {\"€\"}]\n",
    "\n",
    "    # Find all instances of suspect keys in df\n",
    "    if len(suspect_keys) != 0:\n",
    "        indices_to_keep = []\n",
    "        all_idxs = []\n",
    "        for key in suspect_keys:\n",
    "            idxs = df.loc[df.key == key].index\n",
    "            all_idxs.extend(idxs)\n",
    "            # If there is more than one such key\n",
    "            for pair in list(zip(idxs, idxs[1:]))[::2]:\n",
    "                if pair[1] - pair[0] == 1:\n",
    "                    indices_to_keep.extend(pair)\n",
    "\n",
    "        # Take set difference to find what's left\n",
    "        indices_to_remove = list(set(all_idxs) - set(indices_to_keep))\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def move_to_strict_striped_type_order(df):\n",
    "        \n",
    "    df_2 = pd.DataFrame(columns=[\"key\", \"timestamp\", \"type\"])\n",
    "    indexes = []\n",
    "    for i in range(len(df)):\n",
    "        if i not in indexes:\n",
    "            df_2 = df_2.append(df.loc[i,:])\n",
    "            letter = df.loc[i,\"key\"]\n",
    "            indexes.append(i)\n",
    "\n",
    "            for j in range(i+1, len(df)):\n",
    "                if ((df.loc[j,\"key\"] == df.loc[i,\"key\"]) and (j not in indexes)):\n",
    "\n",
    "                    df_2 = df_2.append( df.loc[j,:])\n",
    "                    indexes.append(j)\n",
    "                    break;\n",
    "                    \n",
    "    return df_2.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "def test_repeating_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    pat_len = len(pattern)\n",
    "    assert \"keydown\" == lst[0], \"keydown does not start the list: {}\".format(lst[0])\n",
    "    assert len(lst) % pat_len == 0, \"mismatched length of list\"\n",
    "    assert list(pattern) * (len(lst) // pat_len) == lst, \"the list does not follow the correct pattern\"\n",
    "    \n",
    "def assess_repeating_key_compression_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    \n",
    "    assert set(pattern).issubset(set(lst))\n",
    "    pat_len = len(pattern)\n",
    "    if (\"keydown\" == lst[0]) and (len(lst) % pat_len == 0) and (list(pattern) * (len(lst) // pat_len) == lst):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def combine_contiguous_shift_keydowns_without_matching_keyup(df,\n",
    "                                                             shift_char = 'β'):\n",
    "    \"\"\"\n",
    "    Function assumes that df has been sorted before getting this far.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the index of all shift keydowns (these are the ones causing the registration problems)\n",
    "    idxs_down = df.index[(df[\"key\"] == shift_char) & (df[\"type\"] == \"keydown\")].tolist()\n",
    "\n",
    "    # Locate all contiguous sub-sequences\n",
    "    keydown_groups = []\n",
    "    for k, g in groupby(enumerate(idxs_down), lambda ix: ix[0] - ix[1]):\n",
    "        keydown_groups.append(list(map(itemgetter(1), g)))\n",
    "\n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_keydown_coordinates = []\n",
    "    for g in keydown_groups:\n",
    "        # Contiguous groups of shifts\n",
    "        if len(g) > 1:\n",
    "            ii = None\n",
    "            for j in range(1, 6):\n",
    "                if (df.loc[g[-1] + j, \"type\"] == shift_char) and (df.loc[g[-1] + j, \"key\"] == shift_char):\n",
    "                    ii = j\n",
    "            if ii:\n",
    "                # Do this if the immediate key after each group is a \"keyup\"\n",
    "                removal_keydown_coordinates.extend(g[1:])\n",
    "            else:\n",
    "                # Do this if there is no immediately preceeding \"keyup\"\n",
    "                removal_keydown_coordinates.extend(g)\n",
    "\n",
    "    # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "    df.drop(df.index[removal_keydown_coordinates], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "def remove_superfluous_shifts(df, \n",
    "                              shift_char = 'β'):\n",
    "    \n",
    "    ### NOTE the backspace operator has to appear before this\n",
    "    \n",
    "    idxs = df.index[df['key'] == shift_char].tolist()\n",
    "    \n",
    "    # Locate a contiguous sub-sequence at the start of the sentence\n",
    "    shift_groups = []\n",
    "    for k, g in groupby(enumerate(idxs), lambda ix: ix[0] - ix[1]):\n",
    "        shift_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_shift_coordinates = []\n",
    "    for g in shift_groups:\n",
    "        if set(g) == 'keydown' or set(g) == 'keydown':\n",
    "            removal_shift_coordinates.append(g[:-1])\n",
    "            \n",
    "    \n",
    "        \n",
    "    if len(shift_groups[0]) > 2 and df.type[shift_groups[0][-1]] == 'keyup' and df.type[shift_groups[0][-2]] == 'keydown':\n",
    "        # Coordinates to remove\n",
    "        df.drop(df.index[shift_groups[0][:-2]], inplace=True)\n",
    "        \n",
    "    # Shifts should only ever appear as contiguous pairs\n",
    "    if not all([len(x) == 2 for x in shift_groups[1:]]): \n",
    "        print(\"Other shift combinations are also longer than they should be.\\n\")\n",
    "        print(shift_groups)\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
