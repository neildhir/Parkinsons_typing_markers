{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "\n",
    "from haberrspd.preprocess import preprocessMJFF\n",
    "                         \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from scipy.stats import (gamma, lognorm, gengamma)\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Plot stuff\n",
    "import seaborn as sns\n",
    "from scipy.constants import golden\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Depending on where I am, set the path\n",
    "import socket\n",
    "if socket.gethostname() == 'pax':\n",
    "    # Monster machine\n",
    "    data_root = '../data/MJFF/' # My local path\n",
    "    data_root = Path(data_root)\n",
    "else:\n",
    "    # Laptop\n",
    "    data_root = '/home/nd/data/liverpool/MJFF' # My local path\n",
    "    data_root = Path(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character + Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/SpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_root / 'SpanishData-duplicateeventsremoved.csv')\n",
    "df = pd.read_csv(data_root / 'SpanishData.csv')\n",
    "df_meta = pd.read_csv(data_root / \"SpanishParticipantKey.csv\",\n",
    "                      index_col=0,\n",
    "                      header=0,\n",
    "                      names=['participant_id', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character ONLY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english',include_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/char/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = set(df_meta.loc[df_meta.diagnosis == 0].participant_id)\n",
    "pd_subjects = set(df_meta.loc[df_meta.diagnosis == 1].participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in pd_subjects:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    pd_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)\n",
    "    \n",
    "control_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in controls:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    control_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs\n",
    "pd_cleaned_list = [x for x in pd_timestamp_diffs if str(x) != 'nan']\n",
    "control_cleaned_list = [x for x in control_timestamp_diffs if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(pd_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(control_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical turk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(data_root /'preprocessed_MechanicalTurkCombinedEnglishData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/MJFF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IKI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_mjff_iki_training_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_mjff_data_objects, us_standard_layout_keyboard, english_keys_to_2d_coordinates\n",
    "import keras.backend as K\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, int64, ones, hstack, pad, einsum, dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import cast, float32, one_hot\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time_space\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "if which_information == \"char_time_space\":\n",
    "    # Get relevant long-format data\n",
    "    which_information = \"char_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "\n",
    "# Store alphabet size\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "print('Total number of characters:', alphabet_size)\n",
    "alphabet_indices = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "if which_information == \"char_time\" or which_information == \"char_time_space\":\n",
    "    # Rounds (up) to nearest thousand\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -3)\n",
    "if which_information == \"char\":\n",
    "    # Rounds (up) to nearest hundred\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -2)\n",
    "\n",
    "# Make training data array\n",
    "all_sentences = [item for sublist in subject_documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer which maps characters to integers\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "\n",
    "# Fit to text: convert all chars to ints\n",
    "tk.fit_on_texts(all_sentences)\n",
    "\n",
    "# Update alphabet\n",
    "tk.word_index = alphabet_indices\n",
    "\n",
    "# Get integer sequences: converts sequences of chars to sequences of ints\n",
    "int_sequences = tk.texts_to_sequences(all_sentences)\n",
    "\n",
    "# Pad sequences so that they all have the same length and then one-hot encode\n",
    "X = to_categorical(pad_sequences(int_sequences, maxlen=max_sentence_length, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information  =  'char_time_space'\n",
    "if which_information == 'char_time_space':\n",
    "    # Load relevant keyboard\n",
    "    keyboard = us_standard_layout_keyboard()  # OBS: nested list\n",
    "    # Check that all chars are in fact in our \"keyboard\" -- if not, we cannot map a coordinate\n",
    "    assert alphabet.issubset(set(list(itertools.chain.from_iterable(keyboard))))\n",
    "    space = [english_keys_to_2d_coordinates(sentence, keyboard) for sentence in all_sentences]\n",
    "    space_padded = [pad(s, [(0, max_sentence_length - len(s)), (0, 0)], mode='constant') for s in space]\n",
    "    # Append coordinates to one-hot encoded sentences\n",
    "    X = einsum('ijk->kij', dstack([hstack((x, s)) for (x, s) in zip(X, space_padded)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document (participant) -level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three options (at time of writing):\n",
    "\n",
    "1. Submit each sentence to model and extract classification probability for each sentence, agglomorate at the end, and the conduct a classification on the vector of all 15 probabilities.\n",
    "2. Calculate the expected value of all encoded (15) sentences and then pass this to the model and take the classification.\n",
    "3. Vertically stack all embedded sentences, and let the convolution run over this (very long) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_training_data_keras, create_mjff_data_objects\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "# subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "# X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(DATA_ROOT, which_information, data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in subject_documents[:3]:\n",
    "    print(doc[:2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Homogenise so that Spacebar is a blank character\n",
    "0. Delete rubbish characters (i.e. remove the rows)\n",
    "2. What to do with stuff like Shift\n",
    "3. Figure out what to do when multiple characters are depressed simultaneously\n",
    "4. Make lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from haberrspd.preprocess import (clean_mrc,\n",
    "                                  create_sentences_from_raw_typing_mrc,\n",
    "                                  backspace_corrector, \n",
    "                                  flatten,\n",
    "                                  calculate_edit_distance_between_response_and_target_MRC)\n",
    "from haberrspd.charCNN.data_utils_tf import us_english_keyboard_mrc\n",
    "from numpy import concatenate\n",
    "from typing import Tuple\n",
    "import random\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from itertools import compress, count, groupby\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "# Monster machine\n",
    "data_root = '../data/MRC/' # My local path\n",
    "data_root = Path(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_root / \"CombinedTypingDataSept27.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (814388, 12)\n",
      "Size of dataframe after row pruning: (812330, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (812330, 12)\n",
      "Size of dataframe after row pruning: (780201, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>β</td>\n",
       "      <td>keydown</td>\n",
       "      <td>1</td>\n",
       "      <td>25885.055</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26086.840</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>β</td>\n",
       "      <td>keyup</td>\n",
       "      <td>1</td>\n",
       "      <td>26181.975</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>keyup</td>\n",
       "      <td>0</td>\n",
       "      <td>26193.745</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26321.480</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key     type  location  timestamp  participant_id  sentence_id  diagnosis\n",
       "0   β  keydown         1  25885.055            1010            1          0\n",
       "1   h  keydown         0  26086.840            1010            1          0\n",
       "2   β    keyup         1  26181.975            1010            1          0\n",
       "3   h    keyup         0  26193.745            1010            1          0\n",
       "4   o  keydown         0  26321.480            1010            1          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clean_mrc(df)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.copy(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol to process the MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A form of `create_char_compression_time_mjff_data` [to get the temporal data] <-- this needs to be set so that we get a list of \n",
    "2. Second use `create_dataframe_from_processed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.preprocess import (move_to_strict_striped_type_order, \n",
    "backspace_implementer_mrc,\n",
    "                                  range_extend_mrc,\n",
    "remove_solitary_key_presses,\n",
    "combine_contiguous_shift_keydowns_without_matching_keyup, \n",
    "assess_repeating_key_compression_pattern, \n",
    "make_character_compression_time_sentence_mrc)\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_from_raw_typing_mrc(df: pd.DataFrame, \n",
    "                                          make_long_format=True,\n",
    "                                          time_redux_fact=10) -> Tuple[dict, list]:\n",
    "\n",
    "    fail = 0\n",
    "    success = 0\n",
    "    corrected_sentences = defaultdict(dict)\n",
    "    broken_sentences = defaultdict(dict)\n",
    "    char_compression_sentences = defaultdict(dict)\n",
    "    for subj_idx in df.participant_id.unique():\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        print(\"\\t>>>This is subject: %i.\" % subj_idx)\n",
    "        for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "            print(sent_idx, end=\" \")\n",
    "            \n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "\n",
    "            # Store temporary dataframe because why not\n",
    "            tmp_df = df.loc[coordinates, (\"key\", \"timestamp\", \"type\")].reset_index(drop=True)  # Reset index\n",
    "\n",
    "            # Action order:\n",
    "            #     0. Sort dataset\n",
    "            #     1. Implement backspaces\n",
    "            #     2. Remove contiguous shifts\n",
    "            #     3. Remove solitary keys\n",
    "\n",
    "            # Get correctly ordered sentences and total compression times\n",
    "            tmp_df = move_to_strict_striped_type_order(tmp_df)\n",
    "\n",
    "            # Method to 'implement' the users' backspace actions\n",
    "            backspace_implementer_mrc(tmp_df)\n",
    "\n",
    "            # Removes contiguous shift presses\n",
    "            combine_contiguous_shift_keydowns_without_matching_keyup(tmp_df)\n",
    "\n",
    "            # Remove solitary key-presses which do not have a matching keyup or keydown\n",
    "            remove_solitary_key_presses(tmp_df)\n",
    "\n",
    "            # Check what we managed to achieve\n",
    "            if assess_repeating_key_compression_pattern(tmp_df.type.tolist()):\n",
    "\n",
    "                # Condition succeeds: data-collection is fixed\n",
    "                corrected_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                success += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Condition fails: data-collection is broken\n",
    "                broken_sentences[subj_idx][sent_idx] = tmp_df\n",
    "                fail += 1\n",
    "                print(\"[broken sentence] Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "                \n",
    "        print()\n",
    "\n",
    "    for subj_idx in corrected_sentences.keys():\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        for sent_idx in corrected_sentences[subj_idx].keys():\n",
    "            if make_long_format:\n",
    "                # Final long-format sentences stored here\n",
    "                char_compression_sentences[subj_idx][sent_idx] = \"\".join(\n",
    "                    make_character_compression_time_sentence_mrc(\n",
    "                        corrected_sentences[subj_idx][sent_idx], time_redux_fact=time_redux_fact\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # We do not use the time-dimension and look only at the spatial component\n",
    "                # Final long-format sentences stored here\n",
    "                char_compression_sentences[subj_idx][sent_idx] = \"\".join(\n",
    "                    corrected_sentences[subj_idx][sent_idx].key[::2]\n",
    "                )  # [::2] takes into account that we only want one of the keydown-keyup pair.\n",
    "\n",
    "    print(\"Percentage failed: {}\".format(round(100 * (fail / (success + fail)), 2)))\n",
    "    print(fail, success)\n",
    "\n",
    "    return char_compression_sentences, broken_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>>>This is subject: 1010.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1010, Sentence: 6\n",
      "7 8 [broken sentence] Participant: 1010, Sentence: 8\n",
      "9 10 11 [broken sentence] Participant: 1010, Sentence: 11\n",
      "12 [broken sentence] Participant: 1010, Sentence: 12\n",
      "13 14 15 \n",
      "\t>>>This is subject: 1011.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 [broken sentence] Participant: 1011, Sentence: 13\n",
      "14 \n",
      "\t>>>This is subject: 1012.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1014.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1014, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1013.\n",
      "1 2 5 [broken sentence] Participant: 1013, Sentence: 5\n",
      "3 4 [broken sentence] Participant: 1013, Sentence: 4\n",
      "6 [broken sentence] Participant: 1013, Sentence: 6\n",
      "7 9 10 11 [broken sentence] Participant: 1013, Sentence: 11\n",
      "12 13 14 15 \n",
      "\t>>>This is subject: 1015.\n",
      "1 2 5 3 4 6 7 8 [broken sentence] Participant: 1015, Sentence: 8\n",
      "9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1019.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1016.\n",
      "1 [broken sentence] Participant: 1016, Sentence: 1\n",
      "2 5 3 4 6 7 8 9 10 11 12 13 [broken sentence] Participant: 1016, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1018.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1020.\n",
      "1 2 5 3 4 6 7 8 9 10 12 [broken sentence] Participant: 1020, Sentence: 12\n",
      "13 14 15 \n",
      "\t>>>This is subject: 1022.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1021.\n",
      "1 [broken sentence] Participant: 1021, Sentence: 1\n",
      "2 5 [broken sentence] Participant: 1021, Sentence: 5\n",
      "3 4 6 7 8 [broken sentence] Participant: 1021, Sentence: 8\n",
      "9 10 [broken sentence] Participant: 1021, Sentence: 10\n",
      "11 12 13 [broken sentence] Participant: 1021, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1024.\n",
      "1 [broken sentence] Participant: 1024, Sentence: 1\n",
      "5 [broken sentence] Participant: 1024, Sentence: 5\n",
      "3 [broken sentence] Participant: 1024, Sentence: 3\n",
      "4 6 [broken sentence] Participant: 1024, Sentence: 6\n",
      "7 [broken sentence] Participant: 1024, Sentence: 7\n",
      "8 [broken sentence] Participant: 1024, Sentence: 8\n",
      "9 [broken sentence] Participant: 1024, Sentence: 9\n",
      "10 11 12 [broken sentence] Participant: 1024, Sentence: 12\n",
      "13 14 [broken sentence] Participant: 1024, Sentence: 14\n",
      "15 [broken sentence] Participant: 1024, Sentence: 15\n",
      "\n",
      "\t>>>This is subject: 1023.\n",
      "1 [broken sentence] Participant: 1023, Sentence: 1\n",
      "2 [broken sentence] Participant: 1023, Sentence: 2\n",
      "5 3 4 6 7 8 [broken sentence] Participant: 1023, Sentence: 8\n",
      "9 10 [broken sentence] Participant: 1023, Sentence: 10\n",
      "11 12 13 [broken sentence] Participant: 1023, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1026.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1025.\n",
      "1 2 5 [broken sentence] Participant: 1025, Sentence: 5\n",
      "3 4 6 7 8 [broken sentence] Participant: 1025, Sentence: 8\n",
      "9 10 11 12 13 [broken sentence] Participant: 1025, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1027.\n",
      "2 5 3 4 6 7 8 9 11 [broken sentence] Participant: 1027, Sentence: 11\n",
      "12 13 14 15 \n",
      "\t>>>This is subject: 1030.\n",
      "1 2 [broken sentence] Participant: 1030, Sentence: 2\n",
      "5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1031.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1033.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1034.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1035.\n",
      "1 2 [broken sentence] Participant: 1035, Sentence: 2\n",
      "5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1037.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 [broken sentence] Participant: 1037, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1038.\n",
      "1 2 [broken sentence] Participant: 1038, Sentence: 2\n",
      "5 3 4 6 7 [broken sentence] Participant: 1038, Sentence: 7\n",
      "8 9 10 [broken sentence] Participant: 1038, Sentence: 10\n",
      "11 12 13 [broken sentence] Participant: 1038, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1039.\n",
      "1 5 6 7 8 9 10 14 \n",
      "\t>>>This is subject: 1040.\n",
      "1 2 [broken sentence] Participant: 1040, Sentence: 2\n",
      "5 [broken sentence] Participant: 1040, Sentence: 5\n",
      "3 4 6 [broken sentence] Participant: 1040, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 [broken sentence] Participant: 1040, Sentence: 15\n",
      "\n",
      "\t>>>This is subject: 1041.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1042.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1042, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1043.\n",
      "1 2 [broken sentence] Participant: 1043, Sentence: 2\n",
      "5 [broken sentence] Participant: 1043, Sentence: 5\n",
      "3 4 6 7 8 9 10 11 [broken sentence] Participant: 1043, Sentence: 11\n",
      "12 13 [broken sentence] Participant: 1043, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1044.\n",
      "1 [broken sentence] Participant: 1044, Sentence: 1\n",
      "2 [broken sentence] Participant: 1044, Sentence: 2\n",
      "5 3 4 6 7 8 9 10 11 12 13 15 \n",
      "\t>>>This is subject: 1045.\n",
      "2 [broken sentence] Participant: 1045, Sentence: 2\n",
      "5 [broken sentence] Participant: 1045, Sentence: 5\n",
      "3 4 6 7 9 [broken sentence] Participant: 1045, Sentence: 9\n",
      "10 11 12 13 [broken sentence] Participant: 1045, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1046.\n",
      "1 2 5 3 [broken sentence] Participant: 1046, Sentence: 3\n",
      "4 6 10 11 12 13 [broken sentence] Participant: 1046, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1047.\n",
      "1 2 5 3 4 7 8 [broken sentence] Participant: 1047, Sentence: 8\n",
      "9 10 11 [broken sentence] Participant: 1047, Sentence: 11\n",
      "12 13 [broken sentence] Participant: 1047, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1048.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1049.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1051.\n",
      "1 2 5 3 4 6 7 8 9 10 13 14 15 \n",
      "\t>>>This is subject: 1052.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1053.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1053, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1054.\n",
      "1 [broken sentence] Participant: 1054, Sentence: 1\n",
      "2 [broken sentence] Participant: 1054, Sentence: 2\n",
      "5 3 4 6 7 9 10 11 12 13 [broken sentence] Participant: 1054, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1055.\n",
      "1 2 5 4 6 7 8 9 [broken sentence] Participant: 1055, Sentence: 9\n",
      "10 11 [broken sentence] Participant: 1055, Sentence: 11\n",
      "12 13 14 15 \n",
      "\t>>>This is subject: 1056.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1057.\n",
      "1 2 5 3 \n",
      "\t>>>This is subject: 1059.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1059, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1063.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1064.\n",
      "2 [broken sentence] Participant: 1064, Sentence: 2\n",
      "5 3 6 7 8 10 11 12 14 15 \n",
      "\t>>>This is subject: 1065.\n",
      "1 5 [broken sentence] Participant: 1065, Sentence: 5\n",
      "3 4 6 [broken sentence] Participant: 1065, Sentence: 6\n",
      "7 8 [broken sentence] Participant: 1065, Sentence: 8\n",
      "9 10 11 12 13 [broken sentence] Participant: 1065, Sentence: 13\n",
      "14 [broken sentence] Participant: 1065, Sentence: 14\n",
      "15 \n",
      "\t>>>This is subject: 1066.\n",
      "2 5 3 4 6 7 8 9 [broken sentence] Participant: 1066, Sentence: 9\n",
      "10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1067.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1068.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1069.\n",
      "1 2 5 [broken sentence] Participant: 1069, Sentence: 5\n",
      "3 4 6 7 8 9 10 11 12 13 [broken sentence] Participant: 1069, Sentence: 13\n",
      "14 15 [broken sentence] Participant: 1069, Sentence: 15\n",
      "\n",
      "\t>>>This is subject: 1071.\n",
      "1 2 5 3 4 6 [broken sentence] Participant: 1071, Sentence: 6\n",
      "7 8 9 10 11 12 13 14 15 \n",
      "\t>>>This is subject: 1070.\n",
      "1 2 5 3 4 6 7 8 9 10 11 12 13 [broken sentence] Participant: 1070, Sentence: 13\n",
      "14 15 \n",
      "\t>>>This is subject: 1072.\n",
      "1 2 5 3 4 "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-60ce327acb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sentences_from_raw_typing_mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-df04d731c812>\u001b[0m in \u001b[0;36mcreate_sentences_from_raw_typing_mrc\u001b[0;34m(df, make_long_format, time_redux_fact)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Method to 'implement' the users' backspace actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mbackspace_implementer_mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Removes contiguous shift presses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cloud/habitual_errors_NLP/notebooks/../haberrspd/preprocess.py\u001b[0m in \u001b[0;36mbackspace_implementer_mrc\u001b[0;34m(df, backspace_char)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;31m# Given a value of keydown timestamp (z), select a row in the keyup df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;31m# where timestamp is closest to z.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mkeyup_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keyup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_keyup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"€\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyup_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keyup\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "new = create_sentences_from_raw_typing_mrc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backspace_implementer_mrc(df: pd.DataFrame, backspace_char=\"α\"):\n",
    "\n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems\n",
    "    idxs = df.index[(df.key == backspace_char)].tolist()\n",
    "    groups = []\n",
    "    remove = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    # Only remove ones which are actually only of list length 1\n",
    "    for g in groups:\n",
    "        # Data-reading error\n",
    "        if len(g) == 1:\n",
    "            remove.extend(g)\n",
    "        # We replace these inline so we don't have to do it later\n",
    "        elif len(g) == 2:\n",
    "            # Place indicators [keydown]\n",
    "            df.loc[g[0], \"key\"] = \"€\"\n",
    "            # Place indicators [keyup]\n",
    "            df.loc[g[1], \"key\"] = \"€\"\n",
    "\n",
    "    if remove:\n",
    "        # In-place droppping of rows with only one backspace\n",
    "        df.drop(df.index[remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 1) Delete all backspace+keyups to start with\n",
    "    idxs_up = df.index[(df.key == backspace_char) & (df.type == \"keyup\")].tolist()\n",
    "    # Copy these rows for later use\n",
    "    df_keyup = copy.copy(df.iloc[idxs_up])\n",
    "    # In-place dropping of these rows\n",
    "    df.drop(df.index[idxs_up], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 2) Find all remaining backspace+keydowns\n",
    "    idxs = df.index[(df.key == backspace_char) & (df.type == \"keydown\")].tolist()\n",
    "    contiguous_groups = []\n",
    "    indices_to_remove = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    if idxs:\n",
    "        for g in contiguous_groups:\n",
    "\n",
    "            gg = range_extend_mrc(g)\n",
    "            # If any negative indices, correct and move indicator characters\n",
    "            if any(i < 0 for i in gg):\n",
    "                gg = list(filter(lambda x: x >= 0, gg))\n",
    "                indices_to_remove.extend(gg[1:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0], \"key\"] = \"€\"\n",
    "            else:\n",
    "                indices_to_remove.extend(gg[3:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[2], \"key\"] = \"€\"\n",
    "\n",
    "            # Place indicators [keyup]\n",
    "            # Given a value of keydown timestamp (z), select a row in the keyup df\n",
    "            # where timestamp is closest to z.\n",
    "            pdb.set_trace()\n",
    "            keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n",
    "            df.loc[gg[-1], (\"key\", \"timestamp\", \"type\")] = [\"€\", keyup_timestamp, \"keyup\"]\n",
    "\n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Check that the indicators appear in the right places\n",
    "        indicator_indices = df.index[(df.key == \"€\")].tolist()\n",
    "        for pair in list(zip(indicator_indices, indicator_indices[1:]))[::2]:\n",
    "            assert pair[1] - pair[0] == 1, indicator_indices\n",
    "        assert backspace_char not in df.key.tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test(tmp0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = df.loc[(df.participant_id == 1072) & (df.sentence_id == 4), (\"key\", \"timestamp\", \"type\")].reset_index(drop=True)  # Reset index\n",
    "\n",
    "tmp1 = move_to_strict_striped_type_order(tmp0)\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df, backspace_char = \"α\"):\n",
    "    # 0) Remove any singular backspaces that appear bc. data-reading problems\n",
    "    ids = df.index[(df.key == backspace_char)].tolist()\n",
    "    groups = []\n",
    "    remove = []\n",
    "    for k, g in groupby(enumerate(sorted(ids)), lambda ix: ix[1] - ix[0]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    # Only remove ones which are actually only of list length 1\n",
    "    for g in groups:\n",
    "        # Data-reading error\n",
    "        if len(g) == 1:\n",
    "            remove.extend(g)\n",
    "        # We replace these inline so we don't have to do it later\n",
    "        elif len(g) == 2:\n",
    "            # Place indicators [keydown]\n",
    "            df.loc[g[0], \"key\"] = \"€\"\n",
    "            # Place indicators [keyup]\n",
    "            df.loc[g[1], \"key\"] = \"€\"\n",
    "        else:\n",
    "            t = df.loc[g,'type'].tolist()\n",
    "            for i, pair in enumerate(list(zip(t, t[1:]))):\n",
    "                if df.loc[g[i-1],'type'] != 'keydown':\n",
    "                    if pair == ('keydown', 'keyup') or pair == ('keyup', 'keydown'):\n",
    "                        print('bob', g[i],g[i+1])\n",
    "                        # Place indicators [keydown]\n",
    "                        df.loc[g[i], \"key\"] = \"€\"\n",
    "                        # Place indicators [keyup]\n",
    "                        df.loc[g[i+1], \"key\"] = \"€\"\n",
    "                        \n",
    "                        a,b = g[i],g[i+1]\n",
    "\n",
    "    if remove:\n",
    "        # In-place droppping of rows with only one backspace\n",
    "        df.drop(df.index[remove], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    print(df.loc[a, \"key\"],df.loc[b, \"key\"])\n",
    "        \n",
    "    # 1) Delete all backspace+keyups to start with\n",
    "    idxs_up = df.index[(df.key == backspace_char) & (df.type == \"keyup\")].tolist()\n",
    "    # Copy these rows for later use\n",
    "    df_keyup = df.iloc[idxs_up].copy(deep=True)\n",
    "    # In-place dropping of these rows\n",
    "    df.drop(df.index[idxs_up], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 2) Find all remaining backspace+keydowns\n",
    "    idxs = df.index[(df.key == backspace_char) & (df.type == \"keydown\")].tolist()\n",
    "    print(idxs)\n",
    "    contiguous_groups = []\n",
    "    for k, g in groupby(enumerate(sorted(idxs)), lambda ix: ix[1] - ix[0]):\n",
    "        contiguous_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    indices_to_remove = []\n",
    "    if idxs:\n",
    "        for g in contiguous_groups:\n",
    "\n",
    "            gg = range_extend_mrc(g)\n",
    "            # If any negative indices, correct and move indicator characters\n",
    "            if any(i < 0 for i in gg):\n",
    "                gg = list(filter(lambda x: x >= 0, gg))\n",
    "                indices_to_remove.extend(gg[1:-1])\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0], [\"key\", \"type\"]] = [\"€\", \"keydown\"]\n",
    "            else:\n",
    "                indices_to_remove.extend(gg[1:-1]) # replaced [3:-1]\n",
    "                # Place indicators [keydown]\n",
    "                df.loc[gg[0], [\"key\", \"type\"]] = [\"€\", \"keydown\"] # replaced [2]\n",
    "\n",
    "            # Place indicators [keyup]\n",
    "            # Given a value of keydown timestamp (z), select a row in the keyup df\n",
    "            # where timestamp is closest to z.\n",
    "            keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] \n",
    "                                            >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n",
    "            df.loc[gg[-1], (\"key\", \"timestamp\", \"type\")] = [\"€\", keyup_timestamp, \"keyup\"]\n",
    "            \n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[indices_to_remove], inplace=True)\n",
    "\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Check that the indicators appear in the right places\n",
    "        indicator_indices = df.index[(df.key == \"€\")].tolist()\n",
    "        for pair in list(zip(indicator_indices, indicator_indices[1:]))[::2]:\n",
    "            assert pair[1] - pair[0] == 1, indicator_indices\n",
    "        assert backspace_char not in df.key.tolist()\n",
    "        \n",
    "    return idxs_up, groups, df_keyup, contiguous_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = tmp0.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob 83 84\n",
      "€ €\n",
      "[76, 77, 78, 79, 80, 81]\n"
     ]
    }
   ],
   "source": [
    "out = test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[76, 77, 78, 79, 80, 81, 82, 83, 84],\n",
       " [105, 106],\n",
       " [195, 196],\n",
       " [219, 220],\n",
       " [229, 230]]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>α</td>\n",
       "      <td>104018.14</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  timestamp   type\n",
       "82   α  104018.14  keyup"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[76, 77, 78, 79, 80, 81]]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    key   timestamp     type\n",
      "0     β   98425.515  keydown\n",
      "1     t   98527.630  keydown\n",
      "2     β   98619.790    keyup\n",
      "3     t   98633.330    keyup\n",
      "4     h   98661.565  keydown\n",
      "5     e   98726.280  keydown\n",
      "6     h   98781.095    keyup\n",
      "7         98825.725  keydown\n",
      "8     e   98842.220    keyup\n",
      "9     β   98880.230  keydown\n",
      "10    f   98977.310  keydown\n",
      "11        99001.115    keyup\n",
      "12    f   99078.715    keyup\n",
      "13    β   99126.280    keyup\n",
      "14    r   99136.235  keydown\n",
      "15    r   99235.735    keyup\n",
      "16    a   99245.470  keydown\n",
      "17    n   99309.495  keydown\n",
      "18    a   99388.815    keyup\n",
      "19    k   99401.990  keydown\n",
      "20    n   99471.170    keyup\n",
      "21    s   99528.500  keydown\n",
      "22    k   99545.945    keyup\n",
      "23        99620.045  keydown\n",
      "24    s   99640.170    keyup\n",
      "25    a   99734.925  keydown\n",
      "26        99755.130    keyup\n",
      "27    l   99826.120  keydown\n",
      "28    l   99919.650    keyup\n",
      "29    a   99927.060    keyup\n",
      "30    l   99990.355  keydown\n",
      "31    i  100132.095  keydown\n",
      "32    l  100207.085    keyup\n",
      "33    a  100283.745  keydown\n",
      "34    i  100295.935    keyup\n",
      "35    n  100364.940  keydown\n",
      "36    a  100383.085    keyup\n",
      "37    n  100472.535    keyup\n",
      "38    c  100592.160  keydown\n",
      "39    c  100695.120    keyup\n",
      "40    e  100765.010  keydown\n",
      "41    e  100874.720    keyup\n",
      "42       100914.135  keydown\n",
      "43    w  101010.585  keydown\n",
      "44       101061.205    keyup\n",
      "45    w  101108.415    keyup\n",
      "46    a  101180.130  keydown\n",
      "47    s  101234.915  keydown\n",
      "48    a  101291.405    keyup\n",
      "49       101314.365  keydown\n",
      "50    s  101383.515    keyup\n",
      "51       101497.430    keyup\n",
      "52    i  101505.925  keydown\n",
      "53    m  101624.590  keydown\n",
      "54    i  101686.210    keyup\n",
      "55    p  101738.095  keydown\n",
      "56    m  101803.725    keyup\n",
      "57    o  101847.540  keydown\n",
      "58    p  101943.930    keyup\n",
      "59    o  102031.830    keyup\n",
      "60    r  102064.490  keydown\n",
      "61    r  102175.570    keyup\n",
      "62    a  102215.545  keydown\n",
      "63    n  102352.590  keydown\n",
      "64    €  102379.390  keydown\n",
      "65    €  104018.140    keyup\n",
      "66    €  104279.710  keydown\n",
      "67    €  104418.630    keyup\n",
      "68    t  104550.470  keydown\n",
      "69    t  104640.195    keyup\n",
      "70    a  104689.360  keydown\n",
      "71    n  104830.590  keydown\n",
      "72    a  104846.105    keyup\n",
      "73    t  104935.335  keydown\n",
      "74    n  104947.870    keyup\n",
      "75       105012.730  keydown\n",
      "76    t  105041.900    keyup\n",
      "77    e  105168.490  keydown\n",
      "78       105188.260    keyup\n",
      "79    e  105248.790    keyup\n",
      "80    x  105327.185  keydown\n",
      "81    x  105508.180    keyup\n",
      "82    a  105774.885  keydown\n",
      "83    a  105908.580    keyup\n",
      "84    c  106000.615  keydown\n",
      "85    p  106109.950  keydown\n",
      "86    c  106165.210    keyup\n",
      "87    p  106231.040    keyup\n",
      "88    €  106497.430  keydown\n",
      "89    €  106586.315    keyup\n",
      "90    t  106787.340  keydown\n",
      "91    l  106906.265  keydown\n",
      "92    t  106924.555    keyup\n",
      "93    y  107039.160  keydown\n",
      "94    l  107085.845    keyup\n",
      "95    y  107141.120    keyup\n",
      "96       107254.195  keydown\n",
      "97       107398.285    keyup\n",
      "98    b  107404.215  keydown\n",
      "99    b  107485.140    keyup\n",
      "100   e  107550.360  keydown\n",
      "101   e  107651.615    keyup\n",
      "102   c  107706.545  keydown\n",
      "103   a  107806.335  keydown\n",
      "104   c  107821.380    keyup\n",
      "105   u  107914.995  keydown\n",
      "106   a  107927.750    keyup\n",
      "107   s  107974.440  keydown\n",
      "108   u  108027.170    keyup\n",
      "109   e  108066.630  keydown\n",
      "110   s  108109.460    keyup\n",
      "111      108161.580  keydown\n",
      "112   e  108210.715    keyup\n",
      "113   o  108262.725  keydown\n",
      "114      108278.240    keyup\n",
      "115   f  108335.015  keydown\n",
      "116      108414.560  keydown\n",
      "117   f  108424.450    keyup\n",
      "118   o  108430.760    keyup\n",
      "119   t  108476.665  keydown\n",
      "120      108560.600    keyup\n",
      "121   h  108564.670  keydown\n",
      "122   t  108572.185    keyup\n",
      "123   e  108645.740  keydown\n",
      "124   h  108690.105    keyup\n",
      "125   e  108757.600    keyup\n",
      "126   i  108771.775  keydown\n",
      "127   r  108849.280  keydown\n",
      "128   i  108884.265    keyup\n",
      "129      108931.395  keydown\n",
      "130   r  109029.830    keyup\n",
      "131      109067.700    keyup\n",
      "132   r  109578.895  keydown\n",
      "133   e  109720.355  keydown\n",
      "134   r  109736.275    keyup\n",
      "135   e  109881.605    keyup\n",
      "136   n  109980.920  keydown\n",
      "137   n  110085.080    keyup\n",
      "138   o  110091.775  keydown\n",
      "139   o  110201.555    keyup\n",
      "140   w  110269.125  keydown\n",
      "141   n  110388.055  keydown\n",
      "142   w  110462.460    keyup\n",
      "143   n  110521.075    keyup\n",
      "144      110591.050  keydown\n",
      "145      110698.220    keyup\n",
      "146   h  110765.435  keydown\n",
      "147   o  110852.380  keydown\n",
      "148   h  110874.725    keyup\n",
      "149   o  110988.310    keyup\n",
      "150   s  111016.105  keydown\n",
      "151   s  111164.620    keyup\n",
      "152   t  111200.005  keydown\n",
      "153   i  111276.420  keydown\n",
      "154   t  111361.525    keyup\n",
      "155   i  111386.260    keyup\n",
      "156   l  111448.245  keydown\n",
      "157   i  111512.405  keydown\n",
      "158   l  111598.280    keyup\n",
      "159   i  111672.070    keyup\n",
      "160   t  111675.360  keydown\n",
      "161   y  111741.550  keydown\n",
      "162   t  111802.635    keyup\n",
      "163      111845.335  keydown\n",
      "164   y  111874.630    keyup\n",
      "165   t  111932.010  keydown\n",
      "166      111981.440    keyup\n",
      "167   o  112006.895  keydown\n",
      "168   t  112026.690    keyup\n",
      "169   w  112106.665  keydown\n",
      "170   o  112140.390    keyup\n",
      "171   w  112190.380    keyup\n",
      "172   a  112232.125  keydown\n",
      "173   r  112319.105  keydown\n",
      "174   a  112367.020    keyup\n",
      "175   r  112444.105    keyup\n",
      "176   s  112597.120  keydown\n",
      "177   s  112781.005    keyup\n",
      "178   €  113126.415  keydown\n",
      "179   €  113221.070    keyup\n",
      "180   d  113232.380  keydown\n",
      "181   s  113304.525  keydown\n",
      "182   d  113344.465    keyup\n",
      "183      113451.265  keydown\n",
      "184   s  113459.680    keyup\n",
      "185   t  113543.005  keydown\n",
      "186      113568.730    keyup\n",
      "187   t  113667.815    keyup\n",
      "188   h  113675.445  keydown\n",
      "189   e  113715.235  keydown\n",
      "190   h  113789.510    keyup\n",
      "191      113858.390  keydown\n",
      "192   e  113888.250    keyup\n",
      "193      113967.980    keyup\n",
      "194   β  114012.835  keydown\n",
      "195   b  114104.850  keydown\n",
      "196   β  114181.535    keyup\n",
      "197   b  114208.220    keyup\n",
      "198   y  114285.820  keydown\n",
      "199   y  114390.065    keyup\n",
      "200   s  114492.065  keydown\n",
      "201   s  114685.720    keyup\n",
      "202   €  115026.470  keydown\n",
      "203   €  115115.575    keyup\n",
      "204   z  115132.055  keydown\n",
      "205   z  115207.485    keyup\n",
      "206   a  115287.710  keydown\n",
      "207   a  115360.520    keyup\n",
      "208   n  115373.020  keydown\n",
      "209   n  115470.155    keyup\n",
      "210   s  115574.420  keydown\n",
      "211   s  115721.175    keyup\n",
      "212   €  115909.355  keydown\n",
      "213   €  115981.405    keyup\n",
      "214   t  116034.040  keydown\n",
      "215   i  116138.440  keydown\n",
      "216   t  116165.120    keyup\n",
      "217   n  116216.665  keydown\n",
      "218   e  116289.290  keydown\n",
      "219   i  116295.620    keyup\n",
      "220   n  116318.535    keyup\n",
      "221   e  116493.190    keyup\n",
      "222   £  116729.550  keydown\n",
      "223   £  116835.630    keyup\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    key   timestamp     type\n",
      "0     β   98425.515  keydown\n",
      "1     t   98527.630  keydown\n",
      "2     β   98619.790    keyup\n",
      "3     t   98633.330    keyup\n",
      "4     h   98661.565  keydown\n",
      "5     e   98726.280  keydown\n",
      "6     h   98781.095    keyup\n",
      "7         98825.725  keydown\n",
      "8     e   98842.220    keyup\n",
      "9     β   98880.230  keydown\n",
      "10    f   98977.310  keydown\n",
      "11        99001.115    keyup\n",
      "12    f   99078.715    keyup\n",
      "13    β   99126.280    keyup\n",
      "14    r   99136.235  keydown\n",
      "15    r   99235.735    keyup\n",
      "16    a   99245.470  keydown\n",
      "17    n   99309.495  keydown\n",
      "18    a   99388.815    keyup\n",
      "19    k   99401.990  keydown\n",
      "20    n   99471.170    keyup\n",
      "21    s   99528.500  keydown\n",
      "22    k   99545.945    keyup\n",
      "23        99620.045  keydown\n",
      "24    s   99640.170    keyup\n",
      "25    a   99734.925  keydown\n",
      "26        99755.130    keyup\n",
      "27    l   99826.120  keydown\n",
      "28    l   99919.650    keyup\n",
      "29    a   99927.060    keyup\n",
      "30    l   99990.355  keydown\n",
      "31    i  100132.095  keydown\n",
      "32    l  100207.085    keyup\n",
      "33    a  100283.745  keydown\n",
      "34    i  100295.935    keyup\n",
      "35    n  100364.940  keydown\n",
      "36    a  100383.085    keyup\n",
      "37    n  100472.535    keyup\n",
      "38    c  100592.160  keydown\n",
      "39    c  100695.120    keyup\n",
      "40    e  100765.010  keydown\n",
      "41    e  100874.720    keyup\n",
      "42       100914.135  keydown\n",
      "43    w  101010.585  keydown\n",
      "44       101061.205    keyup\n",
      "45    w  101108.415    keyup\n",
      "46    a  101180.130  keydown\n",
      "47    s  101234.915  keydown\n",
      "48    a  101291.405    keyup\n",
      "49       101314.365  keydown\n",
      "50    s  101383.515    keyup\n",
      "51       101497.430    keyup\n",
      "52    i  101505.925  keydown\n",
      "53    m  101624.590  keydown\n",
      "54    i  101686.210    keyup\n",
      "55    p  101738.095  keydown\n",
      "56    m  101803.725    keyup\n",
      "57    o  101847.540  keydown\n",
      "58    p  101943.930    keyup\n",
      "59    o  102031.830    keyup\n",
      "60    r  102064.490  keydown\n",
      "61    r  102175.570    keyup\n",
      "62    a  102215.545  keydown\n",
      "63    n  102352.590  keydown\n",
      "64    a  102379.390    keyup\n",
      "65    t  102459.575  keydown\n",
      "66    n  102469.355    keyup\n",
      "67       102580.810  keydown\n",
      "68    t  102588.555    keyup\n",
      "69    e  102672.150  keydown\n",
      "70    e  102753.140    keyup\n",
      "71       102774.405    keyup\n",
      "72    x  102836.610  keydown\n",
      "73    x  102962.775    keyup\n",
      "74    a  102990.560  keydown\n",
      "75    a  103132.165    keyup\n",
      "76    α  103372.665  keydown\n",
      "77    α  103879.135  keydown\n",
      "78    α  103911.880  keydown\n",
      "79    α  103944.405  keydown\n",
      "80    α  103977.625  keydown\n",
      "81    α  104008.340  keydown\n",
      "82    α  104018.140    keyup\n",
      "83    α  104279.710  keydown\n",
      "84    α  104418.630    keyup\n",
      "85    t  104550.470  keydown\n",
      "86    t  104640.195    keyup\n",
      "87    a  104689.360  keydown\n",
      "88    n  104830.590  keydown\n",
      "89    a  104846.105    keyup\n",
      "90    t  104935.335  keydown\n",
      "91    n  104947.870    keyup\n",
      "92       105012.730  keydown\n",
      "93    t  105041.900    keyup\n",
      "94    e  105168.490  keydown\n",
      "95       105188.260    keyup\n",
      "96    e  105248.790    keyup\n",
      "97    x  105327.185  keydown\n",
      "98    x  105508.180    keyup\n",
      "99    a  105774.885  keydown\n",
      "100   a  105908.580    keyup\n",
      "101   c  106000.615  keydown\n",
      "102   p  106109.950  keydown\n",
      "103   c  106165.210    keyup\n",
      "104   p  106231.040    keyup\n",
      "105   α  106497.430  keydown\n",
      "106   α  106586.315    keyup\n",
      "107   t  106787.340  keydown\n",
      "108   l  106906.265  keydown\n",
      "109   t  106924.555    keyup\n",
      "110   y  107039.160  keydown\n",
      "111   l  107085.845    keyup\n",
      "112   y  107141.120    keyup\n",
      "113      107254.195  keydown\n",
      "114      107398.285    keyup\n",
      "115   b  107404.215  keydown\n",
      "116   b  107485.140    keyup\n",
      "117   e  107550.360  keydown\n",
      "118   e  107651.615    keyup\n",
      "119   c  107706.545  keydown\n",
      "120   a  107806.335  keydown\n",
      "121   c  107821.380    keyup\n",
      "122   u  107914.995  keydown\n",
      "123   a  107927.750    keyup\n",
      "124   s  107974.440  keydown\n",
      "125   u  108027.170    keyup\n",
      "126   e  108066.630  keydown\n",
      "127   s  108109.460    keyup\n",
      "128      108161.580  keydown\n",
      "129   e  108210.715    keyup\n",
      "130   o  108262.725  keydown\n",
      "131      108278.240    keyup\n",
      "132   f  108335.015  keydown\n",
      "133      108414.560  keydown\n",
      "134   f  108424.450    keyup\n",
      "135   o  108430.760    keyup\n",
      "136   t  108476.665  keydown\n",
      "137      108560.600    keyup\n",
      "138   h  108564.670  keydown\n",
      "139   t  108572.185    keyup\n",
      "140   e  108645.740  keydown\n",
      "141   h  108690.105    keyup\n",
      "142   e  108757.600    keyup\n",
      "143   i  108771.775  keydown\n",
      "144   r  108849.280  keydown\n",
      "145   i  108884.265    keyup\n",
      "146      108931.395  keydown\n",
      "147   r  109029.830    keyup\n",
      "148      109067.700    keyup\n",
      "149   r  109578.895  keydown\n",
      "150   e  109720.355  keydown\n",
      "151   r  109736.275    keyup\n",
      "152   e  109881.605    keyup\n",
      "153   n  109980.920  keydown\n",
      "154   n  110085.080    keyup\n",
      "155   o  110091.775  keydown\n",
      "156   o  110201.555    keyup\n",
      "157   w  110269.125  keydown\n",
      "158   n  110388.055  keydown\n",
      "159   w  110462.460    keyup\n",
      "160   n  110521.075    keyup\n",
      "161      110591.050  keydown\n",
      "162      110698.220    keyup\n",
      "163   h  110765.435  keydown\n",
      "164   o  110852.380  keydown\n",
      "165   h  110874.725    keyup\n",
      "166   o  110988.310    keyup\n",
      "167   s  111016.105  keydown\n",
      "168   s  111164.620    keyup\n",
      "169   t  111200.005  keydown\n",
      "170   i  111276.420  keydown\n",
      "171   t  111361.525    keyup\n",
      "172   i  111386.260    keyup\n",
      "173   l  111448.245  keydown\n",
      "174   i  111512.405  keydown\n",
      "175   l  111598.280    keyup\n",
      "176   i  111672.070    keyup\n",
      "177   t  111675.360  keydown\n",
      "178   y  111741.550  keydown\n",
      "179   t  111802.635    keyup\n",
      "180      111845.335  keydown\n",
      "181   y  111874.630    keyup\n",
      "182   t  111932.010  keydown\n",
      "183      111981.440    keyup\n",
      "184   o  112006.895  keydown\n",
      "185   t  112026.690    keyup\n",
      "186   w  112106.665  keydown\n",
      "187   o  112140.390    keyup\n",
      "188   w  112190.380    keyup\n",
      "189   a  112232.125  keydown\n",
      "190   r  112319.105  keydown\n",
      "191   a  112367.020    keyup\n",
      "192   r  112444.105    keyup\n",
      "193   s  112597.120  keydown\n",
      "194   s  112781.005    keyup\n",
      "195   α  113126.415  keydown\n",
      "196   α  113221.070    keyup\n",
      "197   d  113232.380  keydown\n",
      "198   s  113304.525  keydown\n",
      "199   d  113344.465    keyup\n",
      "200      113451.265  keydown\n",
      "201   s  113459.680    keyup\n",
      "202   t  113543.005  keydown\n",
      "203      113568.730    keyup\n",
      "204   t  113667.815    keyup\n",
      "205   h  113675.445  keydown\n",
      "206   e  113715.235  keydown\n",
      "207   h  113789.510    keyup\n",
      "208      113858.390  keydown\n",
      "209   e  113888.250    keyup\n",
      "210      113967.980    keyup\n",
      "211   β  114012.835  keydown\n",
      "212   b  114104.850  keydown\n",
      "213   β  114181.535    keyup\n",
      "214   b  114208.220    keyup\n",
      "215   y  114285.820  keydown\n",
      "216   y  114390.065    keyup\n",
      "217   s  114492.065  keydown\n",
      "218   s  114685.720    keyup\n",
      "219   α  115026.470  keydown\n",
      "220   α  115115.575    keyup\n",
      "221   z  115132.055  keydown\n",
      "222   z  115207.485    keyup\n",
      "223   a  115287.710  keydown\n",
      "224   a  115360.520    keyup\n",
      "225   n  115373.020  keydown\n",
      "226   n  115470.155    keyup\n",
      "227   s  115574.420  keydown\n",
      "228   s  115721.175    keyup\n",
      "229   α  115909.355  keydown\n",
      "230   α  115981.405    keyup\n",
      "231   t  116034.040  keydown\n",
      "232   i  116138.440  keydown\n",
      "233   t  116165.120    keyup\n",
      "234   n  116216.665  keydown\n",
      "235   e  116289.290  keydown\n",
      "236   i  116295.620    keyup\n",
      "237   n  116318.535    keyup\n",
      "238   e  116493.190    keyup\n",
      "239   £  116729.550  keydown\n",
      "240   £  116835.630    keyup\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(tmp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-147-70746b8d4144>(63)backspace_implementer_mrc()\n",
      "-> keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-224-b116ff6d38ef>\", line 4, in <module>\n",
      "    annoying_fuck = backspace_implementer_mrc(test_df)\n",
      "  File \"<ipython-input-147-70746b8d4144>\", line 63, in backspace_implementer_mrc\n",
      "    keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n",
      "  File \"<ipython-input-147-70746b8d4144>\", line 63, in backspace_implementer_mrc\n",
      "    keyup_timestamp = df_keyup.loc[(df_keyup[\"timestamp\"] >= df.loc[gg[-1], \"timestamp\"])].timestamp.values[0]\n",
      "  File \"/home/neil/anaconda3/envs/py36/lib/python3.6/bdb.py\", line 51, in trace_dispatch\n",
      "    return self.dispatch_line(frame)\n",
      "  File \"/home/neil/anaconda3/envs/py36/lib/python3.6/bdb.py\", line 70, in dispatch_line\n",
      "    if self.quitting: raise BdbQuit\n",
      "bdb.BdbQuit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/neil/anaconda3/envs/py36/lib/python3.6/bdb.py(70)dispatch_line()\n",
      "-> if self.quitting: raise BdbQuit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  quit\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "try:\n",
    "    annoying_fuck = backspace_implementer_mrc(test_df)\n",
    "except:\n",
    "    extype, value, tb = sys.exc_info()\n",
    "    traceback.print_exc()\n",
    "    pdb.post_mortem(tb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
