{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "# Set path to find modelling tools for later use\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "\n",
    "from haberrspd.preprocess import preprocessMJFF\n",
    "                         \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from scipy.stats import (gamma, lognorm, gengamma)\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Plot stuff\n",
    "import seaborn as sns\n",
    "from scipy.constants import golden\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Depending on where I am, set the path\n",
    "import socket\n",
    "if socket.gethostname() == 'pax':\n",
    "    # Monster machine\n",
    "    data_root = '../data/MJFF/' # My local path\n",
    "    data_root = Path(data_root)\n",
    "else:\n",
    "    # Laptop\n",
    "    data_root = '/home/nd/data/liverpool/MJFF' # My local path\n",
    "    data_root = Path(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character + Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/SpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/EnglishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_root / 'SpanishData-duplicateeventsremoved.csv')\n",
    "df = pd.read_csv(data_root / 'SpanishData.csv')\n",
    "df_meta = pd.read_csv(data_root / \"SpanishParticipantKey.csv\",\n",
    "                      index_col=0,\n",
    "                      header=0,\n",
    "                      names=['participant_id', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character ONLY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = preprocessMJFF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = proc('english',include_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Preprocessed_typed_sentence'].apply(lambda x: len(x) < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"../data/MJFF/preproc/char/EnglishSpanishData-preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = set(df_meta.loc[df_meta.diagnosis == 0].participant_id)\n",
    "pd_subjects = set(df_meta.loc[df_meta.diagnosis == 1].participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in pd_subjects:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    pd_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)\n",
    "    \n",
    "control_timestamp_diffs = []\n",
    "# Loop over all subjects\n",
    "for sub in controls:\n",
    "    # Get all delta timestamps for this sentence, across all subjects\n",
    "    control_timestamp_diffs.extend(df.loc[(df.sentence_id == 57) & (df.participant_id == sub)].timestamp.diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs\n",
    "pd_cleaned_list = [x for x in pd_timestamp_diffs if str(x) != 'nan']\n",
    "control_cleaned_list = [x for x in control_timestamp_diffs if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(pd_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 10000, 50) # fixed bin size\n",
    "# plt.xlim([min(data)-5, max(data)+5])\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.hist(control_cleaned_list, bins=bins, alpha=0.5)\n",
    "# plt.vlines(np.quantile(cleaned_list,0.95),0,900,'r')\n",
    "# plt.vlines(np.mean(cleaned_list),0,900,'b')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical turk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(data_root /'preprocessed_MechanicalTurkCombinedEnglishData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/MJFF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IKI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_mjff_iki_training_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_mjff_data_objects, us_standard_layout_keyboard, english_keys_to_2d_coordinates\n",
    "import keras.backend as K\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, int64, ones, hstack, pad, einsum, dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import cast, float32, one_hot\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time_space\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "if which_information == \"char_time_space\":\n",
    "    # Get relevant long-format data\n",
    "    which_information = \"char_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "\n",
    "# Store alphabet size\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "print('Total number of characters:', alphabet_size)\n",
    "alphabet_indices = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "if which_information == \"char_time\" or which_information == \"char_time_space\":\n",
    "    # Rounds (up) to nearest thousand\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -3)\n",
    "if which_information == \"char\":\n",
    "    # Rounds (up) to nearest hundred\n",
    "    max_sentence_length = round(df.Preprocessed_typed_sentence.apply(lambda x: len(x)).max(), -2)\n",
    "\n",
    "# Make training data array\n",
    "all_sentences = [item for sublist in subject_documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer which maps characters to integers\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "\n",
    "# Fit to text: convert all chars to ints\n",
    "tk.fit_on_texts(all_sentences)\n",
    "\n",
    "# Update alphabet\n",
    "tk.word_index = alphabet_indices\n",
    "\n",
    "# Get integer sequences: converts sequences of chars to sequences of ints\n",
    "int_sequences = tk.texts_to_sequences(all_sentences)\n",
    "\n",
    "# Pad sequences so that they all have the same length and then one-hot encode\n",
    "X = to_categorical(pad_sequences(int_sequences, maxlen=max_sentence_length, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information  =  'char_time_space'\n",
    "if which_information == 'char_time_space':\n",
    "    # Load relevant keyboard\n",
    "    keyboard = us_standard_layout_keyboard()  # OBS: nested list\n",
    "    # Check that all chars are in fact in our \"keyboard\" -- if not, we cannot map a coordinate\n",
    "    assert alphabet.issubset(set(list(itertools.chain.from_iterable(keyboard))))\n",
    "    space = [english_keys_to_2d_coordinates(sentence, keyboard) for sentence in all_sentences]\n",
    "    space_padded = [pad(s, [(0, max_sentence_length - len(s)), (0, 0)], mode='constant') for s in space]\n",
    "    # Append coordinates to one-hot encoded sentences\n",
    "    X = einsum('ijk->kij', dstack([hstack((x, s)) for (x, s) in zip(X, space_padded)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document (participant) -level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three options (at time of writing):\n",
    "\n",
    "1. Submit each sentence to model and extract classification probability for each sentence, agglomorate at the end, and the conduct a classification on the vector of all 15 probabilities.\n",
    "2. Calculate the expected value of all encoded (15) sentences and then pass this to the model and take the classification.\n",
    "3. Vertically stack all embedded sentences, and let the convolution run over this (very long) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haberrspd.charCNN.data_utils_tf import create_training_data_keras, create_mjff_data_objects\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_information = \"char_time\"\n",
    "DATA_ROOT = Path(\"../data/\") / \"MJFF\" / \"preproc\"\n",
    "data_string = \"EnglishData-preprocessed.csv\"\n",
    "df = read_csv(DATA_ROOT / which_information / data_string, header=0)  # MJFF data\n",
    "# subject_documents, subjects_diagnoses, alphabet = create_mjff_data_objects(df)\n",
    "# X_train, X_test, y_train, y_test, max_sentence_length, alphabet_size = create_training_data_keras(DATA_ROOT, which_information, data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in subject_documents[:3]:\n",
    "    print(doc[:2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Homogenise so that Spacebar is a blank character\n",
    "0. Delete rubbish characters (i.e. remove the rows)\n",
    "2. What to do with stuff like Shift\n",
    "3. Figure out what to do when multiple characters are depressed simultaneously\n",
    "4. Make lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from haberrspd.preprocess import clean_MRC, backspace_corrector, make_character_compression_time_sentence, reorder_key_timestamp_columns_mrc, calculate_edit_distance_between_response_and_target_MRC\n",
    "from haberrspd.charCNN.data_utils_tf import us_english_keyboard_mrc\n",
    "from numpy import concatenate\n",
    "from typing import Tuple\n",
    "import random\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from itertools import compress, count\n",
    "from operator import itemgetter\n",
    "\n",
    "# Monster machine\n",
    "data_root = '../data/MRC/' # My local path\n",
    "data_root = Path(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv(data_root / \"CombinedTypingDataSept27.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of sentences with 'high' Levenshtein distance...\n",
      "\n",
      "Size of dataframe before row pruning: (814388, 12)\n",
      "Size of dataframe after row pruning: (812330, 12)\n",
      "\n",
      "Removal of sentences with left/right arrows keys...\n",
      "\n",
      "Size of dataframe before row pruning: (812330, 12)\n",
      "Size of dataframe after row pruning: (780201, 12)\n",
      "\n",
      "Removal of sentences with faulty data collection...\n",
      "\n",
      "Size of dataframe before row pruning: (780201, 12)\n",
      "Size of dataframe after row pruning: (699032, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "      <td>1</td>\n",
       "      <td>25885.055</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26086.840</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>shift</td>\n",
       "      <td>keyup</td>\n",
       "      <td>1</td>\n",
       "      <td>26181.975</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>keyup</td>\n",
       "      <td>0</td>\n",
       "      <td>26193.745</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>o</td>\n",
       "      <td>keydown</td>\n",
       "      <td>0</td>\n",
       "      <td>26321.480</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key     type  location  timestamp  participant_id  sentence_id  diagnosis\n",
       "0  shift  keydown         1  25885.055            1010            1          0\n",
       "1      h  keydown         0  26086.840            1010            1          0\n",
       "2  shift    keyup         1  26181.975            1010            1          0\n",
       "3      h    keyup         0  26193.745            1010            1          0\n",
       "4      o  keydown         0  26321.480            1010            1          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clean_MRC(df)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.copy(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol to process the MRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A form of `create_char_compression_time_mjff_data` [to get the temporal data] <-- this needs to be set so that we get a list of \n",
    "2. Second use `create_dataframe_from_processed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_compression_time_mrc_data(df: pd.DataFrame, \n",
    "                                          time_redux_fact=10) -> Tuple[dict, list]:\n",
    "\n",
    "    assert set([\"participant_id\", \"key\", \"timestamp\", \"sentence_id\"]).issubset(df.columns)\n",
    "\n",
    "    # All sentences will be stored here, indexed by their type\n",
    "    char_compression_sentences = defaultdict(dict)\n",
    "    \n",
    "    # Get the unique number of subjects\n",
    "    subjects = sorted(set(df.participant_id))\n",
    "\n",
    "    # Loop over subjects\n",
    "    for subj_idx in subjects:\n",
    "        # Not all subjects have typed all sentences hence we have to do it this way\n",
    "        for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "            \n",
    "            # Locate df segment to extract\n",
    "            coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "            \n",
    "            print(\"Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "            \n",
    "            # Get correctly ordered sentences and total compression times\n",
    "            df_tmp = reorder_key_timestamp_columns_mrc(df.loc[coordinates, ('key','timestamp')])\n",
    "            \n",
    "            # TODO: check to see if the key-compression column follows the correct order\n",
    "            \n",
    "            \n",
    "            # \"correct\" the sentence by operating on user backspaces \n",
    "            corrected_char_sentence, removed_chars_indx = backspace_corrector(df_tmp.key.tolist())\n",
    "            \n",
    "            compression_times = calculate_total_key_compression_time(df_tmp.drop(df_tmp.index[removed_chars_indx]))\n",
    "            \n",
    "            assert len(compression_times) == len(corrected_char_sentence[::2]), \"Error at ({},{}).\".format(subj_idx,sent_idx)\n",
    "            assert any(x < 0 for x in compression_times) is False, \"Error at ({},{}).\".format(subj_idx,sent_idx) # Check no negative timings\n",
    "\n",
    "            # Make long-format version of each typed, corrected, sentence\n",
    "            # Note that we remove the last character to make the calculation correct.\n",
    "            char_compression_sentences[subj_idx][sent_idx] = make_character_compression_time_sentence(compression_times,\n",
    "                                                                                                      corrected_char_sentence[::2], \n",
    "                                                                                                      time_redux_fact)\n",
    "    return char_compression_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(v, d={}, c=count()):\n",
    "    if v in d:\n",
    "        return d.pop(v)\n",
    "    else:\n",
    "        d[v] = next(c)\n",
    "        return d[v]\n",
    "\n",
    "def reorder_key_timestamp_columns_mrc(df: pd.DataFrame):\n",
    "\n",
    "    # Check that the column is of even length\n",
    "    assert len(df) % 2 == 0, \"The length is {}.\".format(len(df))\n",
    "\n",
    "    # Use lookup function to extract the next row-order\n",
    "    df[\"new_row_order\"] = df.key.map(lookup)\n",
    "    \n",
    "    # Don't return an object, just leave as is\n",
    "    return df.sort_values(by=\"new_row_order\", kind=\"mergesort\").drop(\"new_row_order\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 114,   89,   96, 1120, 1082,   61, 1038,   87, 1144,   60])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(df.participant_id.unique(),size=10,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[broken sentence] Participant: 60, Sentence: 12\n",
      "[broken sentence] Participant: 47, Sentence: 5\n",
      "[broken sentence] Participant: 47, Sentence: 14\n",
      "[broken sentence] Participant: 1025, Sentence: 2\n",
      "[broken sentence] Participant: 64, Sentence: 10\n",
      "[broken sentence] Participant: 1122, Sentence: 2\n",
      "[broken sentence] Participant: 1122, Sentence: 8\n",
      "[broken sentence] Participant: 1122, Sentence: 10\n",
      "[broken sentence] Participant: 62, Sentence: 14\n",
      "[broken sentence] Participant: 1078, Sentence: 5\n",
      "[broken sentence] Participant: 1078, Sentence: 4\n",
      "[broken sentence] Participant: 1078, Sentence: 12\n",
      "[broken sentence] Participant: 1055, Sentence: 11\n",
      "[broken sentence] Participant: 11, Sentence: 2\n",
      "[broken sentence] Participant: 11, Sentence: 4\n",
      "[broken sentence] Participant: 11, Sentence: 1\n",
      "[broken sentence] Participant: 11, Sentence: 5\n",
      "[broken sentence] Participant: 11, Sentence: 3\n",
      "[broken sentence] Participant: 11, Sentence: 10\n",
      "[broken sentence] Participant: 11, Sentence: 9\n",
      "[broken sentence] Participant: 11, Sentence: 7\n",
      "[broken sentence] Participant: 11, Sentence: 8\n",
      "[broken sentence] Participant: 11, Sentence: 14\n",
      "[broken sentence] Participant: 11, Sentence: 6\n",
      "[broken sentence] Participant: 11, Sentence: 15\n",
      "[broken sentence] Participant: 11, Sentence: 12\n",
      "[broken sentence] Participant: 11, Sentence: 11\n",
      "[broken sentence] Participant: 11, Sentence: 13\n",
      "[broken sentence] Participant: 106, Sentence: 10\n",
      "[broken sentence] Participant: 106, Sentence: 15\n",
      "[broken sentence] Participant: 12, Sentence: 9\n",
      "[broken sentence] Participant: 108, Sentence: 6\n",
      "[broken sentence] Participant: 86, Sentence: 2\n",
      "[broken sentence] Participant: 86, Sentence: 5\n",
      "[broken sentence] Participant: 86, Sentence: 7\n",
      "[broken sentence] Participant: 86, Sentence: 14\n",
      "[broken sentence] Participant: 86, Sentence: 11\n",
      "[broken sentence] Participant: 33, Sentence: 2\n",
      "[broken sentence] Participant: 33, Sentence: 1\n",
      "[broken sentence] Participant: 33, Sentence: 3\n",
      "[broken sentence] Participant: 1166, Sentence: 12\n",
      "[broken sentence] Participant: 1166, Sentence: 13\n",
      "[broken sentence] Participant: 1010, Sentence: 11\n",
      "[broken sentence] Participant: 1096, Sentence: 1\n",
      "[broken sentence] Participant: 1096, Sentence: 5\n",
      "[broken sentence] Participant: 1096, Sentence: 6\n",
      "[broken sentence] Participant: 1096, Sentence: 10\n",
      "[broken sentence] Participant: 1096, Sentence: 14\n",
      "[broken sentence] Participant: 1096, Sentence: 15\n",
      "[broken sentence] Participant: 68, Sentence: 4\n",
      "[broken sentence] Participant: 68, Sentence: 12\n",
      "[broken sentence] Participant: 1030, Sentence: 2\n",
      "[broken sentence] Participant: 110, Sentence: 10\n",
      "[broken sentence] Participant: 110, Sentence: 6\n",
      "[broken sentence] Participant: 87, Sentence: 10\n",
      "[broken sentence] Participant: 87, Sentence: 15\n",
      "[broken sentence] Participant: 1150, Sentence: 5\n",
      "[broken sentence] Participant: 1150, Sentence: 6\n",
      "[broken sentence] Participant: 1150, Sentence: 8\n",
      "[broken sentence] Participant: 1150, Sentence: 11\n",
      "[broken sentence] Participant: 1150, Sentence: 12\n",
      "[broken sentence] Participant: 1150, Sentence: 13\n",
      "[broken sentence] Participant: 1150, Sentence: 14\n",
      "[broken sentence] Participant: 1121, Sentence: 5\n",
      "[broken sentence] Participant: 1121, Sentence: 10\n",
      "[broken sentence] Participant: 1121, Sentence: 11\n",
      "[broken sentence] Participant: 1021, Sentence: 2\n",
      "[broken sentence] Participant: 1021, Sentence: 4\n",
      "[broken sentence] Participant: 1021, Sentence: 7\n",
      "[broken sentence] Participant: 1021, Sentence: 8\n",
      "[broken sentence] Participant: 1021, Sentence: 10\n",
      "[broken sentence] Participant: 1075, Sentence: 1\n",
      "[broken sentence] Participant: 1075, Sentence: 2\n",
      "[broken sentence] Participant: 1075, Sentence: 5\n",
      "[broken sentence] Participant: 1075, Sentence: 3\n",
      "[broken sentence] Participant: 1075, Sentence: 6\n",
      "[broken sentence] Participant: 1075, Sentence: 8\n",
      "[broken sentence] Participant: 1075, Sentence: 9\n",
      "[broken sentence] Participant: 1075, Sentence: 12\n",
      "[broken sentence] Participant: 1075, Sentence: 14\n",
      "[broken sentence] Participant: 1075, Sentence: 15\n",
      "[broken sentence] Participant: 1134, Sentence: 4\n",
      "[broken sentence] Participant: 1134, Sentence: 6\n",
      "[broken sentence] Participant: 1134, Sentence: 12\n",
      "[broken sentence] Participant: 1134, Sentence: 15\n",
      "[broken sentence] Participant: 1142, Sentence: 6\n",
      "[broken sentence] Participant: 51, Sentence: 10\n",
      "[broken sentence] Participant: 1156, Sentence: 2\n",
      "[broken sentence] Participant: 49, Sentence: 2\n",
      "[broken sentence] Participant: 49, Sentence: 4\n",
      "[broken sentence] Participant: 49, Sentence: 1\n",
      "[broken sentence] Participant: 49, Sentence: 5\n",
      "[broken sentence] Participant: 49, Sentence: 10\n",
      "[broken sentence] Participant: 49, Sentence: 9\n",
      "[broken sentence] Participant: 49, Sentence: 7\n",
      "[broken sentence] Participant: 49, Sentence: 8\n",
      "[broken sentence] Participant: 49, Sentence: 15\n",
      "[broken sentence] Participant: 49, Sentence: 11\n",
      "[broken sentence] Participant: 49, Sentence: 13\n",
      "538 99\n"
     ]
    }
   ],
   "source": [
    "# TODO: backstop removal before any of this is run properly\n",
    "# Test just a single sentence here\n",
    "\n",
    "\n",
    "fail=0\n",
    "success=0\n",
    "\n",
    "for subj_idx in np.random.choice(df.participant_id.unique(),size=50,replace=False):\n",
    "    # Not all subjects have typed all sentences hence we have to do it this way\n",
    "    for sent_idx in df.loc[(df.participant_id == subj_idx)].sentence_id.unique():\n",
    "        \n",
    "        # Locate df segment to extract\n",
    "        coordinates = (df.participant_id == subj_idx) & (df.sentence_id == sent_idx)\n",
    "        \n",
    "        # Store temporary dataframe because why not\n",
    "        tmp = df.loc[coordinates, ('key','timestamp','type')].reset_index(drop=True) # Reset index \n",
    "        \n",
    "        # Get correctly ordered sentences and total compression times\n",
    "        new = new_sort(tmp)\n",
    "        \n",
    "        if not assess_repeating_key_compression_pattern(new.type.tolist()):\n",
    "            # Condition fails: data-collection is broken\n",
    "\n",
    "            combine_shift_keydowns_without_matching_keyup(new) \n",
    "            # Re-do sorting\n",
    "            new = new_sort(tmp)\n",
    "\n",
    "            if assess_repeating_key_compression_pattern(new.type.tolist()):\n",
    "                # Condition succeeds: data-collection is fixed    \n",
    "                success+=1\n",
    "            else:\n",
    "                # Condition fails: data-collection is broken\n",
    "                fail+=1\n",
    "                print(\"[broken sentence] Participant: {}, Sentence: {}\".format(subj_idx, sent_idx))\n",
    "        else:\n",
    "            # Condition succeeds: data-collection is fixed\n",
    "            \n",
    "            success+=1\n",
    "            \n",
    "print(success, fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = copy.copy(df.loc[(df.participant_id == 49) & (df.sentence_id == 13), (\"key\", \"timestamp\",\"type\")].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "£\n"
     ]
    }
   ],
   "source": [
    "for key, value in Counter(test_df.key.tolist()).items():\n",
    "    if value % 2 != 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = test_df.loc[test_df.key == '*'].index\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([159, 258, 259], dtype='int64')\n",
      "(159, 258)\n",
      "99\n",
      "(258, 259)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(idxs)\n",
    "for pair in zip(idxs,idxs[1:]):\n",
    "    print(pair)\n",
    "    print(pair[1] - pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_solitary_key_presses(df, horizon = 5):\n",
    "\n",
    "    \n",
    "    suspect_keys = []\n",
    "    for key, value in Counter(df.key.tolist()).items():\n",
    "        if value % 2 != 0:\n",
    "            suspect_keys.append(key)\n",
    "    \n",
    "    # Find all instances of suspect keys in df\n",
    "    removal_coordinates = []\n",
    "    if len(suspect_keys) != 0:\n",
    "        for key in suspect_keys:\n",
    "            # Find index location of all suspicious keys\n",
    "            idxs = df.loc[df.key == key].index\n",
    "            if len(idxs) >= 2:\n",
    "                # If there is more than one such key\n",
    "                for pair in zip(idxs, idxs[1:]):\n",
    "                    if pair[1] - pair[0] > horizon:\n",
    "                        removal_coordinates.extend(pair[0])\n",
    "            else:\n",
    "                # If there is only one index of this key\n",
    "                # that is already an erroneous entry.\n",
    "                \n",
    "        \n",
    "        # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "        df.drop(df.index[removal_coordinates], inplace=True)\n",
    "        # Reset index so that we can sort it properly in the next step\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_shift_keydowns_without_matching_keyup(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>shift</td>\n",
       "      <td>501093.142367</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>501461.642586</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>shift</td>\n",
       "      <td>501652.342411</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>501684.642522</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v</td>\n",
       "      <td>501764.042641</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>e</td>\n",
       "      <td>536324.742626</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>t</td>\n",
       "      <td>536340.442428</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>t</td>\n",
       "      <td>536549.542371</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>£</td>\n",
       "      <td>536781.642610</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>£</td>\n",
       "      <td>537021.342609</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key      timestamp     type\n",
       "0    shift  501093.142367  keydown\n",
       "1        o  501461.642586  keydown\n",
       "2    shift  501652.342411    keyup\n",
       "3        o  501684.642522    keyup\n",
       "4        v  501764.042641  keydown\n",
       "..     ...            ...      ...\n",
       "255      e  536324.742626    keyup\n",
       "256      t  536340.442428  keydown\n",
       "257      t  536549.542371    keyup\n",
       "258      £  536781.642610  keydown\n",
       "259      £  537021.342609    keyup\n",
       "\n",
       "[260 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "outt = new_sort(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key      timestamp     type\n",
      "0    shift  501093.142367  keydown\n",
      "1    shift  501652.342411    keyup\n",
      "2        o  501461.642586  keydown\n",
      "3        o  501684.642522    keyup\n",
      "4        v  501764.042641  keydown\n",
      "5        v  501933.042600    keyup\n",
      "6        e  501980.242364  keydown\n",
      "7        e  502164.342389    keyup\n",
      "8        r  502093.842460  keydown\n",
      "9        r  502332.842367    keyup\n",
      "10          502236.242504  keydown\n",
      "11          502468.542554    keyup\n",
      "12       t  502526.342563  keydown\n",
      "13       t  502740.742477    keyup\n",
      "14       h  502764.442566  keydown\n",
      "15       h  503012.542475    keyup\n",
      "16       r  502949.742363  keydown\n",
      "17       r  503164.842369    keyup\n",
      "18       e  503099.942580  keydown\n",
      "19       e  503221.242493    keyup\n",
      "20       e  503276.442544  keydown\n",
      "21       e  503477.542501    keyup\n",
      "22          503452.942507  keydown\n",
      "23          503660.542509    keyup\n",
      "24       m  503845.242570  keydown\n",
      "25       m  504133.742632    keyup\n",
      "26       i  504333.842628  keydown\n",
      "27       i  504565.542642    keyup\n",
      "28       l  504789.442483  keydown\n",
      "29       l  504908.842531    keyup\n",
      "30       l  505013.142512  keydown\n",
      "31       l  505124.942498    keyup\n",
      "32       i  505405.442574  keydown\n",
      "33       i  505668.742607    keyup\n",
      "34       o  505725.942579  keydown\n",
      "35       o  506060.842557    keyup\n",
      "36       n  506092.942555  keydown\n",
      "37       n  506379.942376    keyup\n",
      "38          506284.242417  keydown\n",
      "39          506523.842361    keyup\n",
      "40       c  506508.342370  keydown\n",
      "41       c  506717.542368    keyup\n",
      "42       a  506733.842508  keydown\n",
      "43       a  506934.242372    keyup\n",
      "44       t  506909.542623  keydown\n",
      "45       t  507029.542407    keyup\n",
      "46       t  507100.942541  keydown\n",
      "47       t  507301.042537    keyup\n",
      "48       l  507372.242559  keydown\n",
      "49       l  507629.942451    keyup\n",
      "50       e  507549.442615  keydown\n",
      "51       e  507781.442497    keyup\n",
      "52          507693.042431  keydown\n",
      "53          507900.442621    keyup\n",
      "54       a  507933.742392  keydown\n",
      "55       a  508157.642533    keyup\n",
      "56       r  508068.842543  keydown\n",
      "57       r  508243.842565    keyup\n",
      "58       e  508173.342636  keydown\n",
      "59       e  508373.642444    keyup\n",
      "60          508317.442432  keydown\n",
      "61          508580.242484    keyup\n",
      "62       r  508557.142432  keydown\n",
      "63       r  508757.142372    keyup\n",
      "64       e  508613.142632  keydown\n",
      "65       e  508773.942492    keyup\n",
      "66       s  508813.542496  keydown\n",
      "67       s  509021.642477    keyup\n",
      "68       i  509276.042620  keydown\n",
      "69       i  509508.242614    keyup\n",
      "70       d  509522.942456  keydown\n",
      "71       d  509637.842381    keyup\n",
      "72       e  509718.242461  keydown\n",
      "73       e  509973.142584    keyup\n",
      "74       n  509989.542479  keydown\n",
      "75       n  510277.942485    keyup\n",
      "76       t  510173.342636  keydown\n",
      "77       t  510309.442447    keyup\n",
      "78       s  510245.142394  keydown\n",
      "79       s  510493.742584    keyup\n",
      "80          510364.042461  keydown\n",
      "81          510605.442514    keyup\n",
      "82       o  510621.142617  keydown\n",
      "83       o  510980.442477    keyup\n",
      "84       f  510780.842461  keydown\n",
      "85       f  510957.142612    keyup\n",
      "86          510901.042357  keydown\n",
      "87          511116.942512    keyup\n",
      "88       t  511052.342591  keydown\n",
      "89       t  511261.242421    keyup\n",
      "90       h  511285.142622  keydown\n",
      "91       h  511573.542628    keyup\n",
      "92       e  511355.942419  keydown\n",
      "93       e  511534.142436    keyup\n",
      "94          511557.042376  keydown\n",
      "95          511828.842374    keyup\n",
      "96       p  512164.542501  keydown\n",
      "97       p  512405.342518    keyup\n",
      "98       r  512389.242491  keydown\n",
      "99       r  512573.742440    keyup\n",
      "100      o  512548.742522  keydown\n",
      "101      o  512780.742405    keyup\n",
      "102      v  512796.042584  keydown\n",
      "103      v  512989.142555    keyup\n",
      "104      i  513205.042410  keydown\n",
      "105      i  513461.442473    keyup\n",
      "106      n  513756.642392  keydown\n",
      "107      n  514038.042373    keyup\n",
      "108      c  513949.742363  keydown\n",
      "109      c  514099.942580    keyup\n",
      "110      e  514213.242508  keydown\n",
      "111      e  514469.042535    keyup\n",
      "112         514389.642415  keydown\n",
      "113         514605.142646    keyup\n",
      "114      a  514621.442485  keydown\n",
      "115      a  514836.942416    keyup\n",
      "116      t  514821.442425  keydown\n",
      "117      t  515029.342595    keyup\n",
      "118         514973.442452  keydown\n",
      "119         515365.042422    keyup\n",
      "120      o  515261.942514  keydown\n",
      "121      o  515516.342656    keyup\n",
      "122      n  515805.442454  keydown\n",
      "123      n  516125.742647    keyup\n",
      "124      e  516029.142483  keydown\n",
      "125      e  516245.942543    keyup\n",
      "126         516197.542404  keydown\n",
      "127         516388.642454    keyup\n",
      "128      t  516477.242633  keydown\n",
      "129      t  516701.142473    keyup\n",
      "130      i  516612.742407  keydown\n",
      "131      i  517085.242438    keyup\n",
      "132      m  517100.842485  keydown\n",
      "133      m  517405.742442    keyup\n",
      "134      e  517277.342448  keydown\n",
      "135      e  517476.542540    keyup\n",
      "136         517436.242444  keydown\n",
      "137         517692.542451    keyup\n",
      "138      o  517876.542420  keydown\n",
      "139      o  518164.942426    keyup\n",
      "140      r  518133.642576  keydown\n",
      "141      r  518323.842421    keyup\n",
      "142         518205.442634  keydown\n",
      "143         518429.142362    keyup\n",
      "144      a  518580.442597  keydown\n",
      "145      a  518837.242585    keyup\n",
      "146      n  518868.842603  keydown\n",
      "147      n  519085.542606    keyup\n",
      "148      o  519108.042622  keydown\n",
      "149      o  519438.742646    keyup\n",
      "150      t  519253.342492  keydown\n",
      "151      t  519501.242589    keyup\n",
      "152      h  519421.542602  keydown\n",
      "153      h  519717.042388    keyup\n",
      "154      e  519621.442485  keydown\n",
      "155      e  519845.842607    keyup\n",
      "156      r  519773.242399  keydown\n",
      "157      r  519964.142637    keyup\n",
      "158      ,  520212.942640  keydown\n",
      "159      £  520477.442444    keyup\n",
      "160      £  536781.642610  keydown\n",
      "161         520493.642528  keydown\n",
      "162         520709.342571    keyup\n",
      "163      a  520693.242544  keydown\n",
      "164      a  520979.942496    keyup\n",
      "165      n  520909.342511  keydown\n",
      "166      n  521197.042424    keyup\n",
      "167      d  521093.242423  keydown\n",
      "168      d  521292.142647    keyup\n",
      "169         521229.342535  keydown\n",
      "170         521428.442570    keyup\n",
      "171  shift  521925.342482  keydown\n",
      "172  shift  522277.542561    keyup\n",
      "173      a  522085.042626  keydown\n",
      "174      a  522332.642555    keyup\n",
      "175      l  522485.042506  keydown\n",
      "176      l  522685.042446    keyup\n",
      "177      b  522677.442384  keydown\n",
      "178      b  522837.242585    keyup\n",
      "179      e  522916.042367  keydown\n",
      "180      e  523109.242395    keyup\n",
      "181      r  523012.042495  keydown\n",
      "182      r  523181.342621    keyup\n",
      "183      t  523244.042377  keydown\n",
      "184      t  523373.042407    keyup\n",
      "185      a  523358.042397  keydown\n",
      "186      a  523580.942577    keyup\n",
      "187         523531.942403  keydown\n",
      "188         523788.942503    keyup\n",
      "189      b  523780.442537  keydown\n",
      "190      b  523931.942583    keyup\n",
      "191      e  524068.742486  keydown\n",
      "192      e  524173.242580    keyup\n",
      "193      e  524253.842472  keydown\n",
      "194      e  524421.642357    keyup\n",
      "195      f  524485.042506  keydown\n",
      "196      f  524661.442413    keyup\n",
      "197         524693.542412  keydown\n",
      "198         525036.642488    keyup\n",
      "199      h  525693.642468  keydown\n",
      "200      h  525973.342395    keyup\n",
      "201      a  526308.142618  keydown\n",
      "202      a  526573.542628    keyup\n",
      "203      s  526517.642485  keydown\n",
      "204      s  526724.342581    keyup\n",
      "205         526662.042450  keydown\n",
      "206         526835.742644    keyup\n",
      "207      a  526861.342597  keydown\n",
      "208      a  527117.342436    keyup\n",
      "209         527045.542378  keydown\n",
      "210         527189.042439    keyup\n",
      "211      h  527533.842568  keydown\n",
      "212      h  527781.442497    keyup\n",
      "213      e  527685.542426  keydown\n",
      "214      e  527861.242541    keyup\n",
      "215      a  527820.742633  keydown\n",
      "216      a  528076.142435    keyup\n",
      "217      l  527996.442448  keydown\n",
      "218      l  528269.142651    keyup\n",
      "219      t  528460.942493  keydown\n",
      "220      t  528708.942647    keyup\n",
      "221      h  529149.442435  keydown\n",
      "222      h  529374.342536    keyup\n",
      "223      y  530813.242628  keydown\n",
      "224      y  531101.242409    keyup\n",
      "225         531181.242565  keydown\n",
      "226         531404.742482    keyup\n",
      "227      w  532517.242560  keydown\n",
      "228      w  532780.742405    keyup\n",
      "229      o  532812.042555  keydown\n",
      "230      o  533101.342465    keyup\n",
      "231      r  533021.842590  keydown\n",
      "232      r  533236.842540    keyup\n",
      "233      l  533428.642382  keydown\n",
      "234      l  533669.342643    keyup\n",
      "235      d  533693.242544  keydown\n",
      "236      d  533862.142446    keyup\n",
      "237      w  534068.542374  keydown\n",
      "238      w  534292.842439    keyup\n",
      "239      i  534260.142404  keydown\n",
      "240      i  534578.242563    keyup\n",
      "241      d  534436.942536  keydown\n",
      "242      d  534565.342530    keyup\n",
      "243      e  534629.542527  keydown\n",
      "244      e  534870.242487    keyup\n",
      "245         534805.742623  keydown\n",
      "246         535021.042441    keyup\n",
      "247      m  535356.542456  keydown\n",
      "248      m  535589.542599    keyup\n",
      "249      a  535509.642499  keydown\n",
      "250      a  535765.442526    keyup\n",
      "251      r  535669.242587  keydown\n",
      "252      r  535894.242444    keyup\n",
      "253      k  535925.942518  keydown\n",
      "254      k  536173.742560    keyup\n",
      "255      e  536100.442561  keydown\n",
      "256      e  536324.742626    keyup\n",
      "257      t  536340.442428  keydown\n",
      "258      t  536549.542371    keyup\n",
      "259      £  537021.342609    keyup\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(outt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data=np.hstack([tmp.values,new.values]),columns=['key','timestamp','type']*2).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Locate df segment to extract\n",
    "coordinates = (df.participant_id == 33) & (df.sentence_id == 120)\n",
    "# Store temporary dataframe because why not\n",
    "tmp = df.loc[coordinates, ('key','timestamp','type')]#.reset_index(drop=True) # Reset index \n",
    "\n",
    "tmp.timestamp.diff().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.participant_id.unique():\n",
    "    ss = df.loc[df.participant_id == i].timeStamp.diff().sum()\n",
    "    if ss <= 0.0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combine_shift_keydowns_without_matching_keyup(tmp) \n",
    "tmp.reset_index(drop=True, inplace=True) # Reset index here\n",
    "# Get correctly ordered sentences and total compression times\n",
    "new = new_sort(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bob</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bob</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>shift</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key     type\n",
       "0    bob  keydown\n",
       "1    bob    keyup\n",
       "2  shift  keydown\n",
       "3  shift  keydown\n",
       "4  shift  keydown\n",
       "5  shift  keydown\n",
       "6  shift    keyup\n",
       "7      a  keydown\n",
       "8      a    keyup"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = ['bob']*2+['shift']*4 + ['shift'] + [\"a\"]*2\n",
    "d2 = ['keydown', 'keyup'] +['keydown']*4 + ['keyup']+ ['keydown', 'keyup']\n",
    "test_df = pd.DataFrame(data=np.array([d1,d2]).T, columns=['key','type'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bob</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bob</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>shift</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>shift</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>keydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>keyup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key     type\n",
       "0    bob  keydown\n",
       "1    bob    keyup\n",
       "5  shift  keydown\n",
       "6  shift    keyup\n",
       "7      a  keydown\n",
       "8      a    keyup"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_shift_keydowns_without_matching_keyup(test_df)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby, count\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "\n",
    "def new_sort(df):\n",
    "        \n",
    "    df_2 = pd.DataFrame(columns=[\"key\", \"timestamp\", \"type\"])\n",
    "    indexes = []\n",
    "    for i in range(len(df)):\n",
    "        if i not in indexes:\n",
    "            df_2 = df_2.append(df.loc[i,:])\n",
    "            letter = df.loc[i,\"key\"]\n",
    "            indexes.append(i)\n",
    "\n",
    "            for j in range(i+1, len(df)):\n",
    "                if ((df.loc[j,\"key\"] == df.loc[i,\"key\"]) and (j not in indexes)):\n",
    "\n",
    "                    df_2 = df_2.append( df.loc[j,:])\n",
    "                    indexes.append(j)\n",
    "                    break;\n",
    "                    \n",
    "    return df_2.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "def test_repeating_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    pat_len = len(pattern)\n",
    "    assert \"keydown\" == lst[0], \"keydown does not start the list: {}\".format(lst[0])\n",
    "    assert len(lst) % pat_len == 0, \"mismatched length of list\"\n",
    "    assert list(pattern) * (len(lst) // pat_len) == lst, \"the list does not follow the correct pattern\"\n",
    "    \n",
    "def assess_repeating_key_compression_pattern(lst, pattern=(\"keydown\", \"keyup\")):\n",
    "    \n",
    "    assert set(pattern).issubset(set(lst))\n",
    "    pat_len = len(pattern)\n",
    "    if (\"keydown\" == lst[0]) and (len(lst) % pat_len == 0) and (list(pattern) * (len(lst) // pat_len) == lst):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def combine_shift_keydowns_without_matching_keyup(df):\n",
    "    \"\"\"\n",
    "    Function assumes that df has been sorted before getting this far.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the index of all shift keydowns (these are the ones causing the registration problems)\n",
    "    idxs = df.index[(df['key'] == 'shift') & (df['type'] == 'keydown')].tolist()\n",
    "    \n",
    "    # Locate all contiguous sub-sequences\n",
    "    keydown_groups = []\n",
    "    for k, g in groupby(enumerate(idxs), lambda ix: ix[0] - ix[1]):\n",
    "        keydown_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_keydown_coordinates = []\n",
    "    for g in keydown_groups:\n",
    "        if len(g) > 1:\n",
    "            # Do this if the immediate key after each group is a \"keyup\"\n",
    "            if df.loc[g[-1]+1, \"type\"] == 'keyup' or df.loc[g[-1]+2, \"type\"] == 'keyup':\n",
    "                removal_keydown_coordinates.extend(g[:-1])\n",
    "            else:\n",
    "                # Do this if there is no preceeding \"keyup\"\n",
    "                removal_keydown_coordinates.extend(g)\n",
    "        \n",
    "    # In-place operation, no need to return anything. Cannot reset index at this point.\n",
    "    df.drop(df.index[removal_keydown_coordinates], inplace=True)\n",
    "    # Reset index so that we can sort it properly in the next step\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "def remove_superfluous_shifts(df):\n",
    "    \n",
    "    ### NOTE the backspace operator has to appear before this\n",
    "    \n",
    "    idxs = df.index[df['key'] == 'shift'].tolist()\n",
    "    \n",
    "    # Locate a contiguous sub-sequence at the start of the sentence\n",
    "    shift_groups = []\n",
    "    for k, g in groupby(enumerate(idxs), lambda ix: ix[0] - ix[1]):\n",
    "        shift_groups.append(list(map(itemgetter(1), g)))\n",
    "        \n",
    "    # Check what is inside shift groups (if they only contain 'keydown' or 'keyup' there is a problem)\n",
    "    removal_shift_coordinates = []\n",
    "    for g in shift_groups:\n",
    "        if set(g) == 'keydown' or set(g) == 'keydown':\n",
    "            removal_shift_coordinates.append(g[:-1])\n",
    "            \n",
    "    \n",
    "        \n",
    "    if len(shift_groups[0]) > 2 and df.type[shift_groups[0][-1]] == 'keyup' and df.type[shift_groups[0][-2]] == 'keydown':\n",
    "        # Coordinates to remove\n",
    "        df.drop(df.index[shift_groups[0][:-2]], inplace=True)\n",
    "        \n",
    "    # Shifts should only ever appear as contiguous pairs\n",
    "    if not all([len(x) == 2 for x in shift_groups[1:]]): \n",
    "        print(\"Other shift combinations are also longer than they should be.\\n\")\n",
    "        print(shift_groups)\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
